<!DOCTYPE HTML>
<html lang="zh-CN">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="true">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Maverick,LSQ,Galileo,blog" />
    <meta name="generator" content="Maverick 1.1" />
    <meta name="template" content="Galileo" />
    <link rel="alternate" type="application/rss+xml" title="我的个人博客 &raquo; RSS 2.0" href="/Blog/feed/index.xml" />
    <link rel="alternate" type="application/atom+xml" title="我的个人博客 &raquo; ATOM 1.0" href="/Blog/feed/atom/index.xml" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/galileo-3f4dcc35c9.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/ExSearch/ExSearch-182e5a8868.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/katex.min.css">
    <link href="https://fonts.googleapis.com/css?family=Fira+Code&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700&display=swap">
    <script>
        var ExSearchConfig = {
            root: "",
            api: "https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/0f478e2f907150fbe8b72bde26e72bea.json"
        }
    </script>
    
<title>pytorch代码坑 - 我的个人博客</title>
<meta name="author" content="刘胜琪" />
<meta name="description" content="转自知乎" />
<meta property="og:title" content="pytorch代码坑 - 我的个人博客" />
<meta property="og:description" content="转自知乎" />
<meta property="og:site_name" content="我的个人博客" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/Blog/archives/keng/" />
<meta property="og:image" content="" />
<meta property="article:published_time" content="2021-07-18T00:00:00-00.00" />
<meta name="twitter:title" content="pytorch代码坑 - 我的个人博客" />
<meta name="twitter:description" content="转自知乎" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:image" content="" />


    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/disqusjs@1.3/dist/disqusjs.css">
<script src="https://cdn.jsdelivr.net/npm/disqusjs@1.3/dist/disqus.js"></script>
<meta http-equiv="x-dns-prefetch-control" content="on">
<link rel="dns-prefetch" href="//cdn.jsdelivr.net" />
<link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/logo.png">
<script type='text/javascript' src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/jquery-3.4.1.min.js"></script>
<!-- szgotop -->
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog/gotop/css/szgotop.css" />
<!-- FancyBox -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/jquery.fancybox.min.css" />
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/jquery.fancybox.min.js"></script>
<script>
$(function() {
   $(".yue figure img").each(function(i) {
      if (!this.parentNode.href) {
         $(this).wrap("<a href='" + this.src + "' data-fancybox='images' data-caption='" + this.alt + "'></a>")
      }
   })
});
</script>
<script type="text/javascript">
$( '[data-fancybox]' ).fancybox({
	protect:true,
	caption : function( instance, item ) {
	return $(this).find('figcaption').html();
	}
});
</script>
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?d69b9b23082b2143a5bce14c4c459baa";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    </head>
    
    <body>
        
        <div class="container">
            <header id="ga-header">
                <div first>
                    <aside id="ga-brand">
                        <h1 class="brand"><a class="no-style" href="/Blog/">我的个人博客</a></h1>
                        <p>记录生活美好</p>
                    </aside>
                </div>
                <div second id="ga-nav">
                    <nav class="navs">
                        <ul><li><a class="ga-highlight" href="/Blog/" target="_self">首页</a></li><span class="separator">·</span><li><a class="ga-highlight" href="/Blog/archives/" target="_self">归档</a></li><span class="separator">·</span><li><a class="ga-highlight" href="/Blog/about/" target="_self">关于</a></li><span class="separator">·</span><li><a href="#" target="_self" class="search-form-input ga-highlight">搜索</a></li></ul>
                    </nav>
                </div>
            </header>
            <div class="wrapper">
                
<main>    
    <section class="ga-section ga-content">
        <article class="yue">
            <h1 class="ga-post_title">pytorch代码坑</h1>
            <span class="ga-post_meta ga-mono">
                <span>刘胜琪</span>
                <time>
                    2021-07-18
                </time>
                
                in <a no-style class="category" href="/Blog/category/%E9%BB%98%E8%AE%A4%E5%88%86%E7%B1%BB/">
                    默认分类
                </a>
                
                
            </span>
            <div class="ga-content_body">
                <p><strong>Pytorch的坑</strong></p><ol>
<li><strong>nn.Module.cuda() 和 Tensor.cuda() 的作用效果差异</strong></li>
</ol>
<ul>
<li>对于nn.Module:</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> 
<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>
<p>对model自身进行的内存迁移。</p><ul>
<li>对于tensor</li>
</ul>
<p>和nn.Module不同，调用tensor.cuda()只是返回这个tensor对象在GPU内存上的拷贝，而不会对自身进行改变。因此必须对tensor进行重新赋值，即tensor=tensor.cuda().</p><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">create_a_model</span><span class="p">()</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">model</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>    <span class="c1"># 会报错</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">model</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>    <span class="c1"># 正常运行</span>
</pre></div>
<ol start="2">
<li><strong>PyTorch 0.4 计算累积损失的不同</strong></li>
</ol>
<p>以广泛使用的模式total_loss += loss.data[0]为例。Python0.4.0之前，loss是一个封装了(1,)张量的Variable，但Python0.4.0的loss现在是一个零维的标量。对标量进行索引是没有意义的（似乎会报 invalid index to scalar variable 的错误）。使用loss.item()可以从标量中获取Python数字。所以改为：</p><div class="highlight"><pre><span></span><span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
<ol start="3">
<li><strong>torch.Tensor.detach()的使用</strong></li>
</ol>
<p>detach()的官方说明如下：</p><div class="highlight"><pre><span></span><span class="n">Returns</span> <span class="n">a</span> <span class="n">new</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">detached</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">current</span> <span class="n">graph</span><span class="o">.</span>
    <span class="n">The</span> <span class="n">result</span> <span class="n">will</span> <span class="n">never</span> <span class="n">require</span> <span class="n">gradient</span><span class="o">.</span>
</pre></div>
<p>假设有模型A和模型B，我们需要将A的输出作为B的输入，但训练时我们只训练模型B. 那么可以这样做：</p><div class="highlight"><pre><span></span><span class="n">input_B</span> <span class="o">=</span> <span class="n">output_A</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</pre></div>
<p>它可以使两个计算图的梯度传递断开，从而实现我们所需的功能。</p><ol start="4">
<li><p><strong>ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm)</strong></p><p>出现这个错误的情况是，在服务器上的docker中运行训练代码时，batch size设置得过大，shared memory不够（因为docker限制了shm）.解决方法是，将Dataloader的num_workers设置为0.</p></li>
<li><p><strong>pytorch中loss函数的参数设置</strong></p><p>以CrossEntropyLoss为例：</p><div class="highlight"><pre><span></span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;elementwise_mean&#39;</span><span class="p">)</span>
</pre></div>
<ul>
<li><p>若 reduce = False，那么 size_average 参数失效，直接返回向量形式的 loss，即batch中每个元素对应的loss.</p></li>
<li><p>若 reduce = True，那么 loss 返回的是标量：</p></li>
<li><ul>
<li>如果 size_average = True，返回 loss.mean().</li>
<li>如果 size_average = False，返回 loss.sum().</li>
</ul>
</li>
<li><p>weight : 输入一个1D的权值向量，为各个类别的loss加权，如下公式所示：</p></li>
</ul>
<figure style="flex: 433.5820895522388" ><img width="581" height="67" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/cb9a8b8fefac1651f91f96e109f6a66c.jpg" /></figure><ul>
<li>ignore_index : 选择要忽视的目标值，使其对输入梯度不作贡献。如果 size_average = True，那么只计算不被忽视的目标的loss的均值。</li>
<li>reduction : 可选的参数有：‘none’ | ‘elementwise_mean’ | ‘sum’, 正如参数的字面意思，不解释。</li>
</ul>
</li>
<li><p><strong>多GPU的处理机制</strong></p><p>使用多GPU时，应该记住pytorch的处理逻辑是：</p><p>1)在各个GPU上初始化模型。</p><p>2)前向传播时，把batch分配到各个GPU上进行计算。</p><p>3)得到的输出在主GPU上进行汇总，计算loss并反向传播，更新主GPU上的权值。</p><p>4)把主GPU上的模型复制到其它GPU上</p></li>
<li><p><strong>num_batches_tracked参数</strong></p><p>读取模型参数时出现了错误</p><p>KeyError: 'unexpected key &quot;module.bn1.num_batches_tracked&quot; in state_dict'</p><p>经过研究发现，在pytorch 0.4.1及后面的版本里，BatchNorm层新增了num_batches_tracked参数，用来统计训练时的forward过的batch数目，源码如下（pytorch0.4.1）：</p><div class="highlight"><pre><span></span><span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_tracked</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># use cumulative moving average</span>
            <span class="n">exponential_average_factor</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_tracked</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># use exponential moving average</span>
            <span class="n">exponential_average_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span>
</pre></div>
<p>大概可以看出，这个参数和训练时的归一化的计算方式有关。</p><p>因此，我们可以知道该错误是由于训练和测试所用的pytorch版本(0.4.1版本前后的差异)不一致引起的。具体的解决方案是：如果是模型参数（Orderdict格式，很容易修改）里少了num_batches_tracked变量，就加上去，如果是多了就删掉。偷懒的做法是将load_state_dict的strict参数置为False，如下所示：</p><div class="highlight"><pre><span></span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weight_path</span><span class="p">),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p>还看到有人直接修改pytorch 0.4.1的源代码把num_batches_tracked参数删掉的，这就非常不建议了。</p></li>
<li><p><strong>训练时损失出现nan的问题</strong></p><p>训练模型时出现了损失为nan的情况，发现是个大坑。</p><p>可能导致梯度出现nan的三个原因：</p><p><strong>1.梯度爆炸</strong>。也就是说梯度数值超出范围变成nan. 通常可以调小学习率、加BN层或者做梯度裁剪来试试看有没有解决。</p><p><strong>2.损失函数或者网络设计。</strong>比方说，出现了除0，或者出现一些边界情况导致函数不可导，比方说log(0)、sqrt(0).</p><p><strong>3.脏数据。</strong>可以事先对输入数据进行判断看看是否存在nan.</p><p>补充一下nan数据的判断方法：</p><p>注意！像nan或者inf这样的数值不能使用 == 或者 is 来判断！为了安全起见统一使用 math.isnan() 或者 numpy.isnan() 吧。</p><p>例如：</p><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># 判断输入数据是否存在nan</span>
<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input data has NaN!&#39;</span><span class="p">)</span>

<span class="c1"># 判断损失是否为nan</span>
<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loss value is NaN!&#39;</span><span class="p">)</span>
</pre></div>
</li>
<li><p><strong>ValueError: Expected more than 1 value per channel when training</strong></p><p>当batch里只有一个样本时，再调用batch_norm就会报下面这个错误：</p><div class="highlight"><pre><span></span>raise ValueError(&#39;Expected more than 1 value per channel when training, got input size {}&#39;.format(size))
</pre></div>
<p>没有什么特别好的解决办法，在训练前用 num_of_samples % batch_size 算一下会不会正好剩下一个样本。</p></li>
<li><p><strong>优化器的weight_decay项导致的隐蔽bug</strong></p><p>weight_decay指的是权值衰减，即在原损失的基础上加上一个L2惩罚项，使得模型趋向于选择更小的权重参数，起到正则化的效果。</p><p>在训练一个ResNet50的时候，网络的高层部分layer4暂时没有用到，因此也并不会有梯度回传，于是将ResNet50的<strong>所有参数</strong>都传递给Optimizer进行更新了，想着layer4应该能保持原来的权重不变才对。但是实际上，尽管layer4没有梯度回传，但是<strong>weight_decay的作用仍然存在，它使得layer4权值越来越小，趋向于0</strong>。后面需要用到layer4的时候，发现输出异常（接近于0），才注意到这个问题的存在。</p><p>虽然这样的情况可能不容易遇到，但是还是要谨慎：<strong>暂时不需要更新的权值，一定不要传递给Optimizer，避免不必要的麻烦。</strong></p></li>
<li><p><strong>高低版本的切换</strong></p></li>
</ol>
<p>​		AT_CHECK()-&gt;TORCH_CHECK()</p><p>​		THCState_getCurrentStream(state)-&gt;at::cuda::getCurrentCUDAStream().stream()</p><p>​		来自 <a href="https://discuss.pytorch.org/t/thcstate-getcurrentstream-in-torch1-5/85754">https://discuss.pytorch.org/t/thcstate-getcurrentstream-in-torch1-5/85754</a></p>
            </div>
        </article>
        <div id="ga-tags">
    
    <span class="ga-tag">
        <a class="ga-highlight" href="/Blog/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a>
    </span>
    
</div>
    </section>
    
<section id="ga-content_pager">

    <div class="next">
        <a class="ga-highlight" href="/Blog/archives/%E5%8F%AF%E9%87%8D%E5%A4%8D%E6%80%A7%E6%80%BB%E7%BB%93/">pytorch代码可重复性</a>
        <p class="yue">3天训练代码阅读的思考</p>
    </div>


    <div class="prev">
        <a class="ga-highlight" href="/Blog/archives/model.train/">训练模式</a>
        <p class="yue">自己需要提升基础代码知识</p>
    </div>

</section>


    

</main>

                <footer class="ga-mono" id="ga-footer">
                    <section>
                        <span id="ga-uptime"></span>
                        <span class="brand"><a no-style href="https://github.com/Arley517693777" target="_blank">我的个人博客</a></span>
                    </section>
                    <section>
                        <p class="copyright">
                            <span>Copyright © 2022 LSQ</span>
                            <span>Powered by <a no-style href="https://github.com/AlanDecode/Maverick" target="_blank">Maverick</a></span>
                        </p>
                        <div class="copyright">
                            <span class="footer-addon">
                                
                            </span>
                            <nav class="social-links">
                                <ul><li><a class="no-style" title="Twitter" href="https://twitter.com/lsq15" target="_blank"><i class="gi gi-twitter"></i>Twitter</a></li><span class="separator">·</span><li><a class="no-style" title="GitHub" href="https://github.com/LSQsjtu" target="_blank"><i class="gi gi-github"></i>GitHub</a></li></ul>
                            </nav>
                        </div>
                    </section>
                    <script>
                        var site_build_date = "2021-05-04T22:46+08:00"
                    </script>
                    <script src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/galileo-dc4baa7cf4.js"></script>
                </footer>
            </div>
        </div>
    </div>

    <!--katex-->
    <script defer src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/katex.min.js"></script>
    <script>
    mathOpts = {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "\\[", right: "\\]", display: true},
            {left: "$", right: "$", display: false},
            {left: "\\(", right: "\\)", display: false}
        ]
    };
    </script>
    <script defer src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/auto-render.min.js" onload="renderMathInElement(document.body, mathOpts);"></script>

    <script src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/ExSearch/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/ExSearch/ExSearch-493cb9cd89.js"></script>

    
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog/gotop/js/szgotop.js"></script>
<div class="back-to-top cd-top faa-float animated cd-is-visible" style="top: -999px;"></div>

    </body>
</html>