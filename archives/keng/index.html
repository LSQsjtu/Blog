<!DOCTYPE HTML>
<html lang="zh-CN">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="true">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Maverick,LSQ,Galileo,blog" />
    <meta name="generator" content="Maverick 1.1" />
    <meta name="template" content="Galileo" />
    <link rel="alternate" type="application/rss+xml" title="我的个人博客 &raquo; RSS 2.0" href="/Blog/feed/index.xml" />
    <link rel="alternate" type="application/atom+xml" title="我的个人博客 &raquo; ATOM 1.0" href="/Blog/feed/atom/index.xml" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/galileo-3f4dcc35c9.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/ExSearch/ExSearch-182e5a8868.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/katex.min.css">
    <link href="https://fonts.googleapis.com/css?family=Fira+Code&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700&display=swap">
    <script>
        var ExSearchConfig = {
            root: "",
            api: "https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/1ed46474b6a3c85560bb22149fb6057e.json"
        }
    </script>
    
<title>pytorch代码坑 - 我的个人博客</title>
<meta name="author" content="刘胜琪" />
<meta name="description" content="转自知乎" />
<meta property="og:title" content="pytorch代码坑 - 我的个人博客" />
<meta property="og:description" content="转自知乎" />
<meta property="og:site_name" content="我的个人博客" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/Blog/archives/keng/" />
<meta property="og:image" content="" />
<meta property="article:published_time" content="2021-07-18T00:00:00-00.00" />
<meta name="twitter:title" content="pytorch代码坑 - 我的个人博客" />
<meta name="twitter:description" content="转自知乎" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:image" content="" />


    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/disqusjs@1.3/dist/disqusjs.css">
<script src="https://cdn.jsdelivr.net/npm/disqusjs@1.3/dist/disqus.js"></script>
<meta http-equiv="x-dns-prefetch-control" content="on">
<link rel="dns-prefetch" href="//cdn.jsdelivr.net" />
<link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/logo.png">
<script type='text/javascript' src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/jquery-3.4.1.min.js"></script>
<!-- szgotop -->
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog/gotop/css/szgotop.css" />
<!-- FancyBox -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/jquery.fancybox.min.css" />
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/jquery.fancybox.min.js"></script>
<script>
$(function() {
   $(".yue figure img").each(function(i) {
      if (!this.parentNode.href) {
         $(this).wrap("<a href='" + this.src + "' data-fancybox='images' data-caption='" + this.alt + "'></a>")
      }
   })
});
</script>
<script type="text/javascript">
$( '[data-fancybox]' ).fancybox({
	protect:true,
	caption : function( instance, item ) {
	return $(this).find('figcaption').html();
	}
});
</script>
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?d69b9b23082b2143a5bce14c4c459baa";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    </head>
    
    <body>
        
        <div class="container">
            <header id="ga-header">
                <div first>
                    <aside id="ga-brand">
                        <h1 class="brand"><a class="no-style" href="/Blog/">我的个人博客</a></h1>
                        <p>记录生活美好</p>
                    </aside>
                </div>
                <div second id="ga-nav">
                    <nav class="navs">
                        <ul><li><a class="ga-highlight" href="/Blog/" target="_self">首页</a></li><span class="separator">·</span><li><a class="ga-highlight" href="/Blog/archives/" target="_self">归档</a></li><span class="separator">·</span><li><a class="ga-highlight" href="/Blog/about/" target="_self">关于</a></li><span class="separator">·</span><li><a href="#" target="_self" class="search-form-input ga-highlight">搜索</a></li></ul>
                    </nav>
                </div>
            </header>
            <div class="wrapper">
                
<main>    
    <section class="ga-section ga-content">
        <article class="yue">
            <h1 class="ga-post_title">pytorch代码坑</h1>
            <span class="ga-post_meta ga-mono">
                <span>刘胜琪</span>
                <time>
                    2021-07-18
                </time>
                
                in <a no-style class="category" href="/Blog/category/%E9%BB%98%E8%AE%A4%E5%88%86%E7%B1%BB/">
                    默认分类
                </a>
                
                
            </span>
            <div class="ga-content_body">
                <p><strong>Pytorch的坑</strong></p><ol>
<li><strong>nn.Module.cuda() 和 Tensor.cuda() 的作用效果差异</strong></li>
</ol>
<ul>
<li>对于nn.Module:</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> 
<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>
<p>对model自身进行的内存迁移。</p><ul>
<li>对于tensor</li>
</ul>
<p>和nn.Module不同，调用tensor.cuda()只是返回这个tensor对象在GPU内存上的拷贝，而不会对自身进行改变。因此必须对tensor进行重新赋值，即tensor=tensor.cuda().</p><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">create_a_model</span><span class="p">()</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">model</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>    <span class="c1"># 会报错</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">model</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>    <span class="c1"># 正常运行</span>
</pre></div>
<ol start="2">
<li><strong>PyTorch 0.4 计算累积损失的不同</strong></li>
</ol>
<p>以广泛使用的模式total_loss += loss.data[0]为例。Python0.4.0之前，loss是一个封装了(1,)张量的Variable，但Python0.4.0的loss现在是一个零维的标量。对标量进行索引是没有意义的（似乎会报 invalid index to scalar variable 的错误）。使用loss.item()可以从标量中获取Python数字。所以改为：</p><div class="highlight"><pre><span></span><span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
<ol start="3">
<li><strong>torch.Tensor.detach()的使用</strong></li>
</ol>
<p>detach()的官方说明如下：</p><div class="highlight"><pre><span></span><span class="n">Returns</span> <span class="n">a</span> <span class="n">new</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">detached</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">current</span> <span class="n">graph</span><span class="o">.</span>
    <span class="n">The</span> <span class="n">result</span> <span class="n">will</span> <span class="n">never</span> <span class="n">require</span> <span class="n">gradient</span><span class="o">.</span>
</pre></div>
<p>假设有模型A和模型B，我们需要将A的输出作为B的输入，但训练时我们只训练模型B. 那么可以这样做：</p><div class="highlight"><pre><span></span><span class="n">input_B</span> <span class="o">=</span> <span class="n">output_A</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</pre></div>
<p>它可以使两个计算图的梯度传递断开，从而实现我们所需的功能。</p><ol start="4">
<li><p><strong>ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm)</strong></p><p>出现这个错误的情况是，在服务器上的docker中运行训练代码时，batch size设置得过大，shared memory不够（因为docker限制了shm）.解决方法是，将Dataloader的num_workers设置为0.</p></li>
<li><p><strong>pytorch中loss函数的参数设置</strong></p><p>以CrossEntropyLoss为例：</p><div class="highlight"><pre><span></span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;elementwise_mean&#39;</span><span class="p">)</span>
</pre></div>
<ul>
<li><p>若 reduce = False，那么 size_average 参数失效，直接返回向量形式的 loss，即batch中每个元素对应的loss.</p></li>
<li><p>若 reduce = True，那么 loss 返回的是标量：</p></li>
<li><ul>
<li>如果 size_average = True，返回 loss.mean().</li>
<li>如果 size_average = False，返回 loss.sum().</li>
</ul>
</li>
<li><p>weight : 输入一个1D的权值向量，为各个类别的loss加权，如下公式所示：</p></li>
</ul>
<figure style="flex: 433.5820895522388" ><img width="581" height="67" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/cb9a8b8fefac1651f91f96e109f6a66c.jpg" /></figure><ul>
<li>ignore_index : 选择要忽视的目标值，使其对输入梯度不作贡献。如果 size_average = True，那么只计算不被忽视的目标的loss的均值。</li>
<li>reduction : 可选的参数有：‘none’ | ‘elementwise_mean’ | ‘sum’, 正如参数的字面意思，不解释。</li>
</ul>
</li>
<li><p><strong>多GPU的处理机制</strong></p><p>使用多GPU时，应该记住pytorch的处理逻辑是：</p><p>1)在各个GPU上初始化模型。</p><p>2)前向传播时，把batch分配到各个GPU上进行计算。</p><p>3)得到的输出在主GPU上进行汇总，计算loss并反向传播，更新主GPU上的权值。</p><p>4)把主GPU上的模型复制到其它GPU上</p></li>
<li><p><strong>num_batches_tracked参数</strong></p><p>读取模型参数时出现了错误</p><p>KeyError: 'unexpected key &quot;module.bn1.num_batches_tracked&quot; in state_dict'</p><p>经过研究发现，在pytorch 0.4.1及后面的版本里，BatchNorm层新增了num_batches_tracked参数，用来统计训练时的forward过的batch数目，源码如下（pytorch0.4.1）：</p><div class="highlight"><pre><span></span><span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_tracked</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># use cumulative moving average</span>
            <span class="n">exponential_average_factor</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_tracked</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># use exponential moving average</span>
            <span class="n">exponential_average_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span>
</pre></div>
<p>大概可以看出，这个参数和训练时的归一化的计算方式有关。</p><p>因此，我们可以知道该错误是由于训练和测试所用的pytorch版本(0.4.1版本前后的差异)不一致引起的。具体的解决方案是：如果是模型参数（Orderdict格式，很容易修改）里少了num_batches_tracked变量，就加上去，如果是多了就删掉。偷懒的做法是将load_state_dict的strict参数置为False，如下所示：</p><div class="highlight"><pre><span></span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weight_path</span><span class="p">),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p>还看到有人直接修改pytorch 0.4.1的源代码把num_batches_tracked参数删掉的，这就非常不建议了。</p></li>
<li><p><strong>训练时损失出现nan的问题</strong></p><p>训练模型时出现了损失为nan的情况，发现是个大坑。</p><p>可能导致梯度出现nan的三个原因：</p><p><strong>1.梯度爆炸</strong>。也就是说梯度数值超出范围变成nan. 通常可以调小学习率、加BN层或者做梯度裁剪来试试看有没有解决。</p><p><strong>2.损失函数或者网络设计。</strong>比方说，出现了除0，或者出现一些边界情况导致函数不可导，比方说log(0)、sqrt(0).</p><p><strong>3.脏数据。</strong>可以事先对输入数据进行判断看看是否存在nan.</p><p>补充一下nan数据的判断方法：</p><p>注意！像nan或者inf这样的数值不能使用 == 或者 is 来判断！为了安全起见统一使用 math.isnan() 或者 numpy.isnan() 吧。</p><p>例如：</p><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># 判断输入数据是否存在nan</span>
<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input data has NaN!&#39;</span><span class="p">)</span>

<span class="c1"># 判断损失是否为nan</span>
<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loss value is NaN!&#39;</span><span class="p">)</span>
</pre></div>
</li>
<li><p><strong>ValueError: Expected more than 1 value per channel when training</strong></p><p>当batch里只有一个样本时，再调用batch_norm就会报下面这个错误：</p><div class="highlight"><pre><span></span>raise ValueError(&#39;Expected more than 1 value per channel when training, got input size {}&#39;.format(size))
</pre></div>
<p>没有什么特别好的解决办法，在训练前用 num_of_samples % batch_size 算一下会不会正好剩下一个样本。</p></li>
<li><p><strong>优化器的weight_decay项导致的隐蔽bug</strong></p><p>weight_decay指的是权值衰减，即在原损失的基础上加上一个L2惩罚项，使得模型趋向于选择更小的权重参数，起到正则化的效果。</p><p>在训练一个ResNet50的时候，网络的高层部分layer4暂时没有用到，因此也并不会有梯度回传，于是将ResNet50的<strong>所有参数</strong>都传递给Optimizer进行更新了，想着layer4应该能保持原来的权重不变才对。但是实际上，尽管layer4没有梯度回传，但是<strong>weight_decay的作用仍然存在，它使得layer4权值越来越小，趋向于0</strong>。后面需要用到layer4的时候，发现输出异常（接近于0），才注意到这个问题的存在。</p><p>虽然这样的情况可能不容易遇到，但是还是要谨慎：<strong>暂时不需要更新的权值，一定不要传递给Optimizer，避免不必要的麻烦。</strong></p></li>
<li><p><strong>高低版本的切换</strong></p></li>
</ol>
<p>​		AT_CHECK()-&gt;TORCH_CHECK()</p><p>​		THCState_getCurrentStream(state)-&gt;at::cuda::getCurrentCUDAStream().stream()</p><p>​		来自 <a href="https://discuss.pytorch.org/t/thcstate-getcurrentstream-in-torch1-5/85754">https://discuss.pytorch.org/t/thcstate-getcurrentstream-in-torch1-5/85754</a></p><ol start="12">
<li><p>有用的api</p><h3>二、爱因斯坦求和法</h3>
<p><strong>爱因斯坦求和是一种对求和公式简洁高效的记法，其原则是当变量下标重复出现时，即可省略繁琐的求和符号。</strong></p><p>比如求和公式：</p><p>$$ \sum_{i=1}^n a_{i} b_{i} = a_{1} b_{1} + a_{2} b_{2} + ... + a_{n} b_{n} $$</p>
<p>其中变量 <strong>a</strong> 和变量 <strong>b</strong> 的下标重复出现，则可将其表示为：</p><p>$$ a_{i} b_{i} = \sum_{i=1}^n a_{i} $$</p>
<p>由此我们可以将上述矩阵运算化简为：</p><p>$$ C_ { i j } = \sum _ { k } A _ { i k } B _ { k j } = A _ { i k } B _ { k j } $$</p>
<p>进一步地，我们可以得到矩阵乘法的一个抽象</p><p>$$ ik * kj = ij $$</p>
<h2>einsum的原理</h2>
<h3>一、具体原理</h3>
<p>einsum方法正是利用了爱因斯坦求和简洁高效的表示方法，从而可以驾驭任何复杂的矩阵计算操作。基本的框架如下：</p><div class="highlight"><pre><span></span>C = einsum(&#39;ij,jk-&gt;ik&#39;, A, B)
</pre></div>
<p>上述操作表示矩阵A与矩阵B的点积。输入的参数分为两部分:</p><ul>
<li>前面表示计算操作的指令串，</li>
<li>后面是以逗号隔开的操作对象（数量需与前面对应）。</li>
</ul>
<p>其中在计算操作表示中，</p><ul>
<li>&quot;-&gt;&quot; 左边是以逗号隔开的下标索引，重复出现的索引即是需要爱因斯坦求和的；</li>
<li>&quot;-&gt;&quot; 右边是最后输出的结果形式。</li>
</ul>
<p>以上式为例，其计算公式为： $C_{ik} = \sum_{j} A_{ij} B_{jk}$ ，其等价于矩阵A与B的点积。</p><p>在矩阵之间的运算中，下标可以分为两类：</p><ul>
<li>自由标(Free index)，也就是在输入和输出端都出现的下标</li>
<li><a href="https://www.zhihu.com/search?q=%E5%93%91%E6%A0%87&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2462139068%7D">哑标</a>(Summation index)，在输入端出现但输出端没有出现的下标</li>
</ul>
<p>矩阵运算中所有参与运算的下标都被包含在次定义中。</p><p>以上述矩阵$A,B$的乘法过程为例：</p><div class="highlight"><pre><span></span>C = np.einsum(&quot;ik,kj-&gt;ij&quot;, A, B)
print(&quot;einsum result is :\n&quot;, C)
print(&quot;M = A*B = \n&quot;,M)
</pre></div>
<p>可以看出，这与上述通过循环方式得出的结果一致。在 ik,kj -&gt; ij 的例子中, i,j 是自由标，k是哑标。</p><h3>二、计算准则</h3>
<ol>
<li>两个不同矩阵相乘，<strong>哑标</strong>维度需要逐元素相乘并求和，<strong>自由标</strong>保留</li>
<li>自由标可在输出中以任意顺序出现，但只能出现一次</li>
</ol>
</li>
</ol>
<p><a href="https://www.zhihu.com/question/53365039/answer/2462139068">numpy.einsum如何理解和运用？ - 知乎</a></p>
            </div>
        </article>
        <div id="ga-tags">
    
    <span class="ga-tag">
        <a class="ga-highlight" href="/Blog/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a>
    </span>
    
</div>
    </section>
    
<section id="ga-content_pager">

    <div class="next">
        <a class="ga-highlight" href="/Blog/archives/lr%E2%80%94%E2%80%94optimization/">pytorch学习率调整</a>
        <p class="yue">转自知乎</p>
    </div>


    <div class="prev">
        <a class="ga-highlight" href="/Blog/archives/model.train/">训练模式</a>
        <p class="yue">自己需要提升基础代码知识</p>
    </div>

</section>


    

</main>

                <footer class="ga-mono" id="ga-footer">
                    <section>
                        <span id="ga-uptime"></span>
                        <span class="brand"><a no-style href="https://github.com/Arley517693777" target="_blank">我的个人博客</a></span>
                    </section>
                    <section>
                        <p class="copyright">
                            <span>Copyright © 2022 LSQ</span>
                            <span>Powered by <a no-style href="https://github.com/AlanDecode/Maverick" target="_blank">Maverick</a></span>
                        </p>
                        <div class="copyright">
                            <span class="footer-addon">
                                
                            </span>
                            <nav class="social-links">
                                <ul><li><a class="no-style" title="Twitter" href="https://twitter.com/lsq15" target="_blank"><i class="gi gi-twitter"></i>Twitter</a></li><span class="separator">·</span><li><a class="no-style" title="GitHub" href="https://github.com/LSQsjtu" target="_blank"><i class="gi gi-github"></i>GitHub</a></li></ul>
                            </nav>
                        </div>
                    </section>
                    <script>
                        var site_build_date = "2021-05-04T22:46+08:00"
                    </script>
                    <script src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/galileo-dc4baa7cf4.js"></script>
                </footer>
            </div>
        </div>
    </div>

    <!--katex-->
    <script defer src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/katex.min.js"></script>
    <script>
    mathOpts = {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "\\[", right: "\\]", display: true},
            {left: "$", right: "$", display: false},
            {left: "\\(", right: "\\)", display: false}
        ]
    };
    </script>
    <script defer src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/auto-render.min.js" onload="renderMathInElement(document.body, mathOpts);"></script>

    <script src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/ExSearch/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/assets/ExSearch/ExSearch-493cb9cd89.js"></script>

    
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog/gotop/js/szgotop.js"></script>
<div class="back-to-top cd-top faa-float animated cd-is-visible" style="top: -999px;"></div>

    </body>
</html>