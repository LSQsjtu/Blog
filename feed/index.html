<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>我的个人博客</title><link>/Blog/</link><description>记录生活美好</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/f-logo.png</url><title>我的个人博客</title><link>/Blog/</link></image><language>zh-CN</language><lastBuildDate>Fri, 06 Aug 2021 07:26:59 +0806</lastBuildDate><pubDate>Fri, 06 Aug 2021 07:26:59 +0806</pubDate><item><title>20号奇怪想法</title><link>/Blog/archives/strange%20idea/</link><description>&lt;p&gt;&lt;strong&gt;七月二十日&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;KD蒸馏的新奇地方&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;response-base knowledge：用最后的logits，最简单直接&lt;/li&gt;
&lt;li&gt;feature-base knowledge：loss方法，hint layer的选取没有明确的指示，让中间层的特征，attention map一致&lt;/li&gt;
&lt;li&gt;relation-base knowledge：同时使用logits和中间层的feature&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;训练方法，offline，online，self-distillation&lt;/p&gt;&lt;p&gt;stu-network设计暂时不设计&lt;/p&gt;&lt;p&gt;训练算法：使用gan，生成数据，增强数据集&lt;/p&gt;&lt;p&gt;多种模型压缩算法使用增强网络功能&lt;/p&gt;&lt;p&gt;小的教师网络增强大的学生网络的学习&lt;/p&gt;&lt;p&gt;feature-base knowledge distillation开源文章及代码：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Cross-Layer Distillation with Semantic Calibration&lt;/strong&gt;（&lt;a href="https://github.com/DefangChen/SemCKD"&gt;GitHub - DefangChen/SemCKD: This is the official implementation for the AAAI-2021 paper (Cross-Layer Distillation with Semantic Calibration).&lt;/a&gt;  AAAI被引用次数1&lt;/p&gt;&lt;p&gt;2014-2021KD论文整理：&lt;a href="https://github.com/FLHonker/Awesome-Knowledge-Distillation"&gt;FLHonker/Awesome-Knowledge-Distillation: Awesome Knowledge-Distillation. 分类整理的知识蒸馏paper(2014-2021)&lt;/a&gt;&lt;/p&gt;&lt;p&gt;attetionmap use neuron selectivity transfer&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/strange%20idea/</guid><pubDate>Tue, 20 Jul 2021 00:00:00 +0806</pubDate></item><item><title>论文阅读</title><link>/Blog/archives/key_point/</link><description>&lt;p&gt;&lt;strong&gt;论文阅读&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;总共四篇论文，关于action recognition蒸馏方向&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Spatiotemporal distilled dense-Connectivity network for video action recognition&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;解决空间和时间层面信息共享的问题，而不是单独训练。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新知识&lt;/strong&gt;：乘法门&lt;/p&gt;&lt;figure style="flex: 93.26424870466322" &gt;&lt;img width="720" height="386" src="https://pic3.zhimg.com/80/v2-a4142c9523b06fd73b9190d6f36625e2_720w.jpg" /&gt;&lt;/figure&gt;&lt;p&gt;乘法门是一组信息对另一组数据的控制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;写作手法&lt;/strong&gt;：首先便与21文章比对区别之处，说明网络想法来源，通过DenseNet（将所有浅层输出的feature map作为输入），方便信息重复利用，减缓梯度消失问题，等等。公式花里胡哨的，将公式分多块书写，每个loss大量笔墨&lt;/p&gt;&lt;p&gt;新设计的网络跨模态融合，让RGB（appearance）和FLOW（motion）信息交流，设计了一个新的网络结构SDDN和新的蒸馏方式，两个学生（RGB，FLOW）和一个teacher（fusion）&lt;/p&gt;&lt;figure style="flex: 103.07308970099668" &gt;&lt;img width="1241" height="602" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/e6fc8b44286ff20c27bf6bf31bb6ac6b.png" /&gt;&lt;figcaption&gt;image-20210722105903240&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;基础网络结构&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如果使用乘法将两个信息相乘进行控制？使用dense connection？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;用所有层的信息有提升准确率&lt;/p&gt;&lt;figure style="flex: 232.5" &gt;&lt;img width="372" height="80" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/3cc938b889631727b1c59843a1d2b9ca.png" /&gt;&lt;figcaption&gt;image-20210722115733057&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;将各个层的flow feature concatenate在一起&lt;/p&gt;&lt;p&gt;消融实验做得很好：&lt;/p&gt;&lt;p&gt;提升的做法有：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;STDDCN模型本身更好&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;α，β，temperature选取最佳值&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Distillation，教师和两个学生的模式更佳&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;利用前置所有的信息更佳&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;motion信息指导appearance更佳&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Modality distillation with multiple stream networks for action recognition&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;hallucination network:初步理解为模拟的信息输入，自我产生，例如在RGB中模拟输入depth信息 &lt;strong&gt;是否可以模拟帧数多的情景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;将depth数据学得的信息输入hallucination network中学习，网络原本的输入是RGB，所以最后可以在同一种RGB数据下训练和测试&lt;/p&gt;&lt;p&gt;跨模态方法是通过残差&lt;/p&gt;&lt;figure style="flex: 347.43589743589746" &gt;&lt;img width="542" height="78" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/976d481f370ea18695f14d48ca09d38a.png" /&gt;&lt;figcaption&gt;image-20210722195112871&lt;/figcaption&gt;&lt;/figure&gt;&lt;ol start="3"&gt;
&lt;li&gt;&lt;strong&gt;Cross-Modal Knowledge Distillation for Action Recognition&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;使用交叉熵，获得比KL-loss更高的准确度，原因是temperature不好确定&lt;/p&gt;&lt;p&gt;mutual learning 使用多个学生网络&lt;/p&gt;&lt;figure style="flex: 91.98250728862973" &gt;&lt;img width="631" height="343" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/d467e9d6ba401d7fcb9e8fc3e7a0bc2c.png" /&gt;&lt;figcaption&gt;image-20210723101729283&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;解决的问题，将没有标注的skeleton data用于学生网络的训练，增强了数据集的可用性，（可不可以直接用teacher 网络的输出作为ground truth，这样的准确率等于0.86*0.86=0.7396）mutual learning 74.2差不多&lt;/p&gt;&lt;p&gt;利用了缺失标签的信息才是它的长处&lt;/p&gt;&lt;ol start="4"&gt;
&lt;li&gt;&lt;strong&gt;Graph distillation for action detection with privileged modalities&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;解决问题：source domain大部分信息没有利用到&lt;/p&gt;&lt;p&gt;human parsing:人体部分的颜色标注&lt;/p&gt;&lt;p&gt;前面层低级语义信息可以共享&lt;/p&gt;&lt;p&gt;1*1卷积：局部卷积，信息充分融合&lt;/p&gt;&lt;p&gt;训练方式，数据集&lt;/p&gt;&lt;p&gt;会议更新的比较快&lt;/p&gt;&lt;p&gt;bilstm：帧顺着输一次，倒着输一次，可以得到后面的信息&lt;/p&gt;&lt;p&gt;LSTM学习到后面的隐变量&lt;/p&gt;&lt;p&gt;HDM51 dataloader&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/key_point/</guid><pubDate>Thu, 22 Jul 2021 00:00:00 +0806</pubDate></item><item><title>resnet网络</title><link>/Blog/archives/resnet/</link><description>&lt;p&gt;&lt;strong&gt;restnet&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;简化了学习过程，增强了梯度传播&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;相比于学习原始的信号，残差网络学习的是信号的差值，这在许多的研究中被验证是更加有效的，它简化了学习的过程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;根据我们前面的内容可知，在一定程度上，网络越深表达能力越强，性能越好。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;然而随着网络深度的增加，带来了许多优化相关的问题，比如梯度消散，梯度爆炸。&lt;/p&gt;&lt;p&gt;残差网络从根本上解决了梯度问题&lt;/p&gt;&lt;figure style="flex: 121.0762331838565" &gt;&lt;img width="1080" height="446" src="https://res-static.hc-cdn.cn/fms/img/fb9d7c7db3bb265f7f997160aa48bc641603780769781" /&gt;&lt;/figure&gt;&lt;ol start="2"&gt;
&lt;li&gt;&lt;strong&gt;打破了网络的不对称性&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;虽然残差网络可以通过跳层连接，增强了梯度的流动，从而使得上千层网络的训练成为可能，&lt;strong&gt;不过相关的研究表面残差网络的有效性，更加体现在减轻了神经网络的退化。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如果在网络中每个层只有少量的隐藏单元对不同的输入改变它们的激活值，而大部分隐藏单元对不同的输入都是相同的反应，此时整个权重矩阵的秩不高。并且随着网络层数的增加，连乘后使得整个秩变的更低，这就是我们常说的网络退化问题。&lt;/strong&gt;&lt;/p&gt;&lt;ol start="3"&gt;
&lt;li&gt;&lt;strong&gt;增强了网络的泛化能力&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一个残差块可以用表示为：&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7Bl%2B1%7D%3D+x_l%2B%5Cmathcal%7BF%7D%28x_l%2C+%7BW_l%7D%29%5Ctag%7B1%7D" /&gt;&lt;/figure&gt;&lt;p&gt;残差块分成两部分直接映射部分和残差部分。 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=h%28x_l%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是直接映射，反应在图1中是左边的曲线； &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BF%7D%28x_l%2C+%7BW_l%7D%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是残差部分，一般由两个或者三个卷积操作构成，即下图中右侧包含卷积的部分。&lt;/p&gt;&lt;figure style="flex: 23.668639053254438" &gt;&lt;img width="160" height="338" src="https://pic2.zhimg.com/80/v2-bd76d0f10f84d74f90505eababd3d4a1_720w.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图中的Weight在卷积网络中是指卷积操作，addition是指单位加操作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;残差网络的背后原理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;残差块一个更通用的表示方式是&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=y_l%3D+h%28x_l%29%2B%5Cmathcal%7BF%7D%28x_l%2C+%7BW_l%7D%29%5Ctag%7B3%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7Bl%2B1%7D+%3D+f%28y_l%29%5Ctag%7B4%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;现在我们先不考虑升维或者降维的情况，那么在[1]中， &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=h%28%5Ccdot%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是直接映射， &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=f%28%5Ccdot%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是激活函数，一般使用ReLU。我们首先给出两个假设：&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;假设1： &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=h%28%5Ccdot%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是直接映射；&lt;/li&gt;
&lt;li&gt;假设2： &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=f%28%5Ccdot%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是直接映射。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么这时候残差块可以表示为：&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7Bl%2B1%7D+%3D+x_l+%2B+%5Cmathcal%7BF%7D%28x_l%2C+%7BW_l%7D%29%5Ctag%7B5%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对于一个更深的层 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=L" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ，其与 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=l" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 层的关系可以表示为&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_L+%3D+x_l+%2B+%5Csum_%7Bi%3Dl%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29%5Ctag%7B6%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个公式反应了残差网络的两个属性：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=L" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 层可以表示为==任意一个比它浅的l层和他们之间的残差部分之和；==&lt;/li&gt;
&lt;li&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_L%3D+x_0+%2B+%5Csum_%7Bi%3D0%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ， &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=L" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是各个残差块特征的单位累和，而MLP是特征矩阵的累积。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;根据BP（back propagation）中使用的导数的链式法则，损失函数 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cvarepsilon" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 关于 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_l" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 的梯度可以表示为&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_l%7D+%3D+%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D%5Cfrac%7B%5Cpartial+x_L%7D%7B%5Cpartial+x_l%7D+%3D+%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D%281%2B%5Cfrac%7B%5Cpartial+%7D%7B%5Cpartial+x_l%7D%5Csum_%7Bi%3Dl%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29%29+%3D+%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D%2B%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D+%5Cfrac%7B%5Cpartial+%7D%7B%5Cpartial+x_l%7D%5Csum_%7Bi%3Dl%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29+%5Ctag%7B7%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上面公式反映了残差网络的两个属性：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;在整个训练过程中， &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%7D%7B%5Cpartial+x_l%7D%5Csum_%7Bi%3Dl%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29+" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 不可能一直为 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=-1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ，也就是说在残差网络中==不会出现梯度消失的问题==。&lt;/li&gt;
&lt;li&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 表示 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=L" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 层的梯度可以直接传递到任何一个比它浅的 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=l" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 层。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过分析残差网络的正向和反向两个过程，我们发现，当残差块满足上面两个假设时，信息可以非常畅通的在高层和低层之间相互传导，说明这两个假设是让残差网络可以训练深度模型的充分条件。那么这两个假设是必要条件吗？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;直接映射是最好的选择&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于假设1，我们采用反证法，假设 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=h%28x_l%29+%3D+%5Clambda_l+x_l" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ，那么这时候，残差块（图3.b）表示为&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7Bl%2B1%7D+%3D+%5Clambda_lx_l+%2B+%5Cmathcal%7BF%7D%28x_l%2C+%7BW_l%7D%29%5Ctag%7B8%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对于更深的L层&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7BL%7D+%3D+%28%5Cprod_%7Bi%3Dl%7D%5E%7BL-1%7D%5Clambda_i%29x_l+%2B+%5Csum_%7Bi%3Dl%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29%5Ctag%7B9%7D" /&gt;&lt;/figure&gt;&lt;p&gt;为了简化问题，我们只考虑公式的左半部分 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7BL%7D+%3D+%28%5Cprod_%7Bi%3Dl%7D%5E%7BL-1%7D%5Clambda_l%29x_l" /&gt;&lt;/figure&gt; ，损失函数 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cvarepsilon" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 对 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_l" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 求偏微分得&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%5Cvarepsilon%7D%7B%5Cpartial+x_l%7D+%3D+%5Cfrac%7B%5Cpartial%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D+%5Cleft%28+%28%5Cprod_%7Bi%3Dl%7D%5E%7BL-1%7D%5Clambda_i%29+%2B+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_l%7D+%5Chat%7B%5Cmathcal%7BF%7D%7D%28x_i%2C+%5Cmathcal%7BW%7D_i%29%5Cright%29%5Ctag%7B10%7D+" /&gt;&lt;/figure&gt;&lt;p&gt;上面公式反映了两个属性：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;当 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Clambda%3E1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，很有可能发生梯度爆炸；&lt;/li&gt;
&lt;li&gt;当 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Clambda%3C1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，梯度变成0，会阻碍残差网络信息的反向传递，从而影响残差网络的训练。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Clambda" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ==必须等1==。同理，其他常见的激活函数都会产生和上面的例子类似的阻碍信息反向传播的问题。&lt;/p&gt;&lt;p&gt;对于其它不影响梯度的 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=h%28%5Ccdot%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ，例如LSTM中的门机制（图3.c，图3.d）或者Dropout（图3.f）以及[1]中用于降维的 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=1%5Ctimes1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 卷积（图3.e）也许会有效果，作者采用了实验的方法进行验证，实验结果见图4&lt;/p&gt;&lt;figure style="flex: 52.63157894736842" &gt;&lt;img width="720" height="684" src="https://pic2.zhimg.com/80/v2-843326b572e2e4c5c8956e289bd3f58d_720w.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图3：直接映射的变异模型&lt;/p&gt;&lt;figure style="flex: 109.7560975609756" &gt;&lt;img width="720" height="328" src="https://pic4.zhimg.com/80/v2-5d8fd2868a4ba30e61ce477ab00d7f0f_720w.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;图4：变异模型（均为110层）在Cifar10数据集上的表现&lt;p&gt;从图4的实验结果中我们可以看出，在所有的变异模型中，依旧是==直接映射的效果最好==。下面我们对图3中的各种变异模型的分析&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;Exclusive Gating：在LSTM的门机制中，绝大多数门的值为0或者1，几乎很难落到0.5附近。当 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=g%28x%29%5Crightarrow0" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，残差块变成只有直接映射组成，阻碍卷积部分特征的传播；当 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=g%28x%29%5Crightarrow1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，直接映射失效，退化为普通的卷积网络；&lt;/li&gt;
&lt;li&gt;Short-cut only gating： &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=g%28x%29%5Crightarrow0" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，此时网络便是[1]提出的直接映射的残差网络； &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=g%28x%29%5Crightarrow1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，退化为普通卷积网络；&lt;/li&gt;
&lt;li&gt;Dropout：类似于将直接映射乘以 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=1-p" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ，所以会影响梯度的反向传播；&lt;/li&gt;
&lt;li&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=1%5Ctimes1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; conv： &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=1%5Ctimes1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 卷积比直接映射拥有更强的表示能力，但是实验效果却不如直接映射，说明该问题更可能是优化问题而非模型容量问题。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以我们可以得出结论：假设1成立，即&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=y_l+%3D+x_l+%2B+%5Cmathcal%7BF%7D%28x_l%2C+w_l%29+%5Ctag%7B11%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=y_%7Bl%2B1%7D+%3D+x_%7Bl%2B1%7D+%2B+%5Cmathcal%7BF%7D%28x_%7Bl%2B1%7D%2C+w_%7Bl%2B1%7D%29+%3D+f%28y_l%29+%2B+%5Cmathcal%7BF%7D%28f%28y_l%29%2C+w_%7Bl%2B1%7D%29+%5Ctag%7B12%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/resnet/</guid><pubDate>Thu, 22 Jul 2021 00:00:00 +0806</pubDate></item><item><title>论文后续安排</title><link>/Blog/archives/schedule/</link><description>&lt;p&gt;&lt;strong&gt;工作安排&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先为了让模型适用于UCF101和HDM51两个数据集上，搭建baseline并测试精度&lt;/p&gt;&lt;p&gt;之后尝试经典蒸馏方法并运用到上面查看突破口，想出创新点并应用在该领域&lt;/p&gt;&lt;p&gt;创新点：连接加上权重，将所有前面feature输入并加上权重&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/schedule/</guid><pubDate>Fri, 23 Jul 2021 00:00:00 +0806</pubDate></item><item><title>github阅读</title><link>/Blog/archives/github%20HMDB51%E6%80%BB%E7%BB%93/</link><description>&lt;h2&gt;3D-CNN Method&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
  &lt;th&gt;&lt;/th&gt;
  &lt;th&gt;&lt;/th&gt;
  &lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
  &lt;td&gt;iDT&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;LRCN&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;CVPR 2015&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;LSTM composite model&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;C3D&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;2015&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;TSN&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;ECCV 2016&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;R3DCNN&lt;/td&gt;
  &lt;td&gt;NVIDIA&lt;/td&gt;
  &lt;td&gt;2016&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;P3D&lt;/td&gt;
  &lt;td&gt;MSRA&lt;/td&gt;
  &lt;td&gt;ICCV 2017&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;R3D/2.5D&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;2017&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;T3D&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;2017&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;R2+1D&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;2018&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!-- more --&gt;
&lt;p&gt;--&lt;/p&gt;&lt;hr /&gt;
&lt;p&gt;General LIb:&lt;/p&gt;&lt;p&gt;[ video model zoo (caffe2) ] &lt;a href="https://github.com/facebookresearch/VMZ"&gt;https://github.com/facebookresearch/VMZ&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Currently, this codebase supports the following models:&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;R(2+1)D, MCx models &lt;a href="https://research.fb.com/wp-content/uploads/2018/04/a-closer-look-at-spatiotemporal-convolutions-for-action-recognition.pdf"&gt;[1]&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;CSN models &lt;a href="https://arxiv.org/pdf/1904.02811.pdf"&gt;[2]&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;R(2+1)D and CSN models pre-trained on large-scale (65 million!) weakly-supervised public Instagram videos (&lt;strong&gt;IG-65M&lt;/strong&gt;) &lt;a href="https://research.fb.com/wp-content/uploads/2019/05/Large-scale-weakly-supervised-pre-training-for-video-action-recognition.pdf"&gt;[3]&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;C3D&lt;/h3&gt;
&lt;p&gt;[github caffe ]&lt;a href="https://github.com/facebook/C3D"&gt;https://github.com/facebook/C3D&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[ github tensorflow ]&lt;a href="https://github.com/hx173149/C3D-tensorflow"&gt;https://github.com/hx173149/C3D-tensorflow&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[github pytorch] &lt;a href="https://github.com/jfzhang95/pytorch-video-recognition"&gt;https://github.com/jfzhang95/pytorch-video-recognition&lt;/a&gt;&lt;/p&gt;&lt;p&gt;3x3x3  Kernel&lt;/p&gt;&lt;figure style="flex: 262.77372262773724" &gt;&lt;img width="720" height="137" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/71853e0cfa11f4c2df712fc43d7ee2f4.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure style="flex: 42.767857142857146" &gt;&lt;img width="479" height="560" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/b43d027f12bba9f3525b3e699fd0ac8f.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;P3D&lt;/h3&gt;
&lt;p&gt;[ caffe ] &lt;a href="https://github.com/ZhaofanQiu/pseudo-3d-residual-networks"&gt;https://github.com/ZhaofanQiu/pseudo-3d-residual-networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[ pytorch ] &lt;a href="https://github.com/jfzhang95/pytorch-video-recognition"&gt;https://github.com/jfzhang95/pytorch-video-recognition&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Learning spatio-temporal representation with pseudo-3d residual networks. In ICCV, 2017.&lt;/p&gt;&lt;figure style="flex: 79.02208201892745" &gt;&lt;img width="501" height="317" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/424604edeaa910b2e7f9068987cbd376.png" /&gt;&lt;figcaption&gt;1567834917557&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure style="flex: 121.82857142857142" &gt;&lt;img width="2132" height="875" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/2843da38780038aff460bbcd558bab05.png" /&gt;&lt;figcaption&gt;1567834970578&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;T3D*&lt;/h3&gt;
&lt;p&gt;Architecture: DenseNet + 3D&lt;/p&gt;&lt;p&gt;[ github pytorch] &lt;a href="https://github.com/MohsenFayyaz89/T3D"&gt;https://github.com/MohsenFayyaz89/T3D&lt;/a&gt;&lt;/p&gt;&lt;figure style="flex: 97.0059880239521" &gt;&lt;img width="648" height="334" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/8498c4f96d09598e772ad76adb771aa4.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure style="flex: 44.662921348314605" &gt;&lt;img width="477" height="534" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/c03698d9b35355fcf748ec0b723ba4bd.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Res3D/R3D&lt;/h3&gt;
&lt;p&gt;architecture:	ResNet + 3DConv&lt;/p&gt;&lt;p&gt;[github pytorch] &lt;a href="https://github.com/jfzhang95/pytorch-video-recognition"&gt;https://github.com/jfzhang95/pytorch-video-recognition&lt;/a&gt;&lt;/p&gt;&lt;figure style="flex: 59.01856763925729" &gt;&lt;img width="445" height="377" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/8150945c2e765ba0c3418c83799ad304.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure style="flex: 51.63170163170163" &gt;&lt;img width="443" height="429" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/023a150c62aa2f2fabe6010dca6c74b5.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;R2.5D&lt;/h4&gt;
&lt;figure style="flex: 59.58083832335329" &gt;&lt;img width="398" height="334" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/aa929bfe9c21b425a5c3ba07516d40c3.png" /&gt;&lt;figcaption&gt;1567836996218&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;R2+1D&lt;/h3&gt;
&lt;p&gt;[ offical video model zoo (caffe2) ] &lt;a href="https://github.com/facebookresearch/VMZ"&gt;https://github.com/facebookresearch/VMZ&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[ github PyTorch] &lt;a href="https://github.com/leftthomas/R2Plus1D-C3D"&gt;https://github.com/leftthomas/R2Plus1D-C3D&lt;/a&gt;&lt;/p&gt;&lt;figure style="flex: 49.527186761229316" &gt;&lt;img width="419" height="423" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/d9b208e0c8fd89040655af70eee8f95c.png" /&gt;&lt;figcaption&gt;Figure 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;R3DCNN&lt;/h3&gt;
&lt;p&gt;[NVIDIA]&lt;a href="https://research.nvidia.com/sites/default/files/publications/NVIDIA_R3DCNN_cvpr2016.pdf"&gt;https://research.nvidia.com/sites/default/files/publications/NVIDIA_R3DCNN_cvpr2016.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[tensorflow ]&lt;a href="https://github.com/breadbread1984/R3DCNN"&gt;https://github.com/breadbread1984/R3DCNN&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[tensorflow ] &lt;a href="https://github.com/kilsenp/R3DCNN-tensorflow"&gt;https://github.com/kilsenp/R3DCNN-tensorflow&lt;/a&gt;&lt;/p&gt;&lt;p&gt;architecture: C3D + RNN&lt;/p&gt;&lt;h3&gt;TSN&lt;/h3&gt;
&lt;p&gt;[github caffe ] &lt;a href="https://github.com/yjxiong/temporal-segment-networks"&gt;https://github.com/yjxiong/temporal-segment-networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[ caffe opensource ] &lt;a href="https://github.com/yjxiong/caffe"&gt;https://github.com/yjxiong/caffe&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[Paper] &lt;a href="https://arxiv.org/pdf/1608.00859.pdf"&gt;https://arxiv.org/pdf/1608.00859.pdf&lt;/a&gt;&lt;/p&gt;&lt;figure style="flex: 87.5" &gt;&lt;img width="1393" height="796" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/03c5b5d0c76ff8ac3419831b8c213d31.png" /&gt;&lt;figcaption&gt;1568038064174&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;I3D&lt;/h3&gt;
&lt;p&gt;Architecture: Inception base&lt;/p&gt;&lt;p&gt;[git keras ] &lt;a href="https://github.com/OanaIgnat/i3d_keras"&gt;https://github.com/OanaIgnat/i3d_keras&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[Paper ] &lt;a href="https://arxiv.org/pdf/1705.07750.pdf"&gt;https://arxiv.org/pdf/1705.07750.pdf&lt;/a&gt;&lt;/p&gt;&lt;figure style="flex: 118.86792452830188" &gt;&lt;img width="2016" height="848" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/69f472dba62bd4c9c900fd5fad1f8aeb.png" /&gt;&lt;figcaption&gt;1568037268584&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure style="flex: 97.72946859903382" &gt;&lt;img width="2023" height="1035" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/45c870c31d512a5092a0aff42829b21c.png" /&gt;&lt;figcaption&gt;1568037351528&lt;/figcaption&gt;&lt;/figure&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/github%20HMDB51%E6%80%BB%E7%BB%93/</guid><pubDate>Tue, 27 Jul 2021 00:00:00 +0806</pubDate></item><item><title>HMDB数据集</title><link>/Blog/archives/HMDB51%E5%A4%84%E7%90%86/</link><description>&lt;p&gt;&lt;strong&gt;HMDB51数据集&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;orgin HMDB51-About 2GB for a total of 7,000 clips distributed in 51 action classes。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_sta.rar"&gt;Stabilized HMDB51&lt;/a&gt; – the number of clips and classes are the same as HMDB51, but there is a mask in [video_name].form associated with each clip. The mask file is readable in matlab.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了动作标签，还有meta-label（元标签）表征片段的属性&lt;/p&gt;&lt;p&gt;各个方向的，前面，后面，左右方向的视频&lt;/p&gt;&lt;p&gt;There should be 70 videos with id 1 , 30 videos with id 2 in each txt file.&lt;/p&gt;&lt;p&gt;mask:ice_cream:：只有为1的才表征人&lt;/p&gt;&lt;p&gt;stabilized：还有matrxi表征数据集对原始图像的转换&lt;/p&gt;&lt;p&gt;accimage: accelerate image对PIL库的部分功能实现&lt;/p&gt;&lt;p&gt;hog，hof特征为处理后的光流信息特征&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.cnblogs.com/ocean1100/p/9494640.html"&gt;PyTorch载入图片后ToTensor解读（含PIL和OpenCV读取图片对比） - 木易修 - 博客园 (cnblogs.com)&lt;/a&gt;&lt;/p&gt;&lt;p&gt;totensor对于Opencv（不会除以255）和PIL.image的处理不一样&lt;/p&gt;&lt;p&gt;尝试&lt;a href="https://github.com/sebastiantiesmeyer/deeplabchop3d"&gt;GitHub - sebastiantiesmeyer/deeplabchop3d: inflated labchop kinetic net&lt;/a&gt;&lt;/p&gt;&lt;p&gt;直接复现最高精度的结果&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/HMDB51%E5%A4%84%E7%90%86/</guid><pubDate>Wed, 28 Jul 2021 00:00:00 +0806</pubDate></item><item><title>pytorch常见错误总结</title><link>/Blog/archives/pytorch%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E6%80%BB%E7%BB%93/</link><description>&lt;p&gt;&lt;strong&gt;PyTorch常见报错汇总&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;报错： ValueError: num_samples should be a positive integer value, but got num_samples=0&lt;/p&gt;&lt;p&gt;可能的原因：传入的Dataset中的len(self.data_info)==0，即传入该dataloader的dataset里没有数据&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;检查dataset中的路径，路径不对，读取不到数据。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;检查Dataset的&lt;strong&gt;len&lt;/strong&gt;()函数为何&lt;strong&gt;输出为零&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2&lt;/p&gt;&lt;p&gt;报错：TypeError: pic should be PIL Image or ndarray. Got &amp;lt;class 'torch.Tensor'&amp;gt;&lt;/p&gt;&lt;p&gt;可能的原因：当前操作需要PIL Image或ndarray数据类型，但传入了Tensor&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;检查transform中是否存在&lt;strong&gt;两次ToTensor()方法&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;检查transform中每一个操作的数据类型变化&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;3&lt;/p&gt;&lt;p&gt;报错：RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 93 and 89 in dimension 1 at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorMath.cpp:3616&lt;/p&gt;&lt;p&gt;可能的原因：dataloader的__getitem__函数中，返回的图片形状不一致，导致无法stack&lt;/p&gt;&lt;p&gt;解决方法：检查__getitem__函数中的操作&lt;/p&gt;&lt;p&gt;4&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;p&gt;conv: RuntimeError: Given groups=1, weight of size 6 1 5 5, expected input[16, 3, 32, 32] to have 1 channels, but got 3 channels instead&lt;/p&gt;&lt;p&gt;linear: RuntimeError: size mismatch, m1: [16 x 576], m2: [400 x 120] at ../aten/src/TH/generic/THTensorMath.cpp:752&lt;/p&gt;&lt;p&gt;可能的原因：网络层输入数据与网络的参数不匹配&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;检查对应网络层前后定义是否有误&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;检查输入数据shape&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;5&lt;/p&gt;&lt;p&gt;报错：AttributeError: 'DataParallel' object has no attribute 'linear'&lt;/p&gt;&lt;p&gt;可能的原因：并行运算时，模型被dataparallel包装，所有module都增加一个属性 module. 因此需要通过 net.module.linear调用&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;网络层前加入module.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;6&lt;/p&gt;&lt;p&gt;报错:&lt;/p&gt;&lt;p&gt;RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.&lt;/p&gt;&lt;p&gt;可能的原因：gpu训练的模型保存后，在无gpu设备上无法直接加载，或者内存不够了&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;需要设置map_location=&amp;quot;cpu&amp;quot;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;7&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;p&gt;AttributeError: Can't get attribute 'FooNet2' on &amp;lt;module '&lt;strong&gt;main&lt;/strong&gt;' from '&lt;/p&gt;&lt;p&gt;可能的原因：保存的网络模型在当前python脚本中没有定义&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;提前定义该类&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;8&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;p&gt;RuntimeError: Assertion `cur_target &amp;gt;= 0 &amp;amp;&amp;amp; cur_target &amp;lt; n_classes' failed. at ../aten/src/THNN/generic/ClassNLLCriterion.c:94&lt;/p&gt;&lt;p&gt;可能的原因：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;标签数大于等于类别数量，即不满足 cur_target &amp;lt; n_classes，通常是因为&lt;strong&gt;标签从1开始而不是从0开始&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;修改label，从0开始，例如：10分类的标签取值应该是0-9&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;9&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;p&gt;RuntimeError: expected device cuda:0 and dtype Long but got device cpu and dtype Long&lt;/p&gt;&lt;p&gt;Expected object of backend CPU but got backend CUDA for argument #2 'weight'&lt;/p&gt;&lt;p&gt;可能的原因：需计算的两个数据不在同一个设备上&lt;/p&gt;&lt;p&gt;解决方法：采用to函数将数据迁移到同一个设备上&lt;/p&gt;&lt;p&gt;10&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;p&gt;RuntimeError: DataLoader worker (pid 27) is killed by signal: Killed. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.&lt;/p&gt;&lt;p&gt;可能原因：内存不够（不是gpu显存，是内存）&lt;/p&gt;&lt;p&gt;解决方法：申请更大内存&lt;/p&gt;&lt;p&gt;11&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;figure style="flex: 514.2857142857143" &gt;&lt;img width="720" height="70" src="https://pic2.zhimg.com/80/v2-92824691477c695c9e7c5a6e6e6263fd_720w.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;RuntimeError: reduce failed to synchronize: device-side assert triggered&lt;/p&gt;&lt;p&gt;可能的原因：采用&lt;strong&gt;BCE损失函数的时候，input必须是0-1之间&lt;/strong&gt;，由于模型最后没有加sigmoid激活函数，导致的。&lt;/p&gt;&lt;p&gt;解决方法：让模型输出的值域在[0, 1]&lt;/p&gt;&lt;p&gt;12&lt;/p&gt;&lt;p&gt;报错：RuntimeError: unexpected EOF. The file might be corrupted.&lt;/p&gt;&lt;p&gt;torch.load加载模型过程报错，因为模型传输过程中有问题，重新传一遍模型即可&lt;/p&gt;&lt;p&gt;13&lt;/p&gt;&lt;p&gt;报错：UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 1: invalid start byte&lt;/p&gt;&lt;p&gt;可能的原因：&lt;strong&gt;python2保存，python3加载，会报错&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;解决方法：把&lt;strong&gt;encoding改为encoding='iso-8859-1'&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;check_p = torch.load(path, map_location=&amp;quot;cpu&amp;quot;, encoding='iso-8859-1')&lt;/p&gt;&lt;p&gt;14&lt;/p&gt;&lt;p&gt;报错：RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same&lt;/p&gt;&lt;p&gt;问题原因：数据张量已经转换到GPU上，但模型参数还在cpu上，造成计算不匹配问题。&lt;/p&gt;&lt;p&gt;解决方法：通过添加model.cuda()将模型转移到GPU上以解决这个问题。或者通过添加model.to(cuda)解决问题&lt;/p&gt;&lt;ol start="15"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;报错：ValueError: num_samples should be a positive integer value, but got num_samples=0&lt;/p&gt;&lt;p&gt;问题原因：高版本pytorch对于tensor.data[0]会报错，统一修改成tensor.item()&lt;/p&gt;&lt;p&gt;实验代码demo&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch&lt;/span&gt; 
&lt;span class="n"&gt;a&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;print(a.item()) 运行该行代码会报错&lt;/strong&gt;&lt;/p&gt;&lt;figure style="flex: 120.91503267973856" &gt;&lt;img width="370" height="153" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/2b1c7d53e81bc775f36bc651cb2d3632.png" /&gt;&lt;figcaption&gt;在这里插入图片描述&lt;/figcaption&gt;&lt;/figure&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/pytorch%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E6%80%BB%E7%BB%93/</guid><pubDate>Thu, 29 Jul 2021 00:00:00 +0806</pubDate></item><item><title>docker使用</title><link>/Blog/archives/docker%E4%BD%BF%E7%94%A8/</link><description>&lt;p&gt;&lt;strong&gt;docker使用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;命令：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker run -it ubuntu /bin/bash
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;参数说明：&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;-i&lt;/strong&gt;: 交互式操作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-t&lt;/strong&gt;: 终端。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ubuntu&lt;/strong&gt;: ubuntu 镜像。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;/bin/bash&lt;/strong&gt;：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要退出终端，直接输入 &lt;strong&gt;exit&lt;/strong&gt;:&lt;/p&gt;&lt;h3&gt;启动已停止运行的容器&lt;/h3&gt;
&lt;p&gt;查看所有的容器命令如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker ps -a
&lt;/code&gt;&lt;/pre&gt;
&lt;figure style="flex: 1217.1052631578948" &gt;&lt;img width="1850" height="76" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/36bdc4d66eebe31fcf823d3af0a3bbd5.png" /&gt;&lt;/figure&gt;使用 docker start 启动一个已停止的容器：
&lt;pre&gt;&lt;code&gt;$ docker start b750bbbcfd88 
&lt;/code&gt;&lt;/pre&gt;
&lt;figure style="flex: 848.3050847457627" &gt;&lt;img width="1001" height="59" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/da2e587fad6f121a93678c557f0a4ac4.png" /&gt;&lt;/figure&gt;&lt;h3&gt;后台运行&lt;/h3&gt;
&lt;p&gt;在大部分的场景下，我们希望 docker 的服务是在后台运行的，我们可以过 &lt;strong&gt;-d&lt;/strong&gt; 指定容器的运行模式。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker run -itd --name ubuntu-test ubuntu /bin/bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;点击图片查看大图：&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-run-d.png"&gt;&lt;figure style="flex: 1322.5" &gt;&lt;img width="1587" height="60" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/4735f78c70d26c666ab5c85a11a97379.png" /&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-run-d2.png"&gt;&lt;figure style="flex: 1151.9736842105262" &gt;&lt;img width="1751" height="76" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/2baa0f19820e31a07d4b9a8d0c8d5f54.png" /&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;注：&lt;/strong&gt;加了 &lt;strong&gt;-d&lt;/strong&gt; 参数默认不会进入容器，想要进入容器需要使用指令 &lt;strong&gt;docker exec&lt;/strong&gt;（下面会介绍到）。&lt;/p&gt;&lt;h3&gt;停止一个容器&lt;/h3&gt;
&lt;p&gt;停止容器的命令如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker stop &amp;lt;容器 ID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;figure style="flex: 910.0" &gt;&lt;img width="1001" height="55" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-stop-1.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;停止的容器可以通过 docker restart 重启：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker restart &amp;lt;容器 ID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;figure style="flex: 862.9310344827586" &gt;&lt;img width="1001" height="58" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-stop-2.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;进入容器&lt;/h3&gt;
&lt;p&gt;在使用 &lt;strong&gt;-d&lt;/strong&gt; 参数时，容器启动后会进入后台。此时想要进入容器，可以通过以下指令进入：&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;docker attach&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;docker exec&lt;/strong&gt;：推荐大家使用 docker exec 命令，因为此退出容器终端，不会导致容器的停止。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;attach 命令&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下面演示了使用 docker attach 命令。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker attach 1e560fca3906 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-attach.png"&gt;&lt;figure style="flex: 232.69230769230768" &gt;&lt;img width="1573" height="338" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-attach.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 如果从这个容器退出，会导致容器的停止。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;exec 命令&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下面演示了使用 docker exec 命令。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker exec -it 243c32535da7 /bin/bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-exec.png"&gt;&lt;figure style="flex: 247.64150943396226" &gt;&lt;img width="1575" height="318" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-exec.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 如果从这个容器退出，容器不会停止，这就是为什么推荐大家使用 &lt;strong&gt;docker exec&lt;/strong&gt; 的原因。&lt;/p&gt;&lt;p&gt;更多参数说明请使用 &lt;strong&gt;docker exec --help&lt;/strong&gt; 命令查看。&lt;/p&gt;&lt;h3&gt;导出和导入容器&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;导出容器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果要导出本地某个容器，可以使用 &lt;strong&gt;docker export&lt;/strong&gt; 命令。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker export 1e560fca3906 &amp;gt; ubuntu.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;导出容器 1e560fca3906 快照到本地文件 ubuntu.tar。&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-export.png"&gt;&lt;figure style="flex: 280.7142857142857" &gt;&lt;img width="1572" height="280" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-export.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这样将导出容器快照到本地文件。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;导入容器快照&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;可以使用 docker import 从容器快照文件中再导入为镜像，以下实例将快照文件 ubuntu.tar 导入到镜像 test/ubuntu:v1:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat docker/ubuntu.tar | docker import - test/ubuntu:v1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-import.png"&gt;&lt;figure style="flex: 232.36607142857142" &gt;&lt;img width="1041" height="224" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-import.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;此外，也可以通过指定 URL 或者某个目录来导入，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker import http://example.com/exampleimage.tgz example/imagerepo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;删除容器&lt;/h3&gt;
&lt;p&gt;删除容器使用 &lt;strong&gt;docker rm&lt;/strong&gt; 命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker rm -f 1e560fca3906
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-container-rmi.png"&gt;&lt;figure style="flex: 247.16981132075472" &gt;&lt;img width="1572" height="318" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-container-rmi.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;下面的命令可以清理掉所有处于终止状态的容器。&lt;/p&gt;&lt;p&gt;$ docker container prune&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;nvidia-docker run -it --name&lt;span class="o"&gt;=&lt;/span&gt;容器名 -v 宿主机目录:/容器内目录 -p 自定义端口号（此处假定为23333）:22 ufoym/deepo bash
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;镜像ufoym/deepo&lt;/p&gt;&lt;p&gt;-v是实现目录挂载，关于目录挂载，-p是端口映射，映射成功后可以直接通过映射后的端口访问docker。&lt;/p&gt;&lt;p&gt;举例：&lt;/p&gt;&lt;p&gt;假设服务器IP地址为** . ** . *. ***，端口映射为 -p 23333:22  -p 23334:6006  -p 23335:8888，其中8888是jupyter的默认端口，6006是tensorboard的默认端口。则可&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;通过IP地址的23333端口可以直接访问docker，无需通过22端口进入服务器，再在服务器中进入docker&lt;/li&gt;
&lt;li&gt;同一网段内的任意浏览器都可以通过 IP地址:6006来访问tensorboard（前提：已开启tensorboard服务）&lt;/li&gt;
&lt;li&gt;同一网段内的任意浏览器都可以通过 IP地址:8888来访问jupyter（前提：已开启jupyter服务）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果要在主机（计算机或VM）与使用Deepo的容器之间共享数据和配置，请使用-v选项，例如&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;nvidia-docker run -it -v /host/data:/data -v /host/config:/config ufoym/deepo bash
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;某些框架（例如PyTorch）使用共享内存在进程之间共享数据，因此如果使用多处理，容器运行的默认共享内存段大小是不够的，您应该使用&lt;code&gt;--ipc=host&lt;/code&gt;或&lt;code&gt;--shm-size&lt;/code&gt;命令行选项增加共享内存大小到&lt;code&gt;nvidia-docker run&lt;/code&gt;。&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;nvidia-docker run -it --ipc&lt;span class="o"&gt;=&lt;/span&gt;host ufoym/deepo bash
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;共享内存参数&lt;/h4&gt;
&lt;p&gt;shmmax:共享内存段最大尺寸(字节)
shmmni:共享内存段最大数目
shmall:系统共享内存最大尺寸(页), 对32位系统，一页(page)等于4KB
shmmin:共享内存段最小尺寸(字节)
shmseg:每进程最大共享内存段数量&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--ipc=&amp;quot;MODE&amp;quot; : Set the IPC mode for the container

&amp;quot;shareable&amp;quot;: Own private IPC namespace, with a possibility to share it with other containers.

&amp;quot;host&amp;quot;: Use the host system’s IPC namespace.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用host将IPC名称空间公开给控制了主机的攻击者。使用shareable，只能在容器内部访问IPC名称空间，其中可能包含任何攻击。 host模式的存在是为了允许容器与其主机之间进行协作。&lt;/p&gt;&lt;p&gt;--shm-size命令：设置共享内存，shared memory&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/docker%E4%BD%BF%E7%94%A8/</guid><pubDate>Fri, 30 Jul 2021 00:00:00 +0806</pubDate></item><item><title>追踪基本知识</title><link>/Blog/archives/%E8%BF%BD%E8%B8%AA%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</link><description>&lt;p&gt;&lt;strong&gt;object detection&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Region Proposal Network，直接翻译是“&lt;strong&gt;区域生成网络&lt;/strong&gt;”，通俗讲是“筛选出可能会有目标的框”。其本质是基于滑窗的无类别object检测器，输入是任意尺度的图像，输出是一系列矩形候选区域。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;BEV(Bird's Eye View) Map&lt;/strong&gt;：bev视角，鸟瞰视角&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/%E8%BF%BD%E8%B8%AA%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</guid><pubDate>Sun, 01 Aug 2021 00:00:00 +0806</pubDate></item><item><title>CNN理解</title><link>/Blog/archives/CNN/</link><description>&lt;p&gt;&lt;strong&gt;CNN&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;卷积时channel 的意义：每个卷积核提取一个特征，多个卷积核提取多层特征&lt;/p&gt;&lt;hr /&gt;
&lt;p&gt;事实上，当输入为图片或者feature map 时，池化层、非线性激活层、Batch Normalization 等层的输出也可以称作feature map 。卷积神经网络中，非全连接层、输出层以外的几乎所有层的输出都可以称作feature map 。&lt;/p&gt;&lt;hr /&gt;
&lt;p&gt;填充：为了让输入尺寸不变，填充，卷积核大小减一&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;valid 填充：&lt;/p&gt;&lt;p&gt;不使用零来填充输入，卷积核只允许访问那些图像中能完全包含整个核的位置。
 在valid 填充模式中，输出的大小在每一层都缩减。假设核的宽度是 k，则每经过一层，输出的宽度减少了 k-1。
 如果输入图像的宽度是m ，则网络经过了d 层之后，输出的宽度变成 m- d*（k-1） 。如果核的宽度 k非常大时，缩减非常明显。最终网络会缩减到 1 。&lt;/p&gt;&lt;figure style="flex: 87.5" &gt;&lt;img width="420" height="240" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/8b6e80ce37493c55e3ec94d93db836d9.png" /&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;same 填充：&lt;/p&gt;&lt;p&gt;使用足够的零来填充，使得输出和输入保持相同的大小。这是最常见的填充方式。&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;在same填充模式中，网络可以包含任意多的卷积层，因为它不存在网络输出宽度缩减的问题。&lt;/li&gt;
&lt;li&gt;same 填充模式的一个问题是：输入的边缘单元可能存在一定程度上的欠表达。
因为==输入的中间区域的单元的影响域为全部的输出单元==，这意味着这些输入单元的信息会被很多输出单元所编码。而输入的边缘区域的单元的影响域只是输出单元的一部分，这意味着这些输入单元的信息仅仅被少量输出单元所编码。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure style="flex: 86.76470588235294" &gt;&lt;img width="590" height="340" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/5fff5357026356e9a1415c3af7968767.png" /&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;full 填充：&lt;/p&gt;&lt;p&gt;在输入的两端各填充K-1个零，使得每个输入单元都恰好被卷积核访问k次。其中k为卷积核的宽度。&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;它将从卷积核和输入开始相交的时候开始做卷积。&lt;/li&gt;
&lt;li&gt;假设核的宽度是k  ，则每经过一层，输出的宽度增加了 k-1 。
如果输入图像的宽度是 m ，则网络经过了 d 层之后，输出的宽度变成 m+d*(k-1) 。&lt;/li&gt;
&lt;li&gt;它使得输入的边缘单元也能够得到充分表达。&lt;/li&gt;
&lt;li&gt;full 填充的一个问题是：输出的边界单元依赖于更少的输入单元。
这使得学习到的结果在输出的中间部分表现较好，边缘部分的表现较差。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;figure style="flex: 125.0" &gt;&lt;img width="900" height="360" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/850cc76eb7f422bd1d237e696d3d8f73.png" /&gt;&lt;/figure&gt;&lt;p&gt;每个图像的像素位置当作一个输入单元，只影响3个输出单元（核尺寸为3时）&lt;/p&gt;&lt;figure style="flex: 181.0" &gt;&lt;img width="905" height="250" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/cd93b7c4653c12a861afa1a7cbddc137.png" /&gt;&lt;/figure&gt;&lt;p&gt;池化对结果的影响：如果不关注特征出现的位置，采用具有平移特性的池化，只要出现这个特征就可以了，像人脸识别，而对于直线相交，需要判断位置&lt;/p&gt;&lt;p&gt;下图中，使用多个滤波器和一个最大池化单元可以学得旋转不变性。&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;当输入旋转某个角度时，对应的滤波器被激活。&lt;/li&gt;
&lt;li&gt;只要任意一个过滤器被激活，最大池化单元也相应被激活。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure style="flex: 176.58450704225353" &gt;&lt;img width="1003" height="284" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/782eefbf5954de5c6d1b763106a1572d.png" /&gt;&lt;/figure&gt;&lt;p&gt;全连接层转卷积层的优点：可以适应尺寸多变的输入图像。&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;如果是全连接层，则全连接层的输入大小是固定的。&lt;/li&gt;
&lt;li&gt;如果网络的输入尺寸发生变化，则该变化会传递到全连接层，而全连接层无法处理可变的输入。&lt;/li&gt;
&lt;li&gt;如果是卷积层，则它对输入大小没有限制。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure style="flex: 119.31818181818181" &gt;&lt;img width="1050" height="440" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/9af77b8d628e228135af82a14593fc86.png" /&gt;&lt;/figure&gt;&lt;p&gt;全卷积网络&lt;code&gt;FCN&lt;/code&gt; 就是将&lt;code&gt;CNN&lt;/code&gt; 网络后面的几个全连接层替换为卷积层，它可以高效的对测试图像做滑动窗口式的预测。&lt;/p&gt;&lt;p&gt;小卷积层堆叠的缺点是：加深了网络的深度，容易引发梯度消失等问题，从而使得网络的训练难度加大。&lt;/p&gt;&lt;p&gt;​	图像中目标对象的大小可能差别很大。如下图所示，每张图像中狗占据区域都是不同的。由于信息区域的巨大差异，为卷积操作选择合适的卷积核尺寸就非常困难。&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;信息分布更具有全局性的图像中，更倾向于使用较大的卷积核。如最最侧的图片所示。&lt;/li&gt;
&lt;li&gt;信息分布更具有局部性的图像中，更倾向于使用较小的卷积核。如最右侧的图片所示。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure style="flex: 148.14814814814815" &gt;&lt;img width="720" height="243" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/1f685a29808dc8adc34faca390129c09.jpg" /&gt;&lt;/figure&gt;&lt;p&gt;Inception网络中大量使用多尺寸卷积核拼接在一起无论感兴趣的信息区域尺寸多大，总有一种尺度的卷积核与之匹配。这样总可以提取到合适的特征。&lt;/p&gt;&lt;figure style="flex: 77.5" &gt;&lt;img width="1147" height="740" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/5d5e3f88ec5703de49d11742da4cb048.png" /&gt;&lt;/figure&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/CNN/</guid><pubDate>Fri, 06 Aug 2021 00:00:00 +0806</pubDate></item></channel></rss>