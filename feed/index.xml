<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>我的个人博客</title><link>/Blog/</link><description>记录生活美好</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/f-logo.png</url><title>我的个人博客</title><link>/Blog/</link></image><language>zh-CN</language><lastBuildDate>Mon, 29 Nov 2021 08:54:41 +0806</lastBuildDate><pubDate>Mon, 29 Nov 2021 08:54:41 +0806</pubDate><item><title>blender script使用</title><link>/Blog/archives/blender_script/</link><description>&lt;p&gt;&lt;strong&gt;blender script&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;将blender中所有的button转换为代码接口，操纵物体&lt;/p&gt;&lt;p&gt;重要学习数据类型：bpy&lt;/p&gt;&lt;p&gt;bpy.data.object：打开的模型物体&lt;/p&gt;&lt;p&gt;Data is added and removed via methods on the collections in &lt;a href="https://docs.blender.org/api/current/bpy.data.html#module-bpy.data"&gt;&lt;code&gt;bpy.data&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;“poll” function which checks if the cursor is in a valid area or if the object is in the correct mode ：判断是否选择正确的操作方式&lt;/p&gt;&lt;p&gt;blender文件夹下scripts/startup/中有python的环境&lt;/p&gt;&lt;p&gt;When a script is imported as a module, its class instances will remain inside the module and can be accessed later on by importing that module again.&lt;/p&gt;&lt;p&gt;run the script：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;blender --python /home/me/my_script.py&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;While &lt;code&gt;__init__()&lt;/code&gt; and &lt;code&gt;__del__()&lt;/code&gt; will be called if defined, the class instances lifetime only spans the execution.&lt;/p&gt;&lt;p&gt;数据保存为blender.data的格式，下次开启不会丢失&lt;/p&gt;&lt;p&gt;The register/unregister calls are used so it’s possible to toggle add-ons and reload scripts while Blender runs&lt;/p&gt;&lt;p&gt;每次重新跑，估计得重新加载选项&lt;/p&gt;&lt;p&gt;run script&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Loaded in the text editor and press &lt;em&gt;Run Script&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Typed or pasted into the interactive console.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Execute a Python file from the command line with Blender, e.g:&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;blender --python /home/me/my_script.py
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;建立子类，元素命名一般以bl_开头表示自己添加的&lt;/p&gt;&lt;p&gt;Notice these classes don’t define an &lt;code&gt;__init__(self)&lt;/code&gt; function. While &lt;code&gt;__init__()&lt;/code&gt; and &lt;code&gt;__del__()&lt;/code&gt; will be called if defined, the class instances lifetime only spans the execution&lt;/p&gt;&lt;p&gt;&lt;strong&gt;步骤&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;定义Panel面板&lt;/h2&gt;
&lt;p&gt;创建类&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TestPanel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;types&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Panel&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#创建Panel的实例&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;定义Panel类的属性&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TestPanel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;types&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Panel&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;bl_label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;LuoZhiXiang&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;bl_idname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;PT_Test Panel&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;bl_space_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;VIEW_3D&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;bl_region_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;UI&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;bl_category&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;BadGuy&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;#注意前面一定要带有bl_的前缀，否则是会报错的&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;创建Space Type （插件在哪种工作空间使用）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;注意全部要大写！它的作用就是定义这个插件是作用于哪个工作区域Workspace内。&lt;/p&gt;&lt;p&gt;可以切换测试，日志会输出相关type。&lt;/p&gt;&lt;figure style="flex: 127.63157894736842" &gt;&lt;img width="291" height="114" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/b4ecbc125d6216fc415bd62a91305102.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bl_space_type=&amp;quot;VIEW_3D&amp;quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;figure style="flex: 60.301507537688444" &gt;&lt;img width="720" height="597" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/f0a3975b5c50d3ceecb0d6e7f3ae1f78.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;设置使用区域，设置为UI即可&lt;/strong&gt;&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bl_region_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;UI&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其他种类：&lt;/p&gt;&lt;figure style="flex: 63.45609065155807" &gt;&lt;img width="448" height="353" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/5b20d1e58bc9c39cc00db43fd5941a14.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;设置&lt;strong&gt;归属类别&lt;/strong&gt;（将此Panel实例归到哪一类里面）&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bl_category&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;BadGuy&amp;quot;&lt;/span&gt; &lt;span class="c1"&gt;#SideBar Name&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;figure style="flex: 60.0" &gt;&lt;img width="720" height="600" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/3637e44f4b800e75bee53cac4372ac07.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;h1&gt;加载更新&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;register() 注册/登记/加载&lt;/li&gt;
&lt;li&gt;unregister() 不加载&lt;/li&gt;
&lt;li&gt;utils——utilities（实用工具）&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def register():
    bpy.utils.register_class(TestPanel)

def unregister():
    bpy.utils.unregister_class(TestPanel）

if __name__==&amp;quot;__main__&amp;quot;:
    register()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过直接执行脚本来扩展Blender意味着脚本完成执行后脚本定义的类在Blender中保持可用。与将脚本作为模块导入相比，以这种方式使用脚本使得将来访问其类（例如取消注册它们）变得更加困难。将脚本作为模块导入时，其类实例将保留在模块中，稍后可以通过再次导入该模块来访问。&lt;/p&gt;&lt;p&gt;bpy.data.objects返回值，第0个默认为camera，注意区别&lt;/p&gt;&lt;p&gt;输入：bpy.data.objects[0]&lt;/p&gt;&lt;p&gt;结果返回：bpy.data.objects['Camera']&lt;/p&gt;&lt;p&gt;输入：bpy.data.objects[1]&lt;/p&gt;&lt;p&gt;结果返回：bpy.data.objects['Cube']&lt;/p&gt;&lt;p&gt;blender中shapekey类似于material，是指向某个值，感觉跟指针一样，注意copy&lt;/p&gt;&lt;p&gt;所以copy obj的同时也应该copy shapekey&lt;/p&gt;&lt;p&gt;可以新建collection&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/blender_script/</guid><pubDate>Tue, 19 Oct 2021 00:00:00 +0806</pubDate></item><item><title>Matlab学习</title><link>/Blog/archives/matlab%E8%AF%AD%E6%B3%95/</link><description>&lt;p&gt;&lt;strong&gt;matlab学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;clc：清除命令窗口的内容，对工作环境中的全部变量无任何影响
close：关闭当前的Figure窗口
close all:关闭所有的Figure窗口
clear：清除工作空间的所有变量
clear all：清除工作空间的所有变量，函数，和MEX文件&lt;/p&gt;&lt;p&gt;grid on；写一次就可以打开网格&lt;/p&gt;&lt;p&gt;%.*对应元素相乘， *是矩阵相乘&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/matlab%E8%AF%AD%E6%B3%95/</guid><pubDate>Tue, 19 Oct 2021 00:00:00 +0806</pubDate></item><item><title>泰迪熊</title><link>/Blog/archives/Teddy%20Bear/</link><description>&lt;p&gt;&lt;strong&gt;Teddy Bear&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从小陪伴到大的朋友，却一起养成了坏习惯，这让自己一事无成，没有办法去承担自己应该承担的东西，最后还差一点无法守护自己的朋友。&lt;/p&gt;&lt;p&gt;面对爱情一味的去改变自己的生活，却不是自己真正的想要去改变，只是自己认为自己爱对方，所以就可以为了对方改变自己的一切行为。&lt;/p&gt;&lt;p&gt;我认为你应该有足够的能力去承担这个角色所应该有的责任，在困苦时，找到属于两个人共同的解决方法，不顾一切的去勇往直前（这是我想象的未来的相处方式）。&lt;/p&gt;&lt;p&gt;你可以同时是大人和小孩，有大人的成熟和小孩内心最坚强的陪伴。&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/Teddy%20Bear/</guid><pubDate>Tue, 26 Oct 2021 00:00:00 +0806</pubDate></item><item><title>pytorch基础教程</title><link>/Blog/archives/base%20pytorch/</link><description>&lt;p&gt;&lt;strong&gt;pytorch基础教程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;tensors是一种特殊的数据类型和arrays，matrices类似。用tensors编码代替input和output，还有模型参数。&lt;/p&gt;&lt;h1&gt;创建初始化方式&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;通过data生成torch.tensor(data)，这时类型自动推断，和data中类型一致&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;从numpy array&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;np_array&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x_np&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_numpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np_array&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="3"&gt;
&lt;li&gt;&lt;p&gt;从另一个tensor&lt;/p&gt;&lt;p&gt;隐式地保持类型一致&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x_ones&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones_like&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# retains the properties of x_data&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Ones Tensor: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x_ones&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;x_rand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand_like&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# overrides the datatype of x_data&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Random Tensor: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x_rand&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="4"&gt;
&lt;li&gt;调用函数&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;shape要是tensor维度的tuple&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,)&lt;/span&gt;
&lt;span class="n"&gt;rand_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ones_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;zeros_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Random Tensor: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;rand_tensor&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Ones Tensor: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;ones_tensor&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Zeros Tensor: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;zeros_tensor&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;tensor属性&lt;/h1&gt;
&lt;p&gt;tensor.shape,tensor.dtype（datatype的缩写）,torch.device&lt;/p&gt;&lt;h1&gt;tensor数学运算&lt;/h1&gt;
&lt;p&gt;transposing, indexing, slicing, mathematical operations, linear algebra, random sampling, and more are comprehensively described &lt;a href="https://pytorch.org/docs/stable/torch.html"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;tensor.to(‘cuda’)还可以显式在定义时指定device=torch.device(“cuda”)&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;和numpy一样的切片操作&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;用torch.cat拼接tensor（torch.stack用的较少），torch.cat可以指定维度&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;乘法，对应位置相乘&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# This computes the element-wise product&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;tensor.mul(tensor) &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Alternative syntax:&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;tensor * tensor &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="4"&gt;
&lt;li&gt;矩阵乘法&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;tensor.matmul(tensor.T) &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Alternative syntax:&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;tensor @ tensor.T &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="4"&gt;
&lt;li&gt;替代修改操作&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Operations that have a &lt;code&gt;_&lt;/code&gt; suffix are in-place. For example: &lt;code&gt;x.copy_(y)&lt;/code&gt;, &lt;code&gt;x.t_()&lt;/code&gt;, will change &lt;code&gt;x&lt;/code&gt;.&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;5.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;5.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;5.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;5.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;in_place操作会节省内存，但是求导时会报错，故不鼓励使用&lt;/p&gt;&lt;h2&gt;Bridge with NumPy&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;t: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;n: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;t: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;n: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="err"&gt;：&lt;/span&gt;
&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;两者会同时修改，潜在的空间一样&lt;/p&gt;&lt;h1&gt;&lt;code&gt;TORCH.AUTOGRAD&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Forward Propagation&lt;/strong&gt;: 产生最佳最正确的输出&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Backward Propagation&lt;/strong&gt;: 调整它的参数根据生成的error&lt;/p&gt;&lt;p&gt;i.e.:&lt;strong&gt;abbr.&lt;/strong&gt;亦即（源自拉丁文 id est）&lt;/p&gt;&lt;p&gt;w.r.t. :with respect to，相对某一方面而言&lt;/p&gt;&lt;p&gt;backward后会把loss值free，如果loss不是标量，需要指定gradient&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;3.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;requires_grad&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;4.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;requires_grad&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;Q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="n"&gt;external_grad&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;Q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;external_grad&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;directed acyclic graph (DAG)有向无环图，leaves are the input tensors, roots are the output tensors.倒过来的树，从root跟踪到leaves自动计算梯度&lt;/p&gt;&lt;p&gt;&lt;strong&gt;frozen parameters&lt;/strong&gt;：用来微调模型参数&lt;/p&gt;&lt;h1&gt;NEURAL NETWORKS&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Define the neural network that has some learnable parameters (or weights)&lt;/li&gt;
&lt;li&gt;Iterate over a dataset of inputs&lt;/li&gt;
&lt;li&gt;Process input through the network&lt;/li&gt;
&lt;li&gt;Compute the loss (how far is the output from being correct)&lt;/li&gt;
&lt;li&gt;Propagate gradients back into the network’s parameters&lt;/li&gt;
&lt;li&gt;Update the weights of the network, typically using a simple update rule: &lt;code&gt;weight = weight - learning_rate * gradient&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;torch.Tensor&lt;/code&gt; - A &lt;em&gt;multi-dimensional array&lt;/em&gt; with support for autograd operations like &lt;code&gt;backward()&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;code&gt;nn.Module&lt;/code&gt;-封装好的类，方便move到GPU上&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grad_fn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# MSELoss&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grad_fn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_functions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# Linear&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grad_fn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_functions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_functions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# ReLU&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这样可以观察计算图&lt;/p&gt;&lt;p&gt;每次backward前，把计算图梯度清零，否则每次会积累&lt;/p&gt;&lt;h1&gt;数据处理&lt;/h1&gt;
&lt;p&gt;首先导入为ndarray，然后转换为torch.*Tensor&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/base%20pytorch/</guid><pubDate>Tue, 26 Oct 2021 00:00:00 +0806</pubDate></item><item><title>归一化</title><link>/Blog/archives/%E5%BD%92%E4%B8%80%E5%8C%96/</link><description>&lt;p&gt;&lt;strong&gt;归一化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;sigmoid和softmax函数区别&lt;/p&gt;&lt;h2&gt;分类问题&lt;/h2&gt;
&lt;h3&gt;&lt;strong&gt;1 Sigmoid函数&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Sigmoid =&lt;strong&gt;多标签分类问题&lt;/strong&gt;=多个正确答案=非独占输出（例如胸部X光检查、住院）。构建分类器，解决有多个正确答案的问题时，用Sigmoid函数分别处理各个原始输出值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Sigmoid函数&lt;/strong&gt;是一种logistic函数，它将任意的值转换到$[0,1]$之间，如图1所示，函数表达式为：$Sigmoid = \frac{1}{1 + e^{-x}}$ 。&lt;/p&gt;&lt;p&gt;它的导函数为： $Sigmoid'(x) = Sigmoid(x)*(1-Sigmoid(x))$。&lt;/p&gt;&lt;figure style="flex: 74.94145199063232" &gt;&lt;img width="640" height="427" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/b3c2cbcc5704847d6d9042143cb7401f.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;​																									图1：Sigmoid函数&lt;/p&gt;&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：1. Sigmoid函数的输出在(0,1)之间，输出范围有限，优化稳定，可以用作输出层。2. 连续函数，便于求导。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;：1. 最明显的就是饱和性，从上图也不难看出其两侧导数逐渐趋近于0，容易造成梯度消失。2.==激活函数的偏移现象==。Sigmoid函数的输出值均大于0，使得输出==不是0的均值==，这会导致后一层的神经元将得到上一层非0均值的信号作为输入，这会对梯度产生影响。 3. 计算复杂度高，因为Sigmoid函数是指数形式。&lt;/p&gt;&lt;h3&gt;2 Softmax函数&lt;/h3&gt;
&lt;p&gt;Softmax =&lt;strong&gt;多类别分类问题&lt;/strong&gt;=只有一个正确答案=互斥输出（例如手写数字，鸢尾花）。构建分类器，解决只有唯一正确答案的问题时，用Softmax函数处理各个原始输出值。Softmax函数的分母综合了原始输出值的所有因素，这意味着，Softmax函数得到的不同概率之间相互关联。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Softmax函数&lt;/strong&gt;，又称归一化指数函数，函数表达式为：$Softmax = \frac{e^{x_i}}{\sum_{j=1}^{n}e^{x_j}}$。&lt;/p&gt;&lt;figure style="flex: 89.33002481389578" &gt;&lt;img width="720" height="403" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/dc924cfae91bbe8d50b7de43d9d5dfed.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;​																				图2：Softmax函数计算过程&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Softmax函数是二分类函数Sigmoid在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。&lt;/strong&gt;如图2所示，Softmax直白来说就是将原来输出是3,1,-3通过Softmax函数一作用，就映射成为(0,1)的值，而这些值的累和为1（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标。&lt;/p&gt;&lt;p&gt;由于Softmax函数先拉大了输入向量元素之间的差异（通过指数函数），然后才归一化为一个概率分布，在应用到分类问题时，它使得各个类别的概率差异比较显著，最大值产生的概率更接近1，这样输出分布的形式更接近真实分布。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Softmax可以由三个不同的角度来解释。从不同角度来看softmax函数，可以对其应用场景有更深刻的理解：&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;softmax可以当作arg max的一种平滑近似，与arg max操作中暴力地选出一个最大值（产生一个one-hot向量）不同，softmax将这种输出作了一定的平滑，即将one-hot输出中最大值对应的1按输入元素值的大小分配给其他位置。&lt;/li&gt;
&lt;li&gt;softmax将输入向量归一化映射到一个类别概率分布，即 个类别上的概率分布（前文也有提到）。这也是为什么在深度学习中常常将softmax作为MLP的最后一层，并配合以交叉熵损失函数（对分布间差异的一种度量)。&lt;/li&gt;
&lt;li&gt;从概率图模型的角度来看，softmax的这种形式可以理解为一个概率无向图上的联合概率。因此你会发现，条件最大熵模型与softmax回归模型实际上是一致的，诸如这样的例子还有很多。由于概率图模型很大程度上借用了一些热力学系统的理论，因此也可以从物理系统的角度赋予softmax一定的内涵。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;3 总结&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;如果模型输出为非互斥类别，且可以同时选择多个类别，则采用Sigmoid函数计算该网络的原始输出值。&lt;/li&gt;
&lt;li&gt;如果模型输出为互斥类别，且只能选择一个类别，则采用Softmax函数计算该网络的原始输出值。&lt;/li&gt;
&lt;li&gt;Sigmoid函数可以用来解决多标签问题，Softmax函数用来解决单标签问题。&lt;a href="https://zhuanlan.zhihu.com/p/356976844#ref_1"&gt;[1]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;对于某个分类场景，当Softmax函数能用时，Sigmoid函数一定可以用。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;4. 二分类任务&lt;/h3&gt;
&lt;p&gt;对于二分类问题来说，&lt;strong&gt;理论上，两者是没有任何区别的。&lt;/strong&gt;由于我们现在用的Pytorch、TensorFlow等框架计算矩阵方式的问题，导致两者在反向传播的过程中还是有区别的。实验结果表明，两者还是存在差异的，对于不同的分类模型，可能Sigmoid函数效果好，也可能是Softmax函数效果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;首先我们先理论上证明一下二者没有本质上的区别&lt;/strong&gt;，对于二分类而言（以输入$x_1$为例)：&lt;/p&gt;&lt;p&gt;Sigmoid函数： $output(x_1)=\frac{1}{1+e^{-x_1}} (1)$&lt;/p&gt;&lt;p&gt;Softmax函数： $output(x_2)=\frac{e^{-x_1}}{e^{-x_1}+e^{-x_2}} (2)$&lt;/p&gt;&lt;p&gt;由公式（2）我们可知， $x_1-x_2$可以用$z_1$代替，即Softmax函数可以写成：  $output(z_1)=\frac{1}{1+e^{-z_1}} $，和公式（1)完全相同，所以理论上来说两者是没有任何区别的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;然后我们再分析为什么两者之间还存着差异（以Pytorch为例）：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先我们要明白，当你用Sigmoid函数的时候，你的最后一层全连接层的神经元个数为1，而当你用Softmax函数的时候，你的最后一层全连接层的神经元个数是2。这个很好理解，因为Sigmoid函数只有是目标和不是目标之分，实际上只存在一类目标类，另外一个是背景类。而Softmax函数将目标分类为了二类，所以有两个神经元。这也是导致两者存在差异的主要原因。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Sigmoid函数&lt;/strong&gt;针对两点分布提出。神经网络的输出经过它的转换，可以将数值压缩到(0,1)之间，得到的结果可以理解成&lt;strong&gt;分类成目标类别的概率P，而不分类到该类别的概率是(1 - P)&lt;/strong&gt;，这也是典型的两点分布的形式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Softmax函数&lt;/strong&gt;本身针对多项分布提出，当类别数是2时，它退化为二项分布。而它和Sigmoid函数真正的区别就在——二项分布包含两个分类类别（姑且分别称为A和B），而两点分布其实是针对一个类别的概率分布，其对应的那个类别的分布直接由1-P得出。&lt;/p&gt;&lt;p&gt;简单点理解就是，&lt;strong&gt;Sigmoid函数，我们可以当作成它是对一个类别的“建模”&lt;/strong&gt;，将该类别建模完成，另一个相对的类别就直接通过1减去得到。&lt;strong&gt;而softmax函数，是对两个类别建模&lt;/strong&gt;，同样的，得到两个类别的概率之和是1。&lt;/p&gt;&lt;p&gt;神经网络在做二分类时，使用Softmax还是Sigmoid，做法其实有明显差别。由于Softmax是对两个类别（正反两类，通常定义为0/1的label）建模，所以对于NLP模型而言（比如泛BERT模型），Bert输出层需要通过一个nn.Linear()全连接层压缩至2维，然后接Softmax（Pytorch的做法，就是直接接上torch.nn.CrossEntropyLoss）；而Sigmoid只对一个类别建模（通常就是正确的那个类别），所以Bert输出层需要通过一个nn.Linear()全连接层压缩至1维，然后接Sigmoid（torch就是接torch.nn.BCEWithLogitsLoss）。&lt;/p&gt;&lt;p&gt;总而言之，Sotfmax和Sigmoid确实在二分类的情况下可以化为相同的数学表达形式，但并不意味着二者有一样的含义，而且二者的输入输出都是不同的。Sigmoid得到的结果是“分到正确类别的概率和未分到正确类别的概率”，Softmax得到的是“分到正确类别的概率和分到错误类别的概率”。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一种常见的错法（NLP中）：&lt;/strong&gt;即错误地将Softmax和Sigmoid混为一谈，再把BERT输出层压缩至2维的情况下，却用Sigmoid对结果进行计算。这样我们得到的结果其意义是什么呢？&lt;/p&gt;&lt;p&gt;假设我们现在BERT输出层经nn.Linear()压缩后，得到一个二维的向量：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[-0.9419267177581787, 1.944047451019287]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;对应类别分别是(0,1)。我们经过Sigmoid运算得到：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tensor([0.2805, 0.8748])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;前者0.2805指的是分类类别为0的概率，0.8748指的是分类类别为1的概率。二者相互独立，可看作两次独立的实验（显然在这里不适用，因为0-1类别之间显然不是相互独立的两次伯努利事件）。所以显而易见的，二者加和并不等于1。&lt;/p&gt;&lt;p&gt;若用softmax进行计算，可得：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tensor([0.0529, 0.9471])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里两者加和是1，才是正确的选择。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;经验：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对于NLP而言&lt;/strong&gt;，这两者之间确实有差别，Softmax的处理方式有时候会比Sigmoid的处理方式好一点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对于CV而言&lt;/strong&gt;，这两者之间也是有差别的，Sigmoid的处理方式有时候会比Softmax的处理方式好一点。&lt;/p&gt;&lt;p&gt;两者正好相反，这只是笔者的实验经验，建议大家两者都试试。&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/%E5%BD%92%E4%B8%80%E5%8C%96/</guid><pubDate>Sun, 31 Oct 2021 00:00:00 +0806</pubDate></item><item><title>dataloader</title><link>/Blog/archives/model.train/</link><description>&lt;p&gt;&lt;strong&gt;dataloader&lt;/strong&gt;&lt;/p&gt;&lt;h1&gt;参数含义&lt;/h1&gt;
&lt;p&gt;1、dataset：（数据类型 dataset）&lt;/p&gt;&lt;p&gt;输入的数据类型。看名字感觉就像是数据库，C#里面也有dataset类，理论上应该还有下一级的datatable。这应当是原始数据的输入。PyTorch内也有这种数据结构。这里先不管，估计和C#的类似，这里只需要知道是输入数据类型是dataset就可以了。&lt;/p&gt;&lt;p&gt;dataset分为两类：&lt;/p&gt;&lt;h3&gt;Map-style datasets&lt;/h3&gt;
&lt;p&gt;需要完成__getitem__()&lt;code&gt;and&lt;/code&gt;__len__()函数，可以通过dataset[idx]调用数据&lt;/p&gt;&lt;h3&gt;Iterable-style datasets&lt;/h3&gt;
&lt;p&gt;完成__iter__()，这适用于无法shuffle，只可以通过依次调用，确定data的batch_size，可以通过iter(dataset)返回一个数据序列&lt;/p&gt;&lt;p&gt;2、batch_size：（数据类型 int）&lt;/p&gt;&lt;p&gt;每次输入数据的行数，默认为1。PyTorch训练模型时调用数据不是一行一行进行的（这样太没效率），而是一捆一捆来的。这里就是定义每次喂给神经网络多少行数据，如果设置成1，那就是一行一行进行（个人偏好，PyTorch默认设置是1）。&lt;/p&gt;&lt;p&gt;3、shuffle：（数据类型 bool）&lt;/p&gt;&lt;p&gt;洗牌。默认设置为False。在每次迭代训练时是否将数据洗牌，默认设置是False。将输入数据的顺序打乱，是为了使数据更有独立性，但如果数据是有序列特征的，就不要设置成True了。&lt;/p&gt;&lt;p&gt;4、collate_fn：（数据类型 callable，没见过的类型）&lt;/p&gt;&lt;p&gt;将一小段数据合并成数据列表，默认设置是False。如果设置成True，系统会在返回前会将张量数据（Tensors）复制到CUDA内存中。自己定义一个函数提前处理数据，做相应处理&lt;/p&gt;&lt;p&gt;&lt;code&gt;collate_fn&lt;/code&gt; can be used to customize collation, e.g., padding sequential data to max length of a batch. See &lt;a href="https://pytorch.org/docs/1.9.1/data.html?highlight=dataloader#dataloader-collate-fn"&gt;this section&lt;/a&gt; on more about &lt;code&gt;collate_fn&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;5、batch_sampler：（数据类型 Sampler）&lt;/p&gt;&lt;p&gt;批量采样，默认设置为None。但每次返回的是一批数据的索引（注意：不是数据）。其和batch_size、shuffle 、sampler and drop_last参数是不兼容的。我想，应该是每次输入网络的数据是随机采样模式，这样能使数据更具有独立性质。所以，它和一捆一捆按顺序输入，数据洗牌，数据采样，等模式是不兼容的。&lt;/p&gt;&lt;p&gt;6、sampler：（数据类型 Sampler）&lt;/p&gt;&lt;p&gt;采样，默认设置为None。根据定义的策略从数据集中采样输入。如果定义采样规则，则洗牌（shuffle）设置必须为False。&lt;/p&gt;&lt;p&gt;定义采样规则，specify the sequence of indices/keys used in data loading，对于Iterable-style datasets则必须自己定义所有的采样顺序&lt;/p&gt;&lt;p&gt;7、num_workers：（数据类型 Int）&lt;/p&gt;&lt;p&gt;工作者数量，默认是0。使用多少个子进程来导入数据。设置为0，就是使用主进程来导入数据。注意：这个数字必须是大于等于0的，负数估计会出错。&lt;/p&gt;&lt;p&gt;8、pin_memory：（数据类型 bool）&lt;/p&gt;&lt;p&gt;内存寄存，默认为False。在数据返回前，是否将数据复制到CUDA内存中。&lt;/p&gt;&lt;p&gt;9、drop_last：（数据类型 bool）&lt;/p&gt;&lt;p&gt;丢弃最后数据，默认为False。设置了 batch_size 的数目后，最后一批数据未必是设置的数目，有可能会小些。这时你是否需要丢弃这批数据。&lt;/p&gt;&lt;p&gt;10、timeout：（数据类型 numeric）&lt;/p&gt;&lt;p&gt;超时，默认为0。是用来设置数据读取的超时时间的，但超过这个时间还没读取到数据的话就会报错。 所以，数值必须大于等于0。&lt;/p&gt;&lt;p&gt;11、worker_init_fn（数据类型 callable，没见过的类型）&lt;/p&gt;&lt;p&gt;子进程导入模式，默认为Noun。在数据导入前和步长结束后，根据工作子进程的ID逐个按顺序导入数据。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;When automatic batching is disabled&lt;/strong&gt;, the default &lt;code&gt;collate_fn&lt;/code&gt; simply converts NumPy arrays into PyTorch Tensors, and keeps everything else untouched.&lt;/p&gt;&lt;p&gt;When both &lt;code&gt;batch_size&lt;/code&gt; and &lt;code&gt;batch_sampler&lt;/code&gt; are &lt;code&gt;None&lt;/code&gt; (default value for &lt;code&gt;batch_sampler&lt;/code&gt; is already &lt;code&gt;None&lt;/code&gt;), automatic batching is disabled. Each sample obtained from the &lt;code&gt;dataset&lt;/code&gt; is processed with the function passed as the &lt;code&gt;collate_fn&lt;/code&gt; argument.&lt;/p&gt;&lt;p&gt;重点是collate_fn参数&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/model.train/</guid><pubDate>Sun, 14 Nov 2021 00:00:00 +0806</pubDate></item><item><title>numpy学习</title><link>/Blog/archives/numpy%E8%AF%AD%E6%B3%95/</link><description>&lt;p&gt;&lt;strong&gt;numpy学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;numpy.where()&lt;/strong&gt; 有两种用法：&lt;/p&gt;&lt;h3&gt;1. np.where(condition, x, y)&lt;/h3&gt;
&lt;p&gt;满足条件(condition)，输出x，不满足输出y。&lt;/p&gt;&lt;p&gt;如果是一维数组，相当于&lt;code&gt;[xv if c else yv for (c,xv,yv) in zip(condition,x,y)]&lt;/code&gt;&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;    &lt;span class="c1"&gt;# 官网上的例子&lt;/span&gt;
    		 &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
             &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面这个例子的条件为&lt;code&gt;[[True,False], [True,False]]&lt;/code&gt;，分别对应最后输出结果的四个值。第一个值从&lt;code&gt;[1,9]&lt;/code&gt;中选，因为条件为True，所以是选1。==第二个值从[2,8]中选==，因为条件为False，所以选8，后面以此类推。类似的问题可以再看个例子：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
             &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;not chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;not chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
             &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;not chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;not chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;chosen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;chosen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;chosen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;chosen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;lt;U10&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;2. np.where(condition)&lt;/h3&gt;
&lt;p&gt;只有条件 (condition)，没有x和y，则输出满足条件 (即非0) 元素的坐标 (等价于&lt;a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.nonzero.html#numpy.nonzero"&gt;numpy.nonzero&lt;/a&gt;)。这里的坐标以tuple的形式给出，通常原数组有多少维，输出的tuple中就包含几个数组，分别对应符合条件元素的各维坐标。&lt;/p&gt;&lt;p&gt;下面看个复杂点的例子：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;27&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[[&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;

       &lt;span class="p"&gt;[[&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;

       &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;]]])&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;


&lt;span class="c1"&gt;# 符合条件的元素为&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;

      &lt;span class="p"&gt;[[&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;

      &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;]]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;所以np.where会输出每个元素的对应的坐标，因为原数组有三维，所以tuple中有三个数组。&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/numpy%E8%AF%AD%E6%B3%95/</guid><pubDate>Sun, 14 Nov 2021 00:00:00 +0806</pubDate></item><item><title>matplotlib学习</title><link>/Blog/archives/plot%E8%AF%AD%E6%B3%95/</link><description>&lt;p&gt;&lt;strong&gt;plt绘图&lt;/strong&gt;&lt;/p&gt;&lt;h1&gt;在matplotlib中创建子图的多种方式&lt;/h1&gt;
&lt;p&gt;在用Matplotlib绘制图像时，有时候需要从多个角度对数据进行对比。为此子图的概念便提了出来，子图可以在较大的图形中同时放置一组较小的坐标轴。这些子图可能是画中画、网格图，或者是其他更复杂的布局形式。&lt;/p&gt;&lt;p&gt;创建子图常用的可以有如下三种方式。&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;使用add_subplot()面向对象的方式来创建子图&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用面向对象的方式创建子图前，需要创建一个figure对象，如&lt;code&gt;fig = plt.figure()&lt;/code&gt;，然后在图像布局中绘制子图，下列例子中，我们用&lt;code&gt;fig.add_subplot(221)&lt;/code&gt;绘制了2行2列子图，而221代表创建2行2列一共4个子图，并从左往右第1个子图开始绘图。假设我们要绘制2行6列子图，当画到第10块子图时，那么第10块该怎么写呢？2610是不行的，可以用另一种方式(2, 6, 10)&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;  
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 创建图像布局对象fig&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# 221代表创建2行2列一共4个子图，并从左往右第1个子图开始绘图。&lt;/span&gt;
&lt;span class="n"&gt;ax1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;221&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;ax2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;222&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;ax3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;223&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;ax4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;224&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="n"&gt;ax4&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;显示的图像如下：&lt;/p&gt;&lt;figure style="flex: 102.5925925925926" &gt;&lt;img width="1662" height="810" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/fbd89d6776fa5d3a55e449a9f9a1471a.png" /&gt;&lt;figcaption&gt;plot1&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;使用pyplot方式直接创建子图&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了使用上面，面向对象的方式创建图外，我们还可以直接使用pyploy（也就是我们声明的别名plt）直接创建子图对象，而不需要先声明实例对象的方式去创建，最终绘图得到的图像是一模一样的。&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;  
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
&lt;span class="c1"&gt;# 先画好子图具体位置&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;221&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="c1"&gt;# 在该子图下绘图&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;222&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;223&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;224&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;使用subplots创建多个子图&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：如果设置的nrows = 1，ncols = 3也就是1行3列的话，axes的引用格式就不是axes[0][1]，axes[0][2]， axes[0][3]这样子。而是直接使用axes[0]， axes[1]， axes[2]， 不然会报错。因为默认1行就不算是多维数组，所以不需要多维数组访问的方式。&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;  
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="c1"&gt;# 将画布分割为2行2列，起始值为0。&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;nrows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ncols&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="c1"&gt;# 给第1行第1列绘图&lt;/span&gt;
&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;hist0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;edgecolor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="c1"&gt;# 给图形添加标签&lt;/span&gt;
&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;hist1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;edgecolor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;hist2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;edgecolor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;hist3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;edgecolor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;显示的图像如下：&lt;/p&gt;&lt;figure style="flex: 98.39506172839506" &gt;&lt;img width="1594" height="810" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/8a9e36647e1c65df0f69b39bee29a7a6.png" /&gt;&lt;figcaption&gt;plot2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;除此之外，如果要实现更复杂的排列方式，比如说实现不规则的多行多子列图有没有什么办法呢？万能的matplotlib图库当然有办法，那就是使用plt.GridSpec()，不过plt.GridSpec()对象本身不能直接创建一个图形，他其实只是plt.subplot()命令可以识别的一个简易接口。&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;plt.GridSpec：实现更复杂的排列方式&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;  
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="c1"&gt;# 声明一个GridSpec对象实例，创建的是2行3列的图像布局。&lt;/span&gt;
&lt;span class="n"&gt;grid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GridSpec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nrows&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ncols&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;wspace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hspace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 设置整个图像大小。&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
&lt;span class="c1"&gt;# 第一个子图的具体排列位置为(0,0)。&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;orientation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;horizontal&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;edgecolor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;  
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;edgecolor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;  
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;可以看到最终的绘制效果图如下，实现了不规则的图形。&lt;/p&gt;&lt;figure style="flex: 98.39506172839506" &gt;&lt;img width="1594" height="810" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/5b416b5abb69e399a22a23b2400a1f14.png" /&gt;&lt;figcaption&gt;plot3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个例子中有几个参数要特别说明下，因为一开始会让不少人感到困惑，就是关于创建不规则子图的参数指定，因为这决定了子图的排列规则。例子中4个子图的位置分别是grid[0, 0]、grid[0, 1:]、grid[1, :2]、grid[1, 2]它们到底代表着什么呢，怎么理解呢。&lt;/p&gt;&lt;p&gt;可以这样理解，一开始我们声明创建的是2行3列的一个图像布局网格，我们可以想象成我们创建的是一个二维数组，类似如下这样，如果一行的宽度按100%计算的话，每个元素占据的宽度可以理解为33.33%：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;第一个子图的位置是&lt;code&gt;grid[0, 0]&lt;/code&gt;：按照这个&lt;code&gt;[0, 0]&lt;/code&gt;的下标取值为第1行第1列的元素，得到的是1这个元素位置宽度（大概是33.33%的宽度）。&lt;/p&gt;&lt;p&gt;第二个子图的位置是&lt;code&gt;grid[0, 1:]&lt;/code&gt;：按照这个&lt;code&gt;[0, 1:]&lt;/code&gt;的下标取值为第1行第2列的之后所有的元素，得到的是2, 3这个元素位置宽度。所以你可以从效果图中看到第2个子图占据了第一行一大半的宽度（大概是66.66%的宽度）。&lt;/p&gt;&lt;p&gt;第三个子图的位置是&lt;code&gt;grid[1, :2]&lt;/code&gt;：按照这个&lt;code&gt;[1, :2]&lt;/code&gt;的下标取值为第2行第1列起到第3列&lt;strong&gt;之间&lt;/strong&gt;所有的元素，得到的是4, 5这个元素位置宽度。所以你可以从效果图中看到第3个子图占据了第二行一大半的宽度（大概是66.66%的宽度）。&lt;/p&gt;&lt;p&gt;第四个子图的位置是&lt;code&gt;grid[1, 2]&lt;/code&gt;：按照这个&lt;code&gt;[1, 2]&lt;/code&gt;的下标取值为第2行第3列的元素，得到的是6这个元素位置宽度。所以你可以从效果图中看到第4个子图只占据了一个元素的宽度（大概是33.33%的宽度）。&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/plot%E8%AF%AD%E6%B3%95/</guid><pubDate>Sun, 14 Nov 2021 00:00:00 +0806</pubDate></item><item><title>电力电子技术复习</title><link>/Blog/archives/%E7%94%B5%E5%8A%9B%E7%94%B5%E5%AD%90%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0/</link><description>&lt;p&gt;&lt;strong&gt;电力电子技术期中&lt;/strong&gt;&lt;/p&gt;&lt;h3&gt;绪论&lt;/h3&gt;
&lt;p&gt;器件：有源，无源&lt;/p&gt;&lt;p&gt;，拓扑，控制三要素&lt;/p&gt;&lt;p&gt;四种基本变换&lt;/p&gt;&lt;p&gt;AC-DC整流；DC-AC逆变；AC-AC周波变流器，cyclo-converter；DC-DC斩波器chopper&lt;/p&gt;&lt;p&gt;器件，拓扑，控制是电力电子的三要素，开关模式是现代电力电子的核心特征&lt;/p&gt;&lt;p&gt;应用：新能源发电，电源，电力系统&lt;/p&gt;&lt;h3&gt;第二章电力电子器件&lt;/h3&gt;
&lt;h4&gt;2.1概述&lt;/h4&gt;
&lt;h5&gt;特征和概念&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;处理功率大&lt;/li&gt;
&lt;li&gt;工作在开关模式&lt;/li&gt;
&lt;li&gt;需要控制电路&lt;/li&gt;
&lt;li&gt;需要驱动电路&lt;/li&gt;
&lt;li&gt;功率损耗大，需要特殊封装器，散热器&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;损耗分类&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;通态损耗&lt;/li&gt;
&lt;li&gt;开关损耗：开通损耗，关断损耗&lt;/li&gt;
&lt;li&gt;断态损耗&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;器件分类&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;不控器件——功率二极管&lt;/li&gt;
&lt;li&gt;半控器件——晶闸管&lt;/li&gt;
&lt;li&gt;全控器件——BJT(GTR),GTO,MOSFET，IGBT&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;全控器件又分为电流型和电压型，单极型（一种带电粒子，如power mosfet）、双极型（有电子、空穴两种带电粒子，如GTR和GTO），由双极型和单极型器件复合成的器件称为复合型器件，如IGBT&lt;/p&gt;&lt;p&gt;PN结形成的原因&lt;/p&gt;&lt;p&gt;多子扩散，少子漂移&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;正偏：形成正向电流，利于多子扩散，抑制漂移（因为电场的原因），少子的存储（越过电荷区后来不及复合）&lt;/li&gt;
&lt;li&gt;反偏：漏电流，抑制多子扩散，利于漂移，空间电荷区变宽，少子的抽取（两侧漂移的少子被抽取来不及被补充）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;反偏击穿&lt;/p&gt;&lt;p&gt;雪崩击穿，齐纳击穿——可恢复；热击穿（不可恢复）&lt;/p&gt;&lt;p&gt;电容&lt;/p&gt;&lt;p&gt;结电容，频率越高，电容效应越明显&lt;/p&gt;&lt;p&gt;势垒电容：多子的移动&lt;/p&gt;&lt;p&gt;扩散电容：少子的存储和抽取&lt;/p&gt;&lt;p&gt;静态特性：伏安特性&lt;/p&gt;&lt;h4&gt;2.2 不控器件&lt;/h4&gt;
&lt;p&gt;功率二极管&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;尺寸更大，通过电流更大&lt;/li&gt;
&lt;li&gt;垂直导电结构，通过电流更大&lt;/li&gt;
&lt;li&gt;n-低掺杂，耐高压&lt;/li&gt;
&lt;li&gt;电导调制效应，正向电流大时，P区注入并积累在N-区的少子空穴浓度增大，为维持漂移区电中性条件，N-区多子浓度也增大，从而使得电阻率下降，电导率增大；==主要是指N-区内的浓度变化==&lt;/li&gt;
&lt;li&gt;大量少子需要一定时间来存储在N-区&lt;/li&gt;
&lt;li&gt;反偏不能立即关断：功率二极管的空间电荷区两侧（特别是多掺杂N区）储存有大量少子的缘故而并没 有恢复反向阻断能力&lt;/li&gt;
&lt;li&gt;延迟时间：$t_d  = t_4$，电流下降时间：$t_f = t_5$，反向恢复时间：$t_{rr} = t_d+t_f$，恢复特性的软度：$\frac{t_f}{t_d}$，用$S_r$表示。&lt;/li&gt;
&lt;li&gt;反偏到正偏存在正向恢复时间$t_{rr}$。电流上升率越大，$V_{FP}$越高&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;正向和反向电压过充的原因：&lt;/p&gt;&lt;p&gt;正向电流的上升会因器件自身的电感而产生较大压降，所以，电流上升率越大，电压过充越高&lt;/p&gt;&lt;p&gt;下降的两个过程：==抽取少子和抽取远端少子==&lt;/p&gt;&lt;p&gt;$V_{DRM}$正向重复峰值电压：$I_G = 0$时允许==重复==加在器件上的峰值电压，50Hz，每次不超过10ms&lt;/p&gt;&lt;h4&gt;2.3 半控器件&lt;/h4&gt;
&lt;p&gt;正反馈导通：正偏 + 提供门极电流$𝑰_𝐆$。&lt;/p&gt;&lt;p&gt;关断：反偏+电流过零&lt;/p&gt;&lt;p&gt;维持电流$I_H$ 晶闸管维持导通所必需的最小电流 ==通-断==&lt;/p&gt;&lt;p&gt;擎住电流$I_{L}$，晶闸管刚从断态转入通态并移除触发信号后， 能维持导通所需的最小电流。对同一晶闸管来说，通常$I_{L}$约为$I_H$的2~4倍。 ==断-通==
开通时间turn on time $t_{on}=t_d+t_r$&lt;/p&gt;&lt;p&gt;carrier recombination用于少子复合，无法用外电路抽取&lt;/p&gt;&lt;p&gt;关断时间turn off time $t_{off}=t_{rr}+t_{gr}$。反向恢复时间$t_{rr}$，正向阻断时间$t_{gr}$（下面的PN结处于方向状态，无法抽取）&lt;/p&gt;&lt;h4&gt;2.4 全控器件&lt;/h4&gt;
&lt;p&gt;GTO关断增益大，可以通过门级抽取电流的方法进行关断，但开通关断吸收电路复杂，容易出现误导通现象。二极管反向恢复特性差，存在拖尾过程，不能用于高频工作&lt;/p&gt;&lt;p&gt;GTO可控关断的原因：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;α2 设计的较大V2 更容易被控制，因而正反馈在关断时候也存在;&lt;/li&gt;
&lt;li&gt;α1+α2 更接近于1， α1 + α2 ≈ 1. 05 ，因而开通时更接近于饱和区的边界；&lt;/li&gt;
&lt;li&gt;多元集成结构使每个GTO元阴极面积很小，门极和阴极间的距 离大为缩短，使得P2基区横向电阻很小，使得从门极抽出较大电流成为可能.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;GTR放大倍数有限，需要采用达林顿接法，基极很宽，导致β较小。&lt;/p&gt;&lt;p&gt;BJT（GTR）二次击穿会造成永久损害&lt;/p&gt;&lt;p&gt;GTR具有==负的温度系数==&lt;/p&gt;&lt;p&gt;功率MOSFET&lt;/p&gt;&lt;p&gt;按导电沟道分为P沟道和N沟道&lt;/p&gt;&lt;p&gt;按栅极电压为零时存在导电沟道与否可分为耗尽型（为0）和增强型（不为0）&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;截止($V_{DS}$&amp;gt;0, $V_{GS}$=0 或开路)： J1处于反偏状态&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;导通($V_{DS}$&amp;gt;0, $V_{GS}$&amp;gt;0)：$V_{GS} &amp;gt;V_{th}$&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;体二极管反向导通($V_{DS}$&amp;lt;0, $V_{GS}$=0 或开路)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure style="flex: 56.296992481203006" &gt;&lt;img width="599" height="532" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/7bf8c9f2f1da3cddce7f4d5c9c7066a2.png" /&gt;&lt;/figure&gt;&lt;p&gt;MOSFET开通等效电路&lt;/p&gt;&lt;figure style="flex: 75.82116788321167" &gt;&lt;img width="831" height="548" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/45c17aa978b3d13a80c9b21bebe98642.png" /&gt;&lt;/figure&gt;&lt;p&gt;了解四个阶段的大致过程即可，$C_{GD}$在增大&lt;/p&gt;&lt;p&gt;米勒平台：第三阶段中只对$C_{GD}$充电，$V_{GS}$保持不变&lt;/p&gt;&lt;p&gt;整个过程看$V_{DS}$要下降到0左右&lt;/p&gt;&lt;p&gt;米勒平台时间等于（$t_{fv1}+t_{fv2}$）&lt;/p&gt;&lt;p&gt;进入欧姆区后给$C_{GS}$充电直到稳态电压约15V&lt;/p&gt;&lt;p&gt;MOSFET的动态特性&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;开关频率和Cin关系大（时间常数）&lt;/li&gt;
&lt;li&gt;可以减小门极电阻RG可以加快开关速度（增大注入电流）&lt;/li&gt;
&lt;li&gt;开关时间10~100 ns，频率可以高于 100 kHz&lt;/li&gt;
&lt;li&gt;正温度系数，易并联&lt;/li&gt;
&lt;/ol&gt;
&lt;figure style="flex: 98.90710382513662" &gt;&lt;img width="724" height="366" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/bc9616f464e60e78b8f6a30102af94b1.png" /&gt;&lt;/figure&gt;&lt;figure style="flex: 150.37313432835822" &gt;&lt;img width="806" height="268" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/0a2ec2020d61f6f52b86a8d561fd42fe.png" /&gt;&lt;/figure&gt;&lt;p&gt;IGBT可以看成是MOSFET控制的GTR&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;低导通损耗，类似GTR&lt;/li&gt;
&lt;li&gt;电压型器件，类似MOSFET&lt;/li&gt;
&lt;li&gt;工作频率高于GTR，低于MOSFET&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;IGBT三端分别为G，C，E&lt;/p&gt;&lt;p&gt;与MOSFET区别&lt;/p&gt;&lt;p&gt;IGBT开通&lt;/p&gt;&lt;p&gt;$𝑡&lt;em&gt;{fv2}$不对应米勒平台 ；MOSFET $𝑡&lt;/em&gt;{fv2}$对应米勒平台的原因是$V_{DS}$变小，自身 $C_{GD}$及充电时间常数变很大。而IGBT中，MOSFET的$C_{GD}$是和GTR结电容串联后共同决定时间常数&lt;/p&gt;&lt;p&gt;IGBT关断&lt;/p&gt;&lt;p&gt;电流下降分两段，$𝑡&lt;em&gt;{fv1}+𝑡&lt;/em&gt;{fv2}$,并存在$𝑡&lt;em&gt;{fv2}$拖尾电流时间$𝑡&lt;/em&gt;{fv1}$对应IGBT内部MOSFET和GTR一起关断，电流下 降较快，$𝑡_{fv1}$时间，MOSFET已经关断，PNP晶体管无基区少子抽取通道，晶体管基区少子复合缓慢，造成电流下降缓慢，成为拖尾电流。&lt;/p&gt;&lt;p&gt;IGBT特征&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;开关速度快（相对于GTR）&lt;/li&gt;
&lt;li&gt;通态电压比MOSFET低（导通损耗低）&lt;/li&gt;
&lt;li&gt;高输入阻抗（电阻串联）&lt;/li&gt;
&lt;li&gt;驱动功率低（电压驱动）&lt;/li&gt;
&lt;li&gt;驱动电路简单&lt;/li&gt;
&lt;li&gt;有拖尾电流（漂移层存储电荷导致）&lt;/li&gt;
&lt;li&gt;存在==擎住效应==——内部存在一个寄生晶闸管导致&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;第四章 DC-DC变换器&lt;/h3&gt;
&lt;h4&gt;4.1 概述&lt;/h4&gt;
&lt;p&gt;分类：&lt;/p&gt;&lt;p&gt;非隔离型：Buck 变换器，Boost 变换器，Buck-Boost变换器，Cúk 变换器。非隔离DC-DC变换器按所用有源功率器件的个数分为单管、双管和四管。半桥和全桥直流变换器是常用的双管、四管直流变换器。&lt;/p&gt;&lt;p&gt;隔离型DC-DC变换器：单管的有正激式和反激式两种，双管有双管正激、双管反激、推挽和半桥四种，四管就是全桥直流变换器。&lt;/p&gt;&lt;p&gt;按能量传递分为：单向和双向两种。&lt;/p&gt;&lt;h4&gt;4.2 开关模式控制&lt;/h4&gt;
&lt;p&gt;脉冲频率调制（PFM）：固定开通或关断时间、调节脉冲频率的方法实现稳压输出的技术。&lt;/p&gt;&lt;p&gt;脉冲宽度调制（PWM）：固定周期，调节占空比来调节输出电压。&lt;/p&gt;&lt;p&gt;实现通过$v_{control}$调制波和高频的锯齿波称为载波$v_{tri}$来控制占空比。&lt;/p&gt;&lt;figure style="flex: 83.48729792147806" &gt;&lt;img width="723" height="433" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/3d4838e8625e4f3d9f0672a126d5fd68.png" /&gt;&lt;/figure&gt;&lt;blockquote&gt;
&lt;p&gt;学习思路
电路拓扑：D，T，R，L，C的位置
工作模态（working mode）
伏秒平衡（V-S balance）
电压增益（voltage gain）
边界电流（boundary current）CCM&amp;amp;DCM
纹波分析（ripple analysis）&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4&gt;4.3 降压式变换器&lt;/h4&gt;
&lt;p&gt;伏秒平衡&lt;/p&gt;&lt;p&gt;$(V_D-V_O)t_{on} = V_Ot_{off}$推得$\frac{V_O}{V_D}=\frac{t_{on}}{T_{s}}=D$&lt;/p&gt;&lt;p&gt;CCM模式的判断&lt;/p&gt;&lt;figure style="flex: 68.52300242130751" &gt;&lt;img width="566" height="413" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/feded8ba3643d6176408b53bfdba44e8.png" /&gt;&lt;/figure&gt;&lt;p&gt;CCM模式下的纹波分析&lt;/p&gt;&lt;figure style="flex: 75.99620493358634" &gt;&lt;img width="801" height="527" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/309f2301ee1aeba5c0e0c20440904d14.png" /&gt;&lt;/figure&gt;&lt;h4&gt;4.4 Boost升压变换器&lt;/h4&gt;
&lt;p&gt;伏秒平衡&lt;/p&gt;&lt;p&gt;$V_Dt_{on} = (V_O-V_D)t_{off}$推得$\frac{V_O}{V_D}=\frac{T_{s}}{T_{s}-t_{on}}=\frac{1}{1-D}$&lt;/p&gt;&lt;p&gt;CCM模式分析&lt;/p&gt;&lt;figure style="flex: 72.63257575757575" &gt;&lt;img width="767" height="528" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/f273c0a0477cdc82f42b0c802231929e.png" /&gt;&lt;/figure&gt;&lt;p&gt;Boost 变换器不能用于输出端开路工作的情况，没有负载或负载较小，$V_o$会不断升高&lt;/p&gt;&lt;p&gt;寄生参数对于Boost电压增益的影响&lt;/p&gt;&lt;p&gt;因为电感，电容，开关等具有寄生参数导致损耗，所以Boost电路实际的增益曲线并不是线性的，在D逼近1时，电压增益大幅下降，事实上，Boost电路的占空比D是有限制的，通常电压增益限制在4倍以内。&lt;/p&gt;&lt;figure style="flex: 81.875" &gt;&lt;img width="393" height="240" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/a6ec4d3cb751435aa04e50841a73a5be.png" /&gt;&lt;/figure&gt;&lt;p&gt;Boost变换器输出电压的纹波&lt;/p&gt;&lt;figure style="flex: 77.95031055900621" &gt;&lt;img width="753" height="483" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/741db1968b2b1e9265381825ed3ccc97.png" /&gt;&lt;/figure&gt;&lt;p&gt;DCM优势：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;L尺寸小&lt;/li&gt;
&lt;li&gt;没有二极管反向恢复损耗&lt;/li&gt;
&lt;li&gt;效率高（所有存储能量都转移给负载）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;DCM劣势&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;EMI电磁干扰&lt;/li&gt;
&lt;li&gt;D调节困难，可能会跑到CCM模式&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;4.5 Buck-Boost变换器&lt;/h4&gt;
&lt;p&gt;伏秒平衡&lt;/p&gt;&lt;p&gt;$V_Dt_{on} = V_Ot_{off}$推得$\frac{V_O}{V_D}=\frac{D}{1-D}$&lt;/p&gt;&lt;p&gt;CCM分析&lt;/p&gt;&lt;figure style="flex: 77.40667976424362" &gt;&lt;img width="788" height="509" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/b1a3287efaaa7547345f8163152b4e2a.png" /&gt;&lt;/figure&gt;&lt;p&gt;输出纹波电压分析&lt;/p&gt;&lt;figure style="flex: 77.24550898203593" &gt;&lt;img width="774" height="501" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/e8fed3bb6d80bae5fb538b417e6989fa.png" /&gt;&lt;/figure&gt;&lt;h4&gt;4.6 正激变换器&lt;/h4&gt;
&lt;p&gt;$D_3，N_3$为磁复位电路，为了避免磁饱和，在源边人为注入反向电压&lt;/p&gt;&lt;p&gt;和Buck电路的主要区别$\frac{V_O}{V_D}=\frac{N_2}{N_1}D$&lt;/p&gt;&lt;h4&gt;4.7 反激变换器&lt;/h4&gt;
&lt;figure style="flex: 55.90717299578059" &gt;&lt;img width="265" height="237" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/07a88ad2d49411def23e97ad3f143a6b.png" /&gt;&lt;/figure&gt;&lt;p&gt;原型是Buck-Boost&lt;/p&gt;&lt;p&gt;隔离的励磁电感代替L&lt;/p&gt;&lt;p&gt;根据伏秒平衡$\frac{V_O}{V_D}=\frac{N_2}{N_1}\frac{D}{1-D}$&lt;/p&gt;&lt;p&gt;CCM、DCM模式下，反激变换器磁芯工作状 态：反激变换器磁芯有很大的直流偏磁，通常要加入气隙以防止饱和。加入气隙后，磁滞回线变得偏平，达到$B_m$的H更大，电流更大&lt;/p&gt;&lt;h4&gt;PWM控制&lt;/h4&gt;
&lt;p&gt;开通是指器件有开通信号， 但要实际导通电流才称为导通。&lt;/p&gt;&lt;figure style="flex: 82.57372654155496" &gt;&lt;img width="616" height="373" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/f06af01afb950e994757ab33bff3a8b2.png" /&gt;&lt;/figure&gt;&lt;p&gt;全桥变换器的三种典型应用和控制方法：直流电机驱动、正弦波逆变器、高频隔离DC-DC&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/%E7%94%B5%E5%8A%9B%E7%94%B5%E5%AD%90%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0/</guid><pubDate>Mon, 22 Nov 2021 00:00:00 +0806</pubDate></item><item><title>Linux性能查看</title><link>/Blog/archives/Linux%E6%80%A7%E8%83%BD%E6%9F%A5%E7%9C%8B/</link><description>&lt;p&gt;&lt;strong&gt;Linux性能查看&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;1.1 cpu性能查看
1、查看物理cpu个数：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;cat /proc/cpuinfo |grep &amp;quot;physical id&amp;quot;|sort|uniq|wc -l&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;2、查看每个物理cpu中的core个数：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;cat /proc/cpuinfo |grep &amp;quot;cpu cores&amp;quot;|wc -l&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;3、逻辑cpu的个数：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;cat /proc/cpuinfo |grep &amp;quot;processor&amp;quot;|wc -l&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;物理cpu个数*核数=逻辑cpu个数（不支持超线程技术的情况下）&lt;/p&gt;&lt;p&gt;1.2 内存查看
1、查看内存使用情况：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;#free -m
             total       used       free     shared    buffers     cached
Mem:          3949       2519       1430          0        189       1619
-/+ buffers/cache:        710       3239
Swap:         3576          0       3576&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;total：内存总数
used：已经使用的内存数
free：空闲内存数
shared：多个进程共享的内存总额&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;buffers/cache：(已用)的内存数，即used-buffers-cached&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;buffers/cache：(可用)的内存数，即free+buffers+cached&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Buffer Cache用于针对磁盘块的读写；
Page Cache用于针对文件inode的读写，这些Cache能有效地缩短I/O系统调用的时间。&lt;/p&gt;&lt;p&gt;对操作系统来说free/used是系统可用/占用的内存；
对应用程序来说-/+ buffers/cache是可用/占用内存,因为buffers/cache很快就会被使用。
我们工作时候应该从应用角度来看。&lt;/p&gt;&lt;p&gt;1.3 硬盘查看
1、查看硬盘及分区信息：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;fdisk -l&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;2、查看文件系统的磁盘空间占用情况：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;df -h&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;3、查看硬盘的I/O性能（每隔一秒显示一次，显示5次）：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;iostat -x 1 5&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;iostat是含在套装systat中的,可以用yum -y install systat来安装。&lt;/p&gt;&lt;p&gt;常关注的参数：&lt;/p&gt;&lt;p&gt;如%util接近100%,说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。
如idle小于70%，I/O的压力就比较大了，说明读取进程中有较多的wait。
4、查看linux系统中某目录的大小：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;du -sh /root&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;如发现某个分区空间接近用完，可以进入该分区的挂载点，用以下命令找出占用空间最多的文件或目录，然后按照从大到小的顺序，找出系统中占用最多空间的前10个文件或目录：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;du -cksh *|sort -rn|head -n 10&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;1.4 查看平均负载
有时候系统响应很慢，但又找不到原因，这时就要查看平均负载了，看它是否有大量的进程在排队等待。&lt;/p&gt;&lt;p&gt;load average:平均负载
平均负载(load average)是指系统的运行队列的平均利用率，也可以认为是可运行进程的平均数。&lt;/p&gt;&lt;p&gt;以路况为例， 单核CPU、单车道 情况如下：&lt;/p&gt;&lt;figure style="flex: 129.0909090909091" &gt;&lt;img width="426" height="165" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/c8dcafada270cd7823d98db870f2c077.png" /&gt;&lt;/figure&gt;&lt;p&gt;0.00-1.00 之间的数字表示此时路况非常良好，没有拥堵，车辆可以毫无阻碍地通过。
1.00 表示道路还算正常，但有可能会恶化并造成拥堵。此时系统已经没有多余的资源了，管理员需要进行优化。
1.00-*** 表示路况不太好了，如果到达2.00表示有桥上车辆一倍数目的车辆正在等待。这种情况你必须进行检查了。
多核CPU - 多车道 情况如下：&lt;/p&gt;&lt;figure style="flex: 386.4864864864865" &gt;&lt;img width="572" height="74" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/ed2da7b99ffd9336f558671cbf6a38c2.png" /&gt;&lt;/figure&gt;&lt;p&gt;多核CPU的话，满负荷状态的数字为 &amp;quot;1.00 * CPU核数&amp;quot;，即双核CPU为2.00，四核CPU为4.00。&lt;/p&gt;&lt;p&gt;一般的进程需要消耗CPU、内存、磁盘I/O、网络I/O等资源，在这种情况下，平均负载就不是单独指的CPU使用情况。即内存、磁盘、网络等因素也可以影响系统的平均负载值。 
在单核处理器中，平均负载值为1或者小于1的时候，系统处理进程会非常轻松，即负载很低。当达到3的时候，就会显得很忙，达到5或者8的时候就不能很好的处理进程了（其中5和8目前还是个争议的阈值，为了保守起见，建议选择低的）。&lt;/p&gt;&lt;p&gt;查看load average 数据
下面几个命令都可以看到 load average&lt;/p&gt;&lt;p&gt;#top 
#uptime 
#w&lt;/p&gt;&lt;p&gt;截图如下：&lt;/p&gt;&lt;p&gt;top 命令的&lt;/p&gt;&lt;figure style="flex: 106.22837370242215" &gt;&lt;img width="614" height="289" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/520beb08519ecb48a5356867cb5b6a6f.png" /&gt;&lt;/figure&gt;&lt;p&gt;uptime 命令的&lt;/p&gt;&lt;figure style="flex: 461.9047619047619" &gt;&lt;img width="582" height="63" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/461b2a7480dd7076a1782c059122a029.png" /&gt;&lt;/figure&gt;&lt;p&gt;w 命令的&lt;/p&gt;&lt;figure style="flex: 271.5" &gt;&lt;img width="543" height="100" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/2117d8f654e3c3af152c7418a7e6b5ea.png" /&gt;&lt;/figure&gt;&lt;p&gt;这里的 load average 的三个值分别指系统在最后 1/5/15分钟 的平均负载值。&lt;/p&gt;&lt;p&gt;根据经验：我们应该把重点放在5/15分钟的平均负载，因为1分钟的平均负载太频繁，一瞬间的高并发就会导致该值的大幅度改变。&lt;/p&gt;&lt;p&gt;1.5 vmstat命令来判断系统是否繁忙
还可以结合vmstat命令来判断系统是否繁忙，其中：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;procs
r：等待运行的进程数。
b：处在非中断睡眠状态的进程数。
w：被交换出去的可运行的进程数。&lt;/p&gt;&lt;p&gt;memeory
swpd：虚拟内存使用情况，单位为KB。
free：空闲的内存，单位为KB。
buff：被用来作为缓存的内存数，单位为KB。&lt;/p&gt;&lt;p&gt;swap
si：从磁盘交换到内存的交换页数量，单位为KB。
so：从内存交换到磁盘的交换页数量，单位为KB。&lt;/p&gt;&lt;p&gt;io
bi：发送到块设备的块数，单位为KB。
bo：从块设备接受的块数，单位为KB。&lt;/p&gt;&lt;p&gt;system
in：每秒的中断数，包括时钟中断。
cs：每秒的环境切换次数。&lt;/p&gt;&lt;p&gt;cpu
按cpu的总使用百分比来显示。
us：cpu使用时间。
sy：cpu系统使用时间。
id：闲置时间。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;1.6Linux下可使用 nethogs 工具查看进程流量&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;1.7 其他参数
查看内核版本号：
uname -a&lt;/p&gt;&lt;p&gt;简化命令：uname -r&lt;/p&gt;&lt;p&gt;查看系统是32位还是64位的：
file /sbin/init&lt;/p&gt;&lt;p&gt;查看发行版：
cat /etc/issue
或lsb_release -a&lt;/p&gt;&lt;p&gt;查看系统已载入的相关模块：
lsmod&lt;/p&gt;&lt;p&gt;查看pci设置：
lspci&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;2.1.3 系统性能分析工具
1.常用系统命令
Vmstat、sar、iostat、netstat、free、ps、top等&lt;/p&gt;&lt;p&gt;2.常用组合方式
vmstat、sar、iostat检测是否是CPU瓶颈
free、vmstat检测是否是内存瓶颈
iostat检测是否是磁盘I/O瓶颈
netstat检测是否是网络带宽瓶颈
2.1.4 Linux性能评估与优化
系统整体性能评估（uptime命令）
uptime&lt;/p&gt;&lt;p&gt;16:38:00 up 118 days, 3:01, 5 users,load average: 1.22, 1.02, 0.91&lt;/p&gt;&lt;p&gt;注意：&lt;/p&gt;&lt;p&gt;load average三值大小一般不能大于系统CPU的个数。&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;系统有8个CPU,如load average三值长期大于8，说明CPU很繁忙，负载很高，可能会影响系统性能。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;但偶尔大于8，一般不会影响系统性能。&lt;/p&gt;&lt;p&gt;如load average输出值小于CPU个数，则表示CPU有空闲时间片，比如本例中的输出，CPU是非常空闲的&lt;/p&gt;&lt;p&gt;2.2.1 CPU性能评估
1.利用vmstat命令监控系统CPU
显示系统各种资源之间相关性能简要信息，主要看CPU负载情况。&lt;/p&gt;&lt;p&gt;下面是vmstat命令在某个系统的输出结果：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;[root@node1 ~]#vmstat 2 3&lt;/p&gt;&lt;p&gt;procs
 ———–memory———- —swap– —–io—- –system– —–cpu——&lt;/p&gt;&lt;p&gt;r  b swpd freebuff  cache si so bi bo incs us sy idwa st&lt;/p&gt;&lt;p&gt;0  0 0 162240 8304 67032 0 0 13 21 1007 23 0 1 98 0 0&lt;/p&gt;&lt;p&gt;0  0 0 162240 8304 67032 0 0 1 0 1010 20 0 1 100 0 0&lt;/p&gt;&lt;p&gt;0  0 0 162240 8304 67032 0 0 1 1 1009 18 0 1 99 0 0
Procs
r--运行和等待cpu时间片的进程数，这个值如果长期大于系统CPU的个数，说明CPU不足，需要增加CPU&lt;/p&gt;&lt;p&gt;b--在等待资源的进程数，比如正在等待I/O、或者内存交换等。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;CPU
us
用户进程消耗的CPU 时间百分比。
us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期大于50%，就需要考虑优化程序或算法。&lt;/p&gt;&lt;p&gt;sy
内核进程消耗的CPU时间百分比。Sy的值较高时，说明内核消耗的CPU资源很多。&lt;/p&gt;&lt;p&gt;根据经验，us+sy的参考值为80%，如果us+sy大于 80%说明可能存在CPU资源不足。&lt;/p&gt;&lt;p&gt;2.利用sar命令监控系统CPU
sar对系统每方面进行单独统计，但会增加系统开销，不过开销可以评估，对系统的统计结果不会有很大影响。&lt;/p&gt;&lt;p&gt;下面是sar命令对某个系统的CPU统计输出：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;[root@webserver ~]# sar -u 3 5&lt;/p&gt;&lt;p&gt;Linux
 2.6.9-42.ELsmp (webserver) 11/28/2008_i686_
 (8 CPU)&lt;/p&gt;&lt;p&gt;11:41:24
 AM CPU %user %nice%system
 %iowait %steal %idle&lt;/p&gt;&lt;p&gt;11:41:27
 AM all 0.88 0.00 0.29 0.00 0.00 98.83&lt;/p&gt;&lt;p&gt;11:41:30
 AM all 0.13 0.00 0.17 0.21 0.00 99.50&lt;/p&gt;&lt;p&gt;11:41:33
 AM all 0.04 0.00 0.04 0.00 0.00 99.92&lt;/p&gt;&lt;p&gt;11:41:36
 AM all 90.08 0.00 0.13 0.16 0.00 9.63&lt;/p&gt;&lt;p&gt;11:41:39
 AM all 0.38 0.00 0.17 0.04 0.00 99.41&lt;/p&gt;&lt;p&gt;Average:
 all 0.34 0.00 0.16 0.05 0.00 99.45&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;输出解释如下：&lt;/p&gt;&lt;p&gt;%user列显示了用户进程消耗的CPU 时间百分比。
%nice列显示了运行正常进程所消耗的CPU 时间百分比。
%system列显示了系统进程消耗的CPU时间百分比。
%iowait列显示了IO等待所占用的CPU时间百分比
%steal列显示了在内存相对紧张的环境下pagein强制对不同的页面进行的steal操作 。
%idle列显示了CPU处在空闲状态的时间百分比。
问题
你是否遇到过系统CPU整体利用率不高，而应用缓慢的现象？&lt;/p&gt;&lt;p&gt;在一个多CPU的系统中，如果程序使用了单线程，会出现这么一个现象，CPU的整体使用率不高，但是系统应用却响应缓慢，这可能是由于程序使用单线程的原因，单线程只使用一个CPU，导致这个CPU占用率为100%，无法处理其它请求，而其它的CPU却闲置，这就导致了整体CPU使用率不高，而应用缓慢现象的发生。&lt;/p&gt;&lt;p&gt;2.3.1 内存性能评估
1.利用free指令监控内存
free是监控Linux内存使用状况最常用的指令，看下面的一个输出：&lt;/p&gt;&lt;p&gt;[root@webserver ~]# free -m&lt;/p&gt;&lt;p&gt;total
 used freeshared
 buffers cached&lt;/p&gt;&lt;p&gt;Mem:
 8111 7185 926 0 243 6299&lt;/p&gt;&lt;p&gt;-/+
 buffers/cache:
 643 7468&lt;/p&gt;&lt;p&gt;Swap:
 8189 0 8189
经验公式：&lt;/p&gt;&lt;p&gt;应用程序可用内存/系统物理内存&amp;gt;70%，表示系统内存资源非常充足，不影响系统性能;
应用程序可用内存/系统物理内存&amp;lt;20%，表示系统内存资源紧缺，需要增加系统内存;
20%&amp;lt;应用程序可用内存/系统物理内存&amp;lt;70%，表示系统内存资源基本能满足应用需求，暂时不影响系统性能
2.利用vmstat命令监控内存
[root@node1
 ~]#
 vmstat 2 3&lt;/p&gt;&lt;p&gt;procs
 ———–memory———- —swap– —–io—- –system– —–cpu——&lt;/p&gt;&lt;p&gt;r b swpd freebuff cache si so bi bo incs us sy idwa st&lt;/p&gt;&lt;p&gt;0 0 0 162240 8304 67032 0 0 13 21 1007 23 0 1 98 0 0&lt;/p&gt;&lt;p&gt;0 0 0 162240 8304 67032 0 0 1 0 1010 20 0 1 100 0 0&lt;/p&gt;&lt;p&gt;0 0 0 162240 8304 67032 0 0 1 1 1009 18 0 1 99 0 0
memory&lt;/p&gt;&lt;p&gt;swpd--切换到内存交换区的内存数量（k为单位)。如swpd值偶尔非0，不影响系统性能
free--当前空闲的物理内存数量（k为单位）
buff--buffers cache的内存数量，一般对块设备的读写才需要缓冲
cache--page cached的内存数量
一般作为文件系统cached，频繁访问的文件都会被cached，如cache值较大，说明cached的文件数较多，如果此时IO中bi比较小，说明文件系统效率比较好。&lt;/p&gt;&lt;p&gt;swap&lt;/p&gt;&lt;p&gt;si--由磁盘调入内存，也就是内存进入内存交换区的数量。
so--由内存调入磁盘，也就是内存交换区进入内存的数量。
si、so的值长期不为0，表示系统内存不足。需增加系统内存。&lt;/p&gt;&lt;p&gt;2.4.1磁盘I/O性能评估
1.磁盘存储基础
频繁访问的文件或数据尽可能用内存读写代替直接磁盘I/O，效率高千倍。&lt;/p&gt;&lt;p&gt;将经常进行读写的文件与长期不变的文件独立出来，分别放置到不同的磁盘设备上。&lt;/p&gt;&lt;p&gt;对于写操作频繁的数据，可以考虑使用裸设备代替文件系统。&lt;/p&gt;&lt;p&gt;裸设备优点：&lt;/p&gt;&lt;p&gt;数据可直接读写，不需经过操作系统级缓存，节省内存资源，避免内存资源争用;
避免文件系统级维护开销，如文件系统需维护超级块、I-node等;
避免了操作系统cache预读功能，减少了I/O请求
使用裸设备的缺点是：&lt;/p&gt;&lt;p&gt;数据管理、空间管理不灵活，需要很专业的人来操作。&lt;/p&gt;&lt;p&gt;2.利用iostat评估磁盘性能
[root@webserver ~]# iostat -d 2 3&lt;/p&gt;&lt;p&gt;Linux
 2.6.9-42.ELsmp (webserver) 12/01/2008_i686_
 (8 CPU)&lt;/p&gt;&lt;p&gt;Device:
 tps Blk_read/sBlk_wrtn/sBlk_read
 Blk_wrtn&lt;/p&gt;&lt;p&gt;sda 1.87 2.58 114.12 6479462 286537372&lt;/p&gt;&lt;p&gt;Device:
 tps Blk_read/sBlk_wrtn/sBlk_read
 Blk_wrtn&lt;/p&gt;&lt;p&gt;sda
 0.00 0.00 0.00 0 0&lt;/p&gt;&lt;p&gt;Device:
 tps Blk_read/sBlk_wrtn/sBlk_read
 Blk_wrtn&lt;/p&gt;&lt;p&gt;sda
 1.00 0.00 12.00 0 24
解释如下：&lt;/p&gt;&lt;p&gt;Blk_read/s--每秒读取数据块数
Blk_wrtn/s--每秒写入数据块数
Blk_read--读取的所有块数
Blk_wrtn--写入的所有块数
可通过Blk_read/s和Blk_wrtn/s值对磁盘的读写性能有一个基本的了解.
如Blk_wrtn/s值很大，表示磁盘写操作频繁，考虑优化磁盘或程序，
如Blk_read/s值很大，表示磁盘直接读操作很多，可将读取的数据放入内存&lt;/p&gt;&lt;p&gt;规则遵循：&lt;/p&gt;&lt;p&gt;长期的、超大的数据读写，肯定是不正常的，这种情况一定会影响系统性能。&lt;/p&gt;&lt;p&gt;3.利用sar评估磁盘性能
通过“sar –d”组合，可以对系统的磁盘IO做一个基本的统计，请看下面的一个输出：&lt;/p&gt;&lt;p&gt;[root@webserver ~]# sar -d 2 3&lt;/p&gt;&lt;p&gt;Linux
 2.6.9-42.ELsmp (webserver) 11/30/2008_i686_
 (8 CPU)&lt;/p&gt;&lt;p&gt;11:09:33
 PM DEV tps rd_sec/swr_sec/savgrq-sz
 avgqu-sz await svctm %util&lt;/p&gt;&lt;p&gt;11:09:35
 PM dev8-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00&lt;/p&gt;&lt;p&gt;11:09:35
 PM DEV tps rd_sec/swr_sec/savgrq-sz
 avgqu-sz await svctm %util&lt;/p&gt;&lt;p&gt;11:09:37
 PM dev8-0 1.00 0.00 12.00 12.00 0.00 0.00 0.00 0.00&lt;/p&gt;&lt;p&gt;11:09:37
 PM DEV tps rd_sec/swr_sec/savgrq-sz
 avgqu-sz await svctm %util&lt;/p&gt;&lt;p&gt;11:09:39
 PM dev8-0 1.99 0.00 47.76 24.00 0.00 0.50 0.25 0.05&lt;/p&gt;&lt;p&gt;Average:
 DEV tps rd_sec/swr_sec/savgrq-sz
 avgqu-sz await svctm %util&lt;/p&gt;&lt;p&gt;Average:
 dev8-0 1.00 0.00 19.97 20.00 0.00 0.33 0.17 0.02
参数含义：&lt;/p&gt;&lt;p&gt;await--平均每次设备I/O操作等待时间（毫秒）
svctm--平均每次设备I/O操作的服务时间（毫秒）
%util--一秒中有百分之几的时间用于I/O操作
对磁盘IO性能评判标准：&lt;/p&gt;&lt;p&gt;正常svctm应小于await值，而svctm和磁盘性能有关，CPU、内存负荷也会对svctm值造成影响，过多的请求也会间接的导致svctm值的增加。&lt;/p&gt;&lt;p&gt;await值取决svctm和I/O队列长度以及I/O请求模式，
如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，
如果await的值远高于svctm的值，则表示I/O队列等待太长，系统上运行的应用程序将变慢，
此时可以通过更换更快的硬盘来解决问题。
%util--衡量磁盘I/O重要指标，&lt;/p&gt;&lt;p&gt;如%util接近100%，表示磁盘产生的I/O请求太多，I/O系统已经满负荷工作，该磁盘可能存在瓶颈。&lt;/p&gt;&lt;p&gt;可优化程序或者 通过更换 更高、更快的磁盘。&lt;/p&gt;&lt;p&gt;2.5.1. 网络性能评估
（1）通过ping命令检测网络的连通性
（2）通过netstat –i组合检测网络接口状况
（3）通过netstat –r组合检测系统的路由表信息
（4）通过sar –n组合显示系统的网络运行状态
三 Linux服务器性能调优
1.为磁盘I/O调整Linux内核电梯算法
选择文件系统后，该算法可以平衡低延迟需求，收集足够数据，有效组织对磁盘读写请求。&lt;/p&gt;&lt;p&gt;2.禁用不必要的守护进程，节省内存和CPU资源
许多守护进程或服务通常非必需，消耗宝贵内存和CPU时间。将服务器置于险地。
禁用可加快启动时间，释放内存。&lt;/p&gt;&lt;p&gt;减少CPU要处理的进程数
一些应被禁用的Linux守护进程，默认自动运行：&lt;/p&gt;&lt;p&gt;序号 守护进程 描述
1 Apmd 高级电源管理守护进程
2 Nfslock 用于NFS文件锁定
3 Isdn ISDN Moderm支持
4 Autofs 在后台自动挂载文件系统(如自动挂载CD-ROM)
5 Sendmail 邮件传输代理
6 Xfs X Window的字体服务器&lt;/p&gt;&lt;p&gt;3.关掉GUI
4、清理不需要的模块或功能
服务器软件包中太多被启动的功能或模块实际上是不需要的(如Apache中的许多功能模块)，禁用掉有助于提高系统内存可用量，腾出资源给那些真正需要的软件，让它们运行得更快。&lt;/p&gt;&lt;p&gt;5、禁用控制面板
在Linux中，有许多流行的控制面板，如Cpanel，Plesk，Webmin和phpMyAdmin等，禁用释放出大约120MB内存，内存使用量大约下降30-40%。&lt;/p&gt;&lt;p&gt;6、改善Linux Exim服务器性能
使用DNS缓存守护进程，可降低解析DNS记录需要的带宽和CPU时间，DNS缓存通过消除每次都从根节点开始查找DNS记录的需求，从而改善网络性能。&lt;/p&gt;&lt;p&gt;Djbdns是一个非常强大的DNS服务器，它具有DNS缓存功能，Djbdns比BIND DNS服务器更安全，性能更好，可以直接通过&lt;a href="http://cr.yp.to/%E4%B8%8B%E8%BD%BD%EF%BC%8C%E6%88%96%E9%80%9A%E8%BF%87Red"&gt;http://cr.yp.to/%E4%B8%8B%E8%BD%BD%EF%BC%8C%E6%88%96%E9%80%9A%E8%BF%87Red&lt;/a&gt; Hat提供的软件包获得。&lt;/p&gt;&lt;p&gt;7、使用AES256增强gpg文件加密安全
为提高备份文件或敏感信息安全，许多Linux系统管理员都使用gpg进行加密，在使用gpg时，最好指定gpg使用AES256加密算法，AES256使用256位密钥，它是一个开放的加密算法，美国国家安全局(NSA)使用它保护绝密信息。&lt;/p&gt;&lt;p&gt;8、远程备份服务安全
安全是选择远程备份服务最重要的因素，大多数系统管理员都害怕两件事：(黑客)可以删除备份文件，不能从备份恢复系统。&lt;/p&gt;&lt;p&gt;为了保证备份文件100%的安全，备份服务公司提供远程备份服务器，使用scp脚本或RSYNC通过SSH传输数据，这样，没有人可以直接进入和访问远程系统，因此，也没有人可以从备份服务删除数据。在选择远程备份服务提供商时，最好从多个方面了解其服务强壮性，如果可以，可以亲自测试一下。&lt;/p&gt;&lt;p&gt;9、更新默认内核参数设置
为了顺利和成功运行企业应用程序，如数据库服务器，可能需要更新一些默认的内核参数设置，例如，2.4.x系列内核消息队列参数msgmni有一个默认值(例如，共享内存，或shmmax在Red Hat系统上默认只有33554432字节)，它只允许有限的数据库并发连接，下面为数据库服务器更好地运行提供了一些建议值(来自IBM DB2支持网站)：&lt;/p&gt;&lt;p&gt;kernel.shmmax=268435456 (32位)
kernel.shmmax=1073741824 (64位)
kernel.msgmni=1024
fs.file-max=8192
kernel.sem=”250 32000 32 1024″&lt;/p&gt;&lt;p&gt;10、优化TCP
优化TCP协议有助于提高网络吞吐量，跨广域网的通信使用的带宽越大，延迟时间越长时，建议使用越大的TCP Linux大小，以提高数据传输速率，TCP Linux大小决定了发送主机在没有收到数据传输确认时，可以向接收主机发送多少数据。&lt;/p&gt;&lt;p&gt;11、选择正确的文件系统
使用ext4文件系统取代ext3&lt;/p&gt;&lt;p&gt;● Ext4是ext3文件系统的增强版，扩展了存储限制&lt;/p&gt;&lt;p&gt;●具有日志功能，保证高水平的数据完整性(在非正常关闭事件中)&lt;/p&gt;&lt;p&gt;●非正常关闭和重启时，它不需要检查磁盘(这是一个非常耗时的动作)&lt;/p&gt;&lt;p&gt;●更快的写入速度，ext4日志优化了硬盘磁头动作&lt;/p&gt;&lt;p&gt;12、使用noatime文件系统挂载选项
在文件系统启动配置文件fstab中使用noatime选项，如果使用了外部存储，这个挂载选项可以有效改善性能。&lt;/p&gt;&lt;p&gt;13、调整Linux文件描述符限制
Linux限制了任何进程可以打开的文件描述符数量，默认限制是每进程1024，这些限制可能会阻碍基准测试客户端(如httperf和apachebench)和Web服务器本身获得最佳性能，Apache每个连接使用一个进程，因此不会受到影响，但单进程Web服务器，如Zeus是每连接使用一个文件描述符，因此很容易受默认限制的影响。&lt;/p&gt;&lt;p&gt;打开文件限制是一个可以用ulimit命令调整的限制，ulimit -aS命令显示当前的限制，ulimit -aH命令显示硬限制(在未调整/proc中的内核参数前，你不能增加限制)。&lt;/p&gt;&lt;p&gt;Linux第三方应用程序性能技巧&lt;/p&gt;&lt;p&gt;对于运行在Linux上的第三方应用程序，一样有许多性能优化技巧，这些技巧可以帮助你提高Linux服务器的性能，降低运行成本。&lt;/p&gt;&lt;p&gt;14、正确配置MySQL
为了给MySQL分配更多的内存，可设置MySQL缓存大小，要是MySQL服务器实例使用了更多内存，就减少缓存大小，如果MySQL在请求增多时停滞不动，就增加MySQL缓存。&lt;/p&gt;&lt;p&gt;15、正确配置Apache
检查Apache使用了多少内存，再调整StartServers和MinSpareServers参数，以释放更多的内存，将有助于你节省30-40%的内存。&lt;/p&gt;&lt;p&gt;16、分析Linux服务器性能
提高系统效率最好的办法是找出导致整体速度下降的瓶颈并解决掉，下面是找出系统关键瓶颈的一些基本技巧：&lt;/p&gt;&lt;p&gt;● 当大型应用程序，如OpenOffice和Firefox同时运行时，计算机可能会开始变慢，内存不足的出现几率更高。&lt;/p&gt;&lt;p&gt;● 如果启动时真的很慢，可能是应用程序初次启动需要较长的加载时间，一旦启动好后运行就正常了，否则很可能是硬盘太慢了。&lt;/p&gt;&lt;p&gt;●CPU负载持续很高，内存也够用，但CPU利用率很低，可以使用CPU负载分析工具监控负载时间。&lt;/p&gt;&lt;p&gt;17、学习5个Linux性能命令
使用几个命令就可以管理Linux系统的性能了，下面列出了5个最常用的Linux性能命令，包括
top、vmstat、iostat、free和sar，它们有助于系统管理员快速解决性能问题。&lt;/p&gt;&lt;p&gt;(1)top
当前内核服务的任务，还显示许多主机状态的统计数据，默认情况下，它每隔5秒自动更新一次。
如：当前正常运行时间，系统负载，进程数量和内存使用率，&lt;/p&gt;&lt;p&gt;此外，这个命令也显示了那些使用最多CPU时间的进程(包括每个进程的各种信息，如运行用户，执行的命令等)。&lt;/p&gt;&lt;p&gt;(2)vmstat
Vmstat命令提供当前CPU、IO、进程和内存使用率的快照，它和top命令类似，自动更新数据，如：&lt;/p&gt;&lt;p&gt;$ vmstat 10&lt;/p&gt;&lt;p&gt;(3)iostat
Iostat提供三个报告：CPU利用率、设备利用率和网络文件系统利用率，使用-c，-d和-h参数可以分别独立显示这三个报告。&lt;/p&gt;&lt;p&gt;(4)free
显示主内存和交换空间内存统计数据，指定-t参数显示总内存，指定-b参数按字节为单位，使用-m则以兆为单位，默认情况下千字节为单位。&lt;/p&gt;&lt;p&gt;Free命令也可以使用-s参数加一个延迟时间(单位：秒)连续运行，如：&lt;/p&gt;&lt;p&gt;$ free -s 5&lt;/p&gt;&lt;p&gt;(5)sar
收集，查看和记录性能数据，这个命令比前面几个命令历史更悠久，它可以收集和显示较长周期的数据。&lt;/p&gt;&lt;p&gt;其它&lt;/p&gt;&lt;p&gt;下面是一些归类为其它的性能技巧：&lt;/p&gt;&lt;p&gt;18、将日志文件转移到内存中
当一台机器处于运行中时，最好是将系统日志放在内存中，当系统关闭时再将其复制到硬盘，当你运行一台开启了syslog功能的笔记本电脑或移动设备时，ramlog可以帮助你提高系统电池或移动设备闪存驱动器的寿命，使用ramlog的一个好处是，不用再担心某个守护进程每隔30秒向syslog发送一条消息，放在以前，硬盘必须随时保持运转，这样对硬盘和电池都不好。&lt;/p&gt;&lt;p&gt;19、先打包，后写入
在内存中划分出固定大小的空间保存日志文件，这意味着笔记本电脑硬盘不用一直保持运转，只有当某个守护进程需要写入日志时才运转，注意ramlog使用的内存空间大小是固定的，否则系统内存会很快被用光，如果笔记本使用固态硬盘，可以分配50-80MB内存给ramlog使用，ramlog可以减少许多写入周期，极大地提高固态硬盘的使用寿命。&lt;/p&gt;&lt;p&gt;20、一般调优技巧
尽可能使用静态内容替代动态内容，如果你在生成天气预告，或其它每隔1小时就必须更新的数据，最好是写一个程序，每隔1小时生成一个静态的文件，而不是让用户运行一个CGI动态地生成报告。&lt;/p&gt;&lt;p&gt;为动态应用程序选择最快最合适的API，CGI可能最容易编程，但它会为每个请求产生一个进程，通常，这是一个成本很高，且不必要的过程，FastCGI是更好的选择，和Apache的mod_perl一样，都可以极大地提高应用程序的性能。&lt;/p&gt;</description><author>1959376918@qq.com (刘胜琪)</author><guid isPermaLink="true">/Blog/archives/Linux%E6%80%A7%E8%83%BD%E6%9F%A5%E7%9C%8B/</guid><pubDate>Sat, 27 Nov 2021 00:00:00 +0806</pubDate></item></channel></rss>