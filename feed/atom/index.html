<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-CN"><id>/Blog/</id><title>我的个人博客</title><updated>2021-11-19T13:06:49.825039+08:06</updated><author><name>LSQ</name><email>1959376918@qq.com</email></author><link href="/Blog/" rel="alternate"/><generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator><logo>https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/f-logo.png</logo><subtitle>记录生活美好</subtitle><entry><id>/Blog/archives/camera-shooting/</id><title>摄影构图</title><updated>2021-11-19T13:06:49.825582+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;摄影&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;两边阴影，中间光亮突出重点，突出图片主体。&lt;/p&gt;&lt;p&gt;be open-minded&lt;/p&gt;</content><link href="/Blog/archives/camera-shooting/" rel="alternate"/><published>2021-10-06T00:00:00+08:06</published></entry><entry><id>/Blog/archives/Out%20of%20Control/</id><title>失控玩家</title><updated>2021-11-19T13:06:49.825536+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;失控玩家&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;欢快搞笑的快节奏电影，引入游戏视角，思考人存在的意义。&lt;/p&gt;&lt;p&gt;主要围绕游戏中的世界线，反思什么是存在的，什么是活着的。“我思故我在”，个体意识被强烈地放大，不在意是否自己的世界是不是存在的。电影中运用了大量特效场景，非常壮观宏大的场面，夹杂了一点点的人物感情，最后便是一个happy ending。不是特别深沉的题材，更偏向于科幻风，但想表达和反思的内容过多，是励志但却并没有真正振聋发聩的效果。&lt;/p&gt;</content><link href="/Blog/archives/Out%20of%20Control/" rel="alternate"/><published>2021-10-08T00:00:00+08:06</published></entry><entry><id>/Blog/archives/3DtrackingOnNuScences/</id><title>Tracking 实验结果</title><updated>2021-11-19T13:06:49.825496+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Tracking 实验结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;mini dataset上&lt;/p&gt;&lt;p&gt;==detection结果==&lt;/p&gt;&lt;p&gt;Saving metrics to: work_dirs/nusc_nsweep_10
mAP: 0.6720
mATE: 0.2821
mASE: 0.2995
mAOE: 0.2497
mAVE: 0.3732
mAAE: 0.3550
NDS: 0.6801
Eval time: 6.3s&lt;/p&gt;&lt;p&gt;Per-class results:
Object Class    AP      ATE     ASE     AOE     AVE     AAE
car     0.864   0.176   0.154   0.120   0.230   0.121
truck   0.656   0.275   0.165   0.018   0.103   0.386
bus     0.760   0.255   0.150   0.028   0.810   0.195
trailer 0.989   0.220   0.274   0.008   0.007   1.000
construction_vehicle    0.000   1.000   1.000   1.000   1.000   1.000
pedestrian      0.933   0.129   0.244   0.247   0.210   0.104
motorcycle      0.744   0.212   0.245   0.350   0.083   0.033
bicycle 0.493   0.167   0.254   0.454   0.542   0.001
traffic_cone    0.496   0.077   0.268   nan     nan     nan
barrier 0.785   0.310   0.241   0.022   nan     nan
Evaluation nusc: Nusc v1.0-trainval Evaluation
car Nusc dist AP@0.5, 1.0, 2.0, 4.0
77.57, 86.67, 89.92, 91.40 mean AP: 0.8639023655074297
truck Nusc dist AP@0.5, 1.0, 2.0, 4.0
62.22, 64.92, 66.75, 68.44 mean AP: 0.6558199662311992
construction_vehicle Nusc dist AP@0.5, 1.0, 2.0, 4.0
0.00, 0.00, 0.00, 0.00 mean AP: 0.0
bus Nusc dist AP@0.5, 1.0, 2.0, 4.0
66.41, 76.28, 79.49, 81.99 mean AP: 0.7604156206303931
trailer Nusc dist AP@0.5, 1.0, 2.0, 4.0
98.89, 98.89, 98.89, 98.89 mean AP: 0.9889229245954395
barrier Nusc dist AP@0.5, 1.0, 2.0, 4.0
53.24, 76.08, 92.29, 92.29 mean AP: 0.7847208664826456
motorcycle Nusc dist AP@0.5, 1.0, 2.0, 4.0
65.55, 74.64, 78.30, 79.07 mean AP: 0.7439005900622773
bicycle Nusc dist AP@0.5, 1.0, 2.0, 4.0
48.41, 49.64, 49.64, 49.64 mean AP: 0.49334568921118616
pedestrian Nusc dist AP@0.5, 1.0, 2.0, 4.0
91.38, 92.83, 93.79, 95.25 mean AP: 0.9331069588049957
traffic_cone Nusc dist AP@0.5, 1.0, 2.0, 4.0
49.02, 49.02, 49.02, 51.44 mean AP: 0.49623772316396364&lt;/p&gt;&lt;p&gt;==tracking结果==&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;greeding&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Calculating metrics...
Saving metrics to: ./work_dirs/track/10_greedy&lt;/p&gt;&lt;h3&gt;Final results&lt;/h3&gt;
&lt;p&gt;Per-class results:
                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML      FAF     TP      FP      FN      IDS     FRAG    TID    LGD
bicycle         0.412   0.552   0.448   0.808   58      0.362   0.155   2       4       12.8    26      5       32      0       0       0.12   1.75
bus             0.812   0.571   0.826   0.958   86      0.791   0.298   3       0       4.6     71      3       15      0       2       0.90   1.10
car             0.807   0.438   0.863   0.861   2729    0.735   0.277   109     27      199.4   2328    323     374     27      20      0.36   0.59
motorcy         0.736   0.547   0.702   0.952   238     0.660   0.342   7       3       12.5    165     8       71      2       1       0.39   2.00
pedestr         0.850   0.316   0.848   0.895   1470    0.750   0.302   61      16      98.5    1231    129     223     16      5       0.46   0.76
trailer         1.000   0.210   1.000   1.000   41      1.000   0.210   1       0       0.0     41      0       0       0       0       0.00   0.00
truck           0.536   0.506   0.723   0.617   177     0.446   0.295   5       4       41.5    128     49      49      0       1       0.10   0.20&lt;/p&gt;&lt;p&gt;Aggregated results:
AMOTA   0.736
AMOTP   0.448
RECALL  0.773
MOTAR   0.870
GT      685
MOTA    0.678
MOTP    0.268
MT      188
ML      54
FAF     52.8
TP      3990
FP      517
FN      764
IDS     45
FRAG    29
TID     0.33
LGD     0.92
Eval time: 104.7s&lt;/p&gt;&lt;p&gt;Rendering curves&lt;/p&gt;&lt;ol start="2"&gt;
&lt;li&gt;&lt;p&gt;cost&lt;/p&gt;&lt;p&gt;设定的threshold为0.5&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
  &lt;th&gt;K的值&lt;/th&gt;
  &lt;th&gt;未训练结果&lt;/th&gt;
  &lt;th&gt;训练结果&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
  &lt;td&gt;4&lt;/td&gt;
  &lt;td&gt;Per-class results:&lt;br/&gt;                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML      FAF     TP      FP      FN      IDS     FRAG    TID    LGD&lt;br/&gt;bicycle         0.000   1.908   0.621   0.000   58      0.000   0.172   3       1       80.8    7       59      22      29      4       0.14   0.93&lt;br/&gt;bus             0.000   2.000   0.000   0.000   86      0.000   2.000   0       5       500.0   0       nan     86      nan     nan     20.00  20.00&lt;br/&gt;car             0.000   2.000   0.000   0.000   2729    0.000   2.000   0       154     500.0   0       nan     2729    nan     nan     20.00  20.00&lt;br/&gt;motorcy         0.000   2.000   0.000   0.000   238     0.000   2.000   0       11      500.0   0       nan     238     nan     nan     20.00  20.00&lt;br/&gt;pedestr         0.000   2.000   0.000   0.000   1470    0.000   2.000   0       85      500.0   0       nan     1470    nan     nan     20.00  20.00&lt;br/&gt;trailer         0.000   2.000   0.000   0.000   41      0.000   2.000   0       1       500.0   0       nan     41      nan     nan     20.00  20.00&lt;br/&gt;truck           0.000   2.000   0.000   0.000   177     0.000   2.000   0       9       500.0   0       nan     177     nan     nan     20.00  20.00&lt;br/&gt;&lt;br/&gt;Aggregated results:&lt;br/&gt;AMOTA   0.000&lt;br/&gt;AMOTP   1.987&lt;br/&gt;RECALL  0.089&lt;br/&gt;MOTAR   0.000&lt;br/&gt;GT      685&lt;br/&gt;MOTA    0.000&lt;br/&gt;MOTP    1.739&lt;br/&gt;MT      3&lt;br/&gt;ML      266&lt;br/&gt;FAF     440.1&lt;br/&gt;TP      7&lt;br/&gt;FP      59&lt;br/&gt;FN      4763&lt;br/&gt;IDS     29&lt;br/&gt;FRAG    4&lt;br/&gt;TID     17.16&lt;br/&gt;LGD     17.28&lt;br/&gt;Eval time: 9.8s&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;8&lt;/td&gt;
  &lt;td&gt;Per-class results:&lt;br/&gt;                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML      FAF     TP      FP      FN      IDS     FRAG    TID    LGD&lt;br/&gt;bicycle         0.000   1.908   0.621   0.000   58      0.000   0.172   3       1       80.8    7       59      22      29      4       0.14   0.93&lt;br/&gt;bus             0.000   2.000   0.000   0.000   86      0.000   2.000   0       5       500.0   0       nan     86      nan     nan     20.00  20.00&lt;br/&gt;car             0.000   2.000   0.000   0.000   2729    0.000   2.000   0       154     500.0   0       nan     2729    nan     nan     20.00  20.00&lt;br/&gt;motorcy         0.000   2.000   0.000   0.000   238     0.000   2.000   0       11      500.0   0       nan     238     nan     nan     20.00  20.00&lt;br/&gt;pedestr         0.000   2.000   0.000   0.000   1470    0.000   2.000   0       85      500.0   0       nan     1470    nan     nan     20.00  20.00&lt;br/&gt;trailer         0.000   2.000   0.000   0.000   41      0.000   2.000   0       1       500.0   0       nan     41      nan     nan     20.00  20.00&lt;br/&gt;truck           0.000   2.000   0.000   0.000   177     0.000   2.000   0       9       500.0   0       nan     177     nan     nan     20.00  20.00&lt;br/&gt;&lt;br/&gt;Aggregated results:&lt;br/&gt;AMOTA   0.000&lt;br/&gt;AMOTP   1.987&lt;br/&gt;RECALL  0.089&lt;br/&gt;MOTAR   0.000&lt;br/&gt;GT      685&lt;br/&gt;MOTA    0.000&lt;br/&gt;MOTP    1.739&lt;br/&gt;MT      3&lt;br/&gt;ML      266&lt;br/&gt;FAF     440.1&lt;br/&gt;TP      7&lt;br/&gt;FP      59&lt;br/&gt;FN      4763&lt;br/&gt;IDS     29&lt;br/&gt;FRAG    4&lt;br/&gt;TID     17.16&lt;br/&gt;LGD     17.28&lt;br/&gt;Eval time: 9.8s&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;12&lt;/td&gt;
  &lt;td&gt;Per-class results:&lt;br/&gt;                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML      FAF     TP      FP      FN      IDS     FRAG    TID    LGD&lt;br/&gt;bicycle         0.000   1.908   0.621   0.000   58      0.000   0.172   3       1       80.8    7       59      22      29      4       0.14   0.93&lt;br/&gt;bus             0.000   2.000   0.000   0.000   86      0.000   2.000   0       5       500.0   0       nan     86      nan     nan     20.00  20.00&lt;br/&gt;car             0.000   2.000   0.000   0.000   2729    0.000   2.000   0       154     500.0   0       nan     2729    nan     nan     20.00  20.00&lt;br/&gt;motorcy         0.000   2.000   0.000   0.000   238     0.000   2.000   0       11      500.0   0       nan     238     nan     nan     20.00  20.00&lt;br/&gt;pedestr         0.000   2.000   0.000   0.000   1470    0.000   2.000   0       85      500.0   0       nan     1470    nan     nan     20.00  20.00&lt;br/&gt;trailer         0.000   2.000   0.000   0.000   41      0.000   2.000   0       1       500.0   0       nan     41      nan     nan     20.00  20.00&lt;br/&gt;truck           0.000   2.000   0.000   0.000   177     0.000   2.000   0       9       500.0   0       nan     177     nan     nan     20.00  20.00&lt;br/&gt;&lt;br/&gt;Aggregated results:&lt;br/&gt;AMOTA   0.000&lt;br/&gt;AMOTP   1.987&lt;br/&gt;RECALL  0.089&lt;br/&gt;MOTAR   0.000&lt;br/&gt;GT      685&lt;br/&gt;MOTA    0.000&lt;br/&gt;MOTP    1.739&lt;br/&gt;MT      3&lt;br/&gt;ML      266&lt;br/&gt;FAF     440.1&lt;br/&gt;TP      7&lt;br/&gt;FP      59&lt;br/&gt;FN      4763&lt;br/&gt;IDS     29&lt;br/&gt;FRAG    4&lt;br/&gt;TID     17.16&lt;br/&gt;LGD     17.28&lt;br/&gt;Eval time: 10.0s&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;16&lt;/td&gt;
  &lt;td&gt;Per-class results:&lt;br/&gt;                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML      FAF     TP      FP      FN      IDS     FRAG    TID    LGD&lt;br/&gt;bicycle         0.000   1.908   0.621   0.000   58      0.000   0.172   3       1       80.8    7       59      22      29      4       0.14   0.93&lt;br/&gt;bus             0.000   2.000   0.000   0.000   86      0.000   2.000   0       5       500.0   0       nan     86      nan     nan     20.00  20.00&lt;br/&gt;car             0.000   2.000   0.000   0.000   2729    0.000   2.000   0       154     500.0   0       nan     2729    nan     nan     20.00  20.00&lt;br/&gt;motorcy         0.000   2.000   0.000   0.000   238     0.000   2.000   0       11      500.0   0       nan     238     nan     nan     20.00  20.00&lt;br/&gt;pedestr         0.000   2.000   0.000   0.000   1470    0.000   2.000   0       85      500.0   0       nan     1470    nan     nan     20.00  20.00&lt;br/&gt;trailer         0.000   2.000   0.000   0.000   41      0.000   2.000   0       1       500.0   0       nan     41      nan     nan     20.00  20.00&lt;br/&gt;truck           0.000   2.000   0.000   0.000   177     0.000   2.000   0       9       500.0   0       nan     177     nan     nan     20.00  20.00&lt;br/&gt;&lt;br/&gt;Aggregated results:&lt;br/&gt;AMOTA   0.000&lt;br/&gt;AMOTP   1.987&lt;br/&gt;RECALL  0.089&lt;br/&gt;MOTAR   0.000&lt;br/&gt;GT      685&lt;br/&gt;MOTA    0.000&lt;br/&gt;MOTP    1.739&lt;br/&gt;MT      3&lt;br/&gt;ML      266&lt;br/&gt;FAF     440.1&lt;br/&gt;TP      7&lt;br/&gt;FP      59&lt;br/&gt;FN      4763&lt;br/&gt;IDS     29&lt;br/&gt;FRAG    4&lt;br/&gt;TID     17.16&lt;br/&gt;LGD     17.28&lt;br/&gt;Eval time: 9.8s&lt;/td&gt;
  &lt;td&gt;Per-class results:&lt;br/&gt;                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML      FAF     TP      FP      FN      IDS     FRAG    TID    LGD&lt;br/&gt;bicycle         0.199   1.051   0.397   0.667   58      0.241   0.182   2       5       16.3    21      7       35      2       1       0.38   1.88&lt;br/&gt;bus             0.366   1.340   0.558   1.000   86      0.395   0.228   2       2       0.0     34      0       38      14      1       2.88   2.88&lt;br/&gt;car             0.126   1.688   0.678   0.850   2729    0.168   0.207   66      32      50.0    540     81      879     1310    104     1.21   1.89&lt;br/&gt;motorcy         0.000   2.000   0.000   0.000   238     0.000   2.000   0       11      500.0   0       nan     238     nan     nan     20.00  20.00&lt;br/&gt;pedestr         0.018   1.861   0.810   0.619   1470    0.076   0.144   48      10      53.1    181     69      279     1010    60      0.45   0.98&lt;br/&gt;trailer         0.799   0.298   0.829   1.000   41      0.829   0.208   1       0       0.0     34      0       7       0       0       3.50   3.50&lt;br/&gt;truck           0.196   1.582   0.401   0.980   177     0.277   0.311   1       6       0.8     50      1       106     21      8       2.50   4.00&lt;br/&gt;&lt;br/&gt;Aggregated results:&lt;br/&gt;AMOTA   0.243&lt;br/&gt;AMOTP   1.403&lt;br/&gt;RECALL  0.525&lt;br/&gt;MOTAR   0.731&lt;br/&gt;GT      685&lt;br/&gt;MOTA    0.284&lt;br/&gt;MOTP    0.469&lt;br/&gt;MT      120&lt;br/&gt;ML      66&lt;br/&gt;FAF     88.6&lt;br/&gt;TP      860&lt;br/&gt;FP      158&lt;br/&gt;FN      1582&lt;br/&gt;IDS     2357&lt;br/&gt;FRAG    174&lt;br/&gt;TID     4.42&lt;br/&gt;LGD     5.02&lt;br/&gt;Eval time: 27.2s，有提升，但是是否泛用，有待猜测&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;没有训练的测试时有时没有recall值设置&lt;/p&gt;&lt;p&gt;只跟踪同类物体&lt;/p&gt;&lt;ol start="2"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
  &lt;th&gt;K的值&lt;/th&gt;
  &lt;th&gt;未训练结果&lt;/th&gt;
  &lt;th&gt;训练结果&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
  &lt;td&gt;4&lt;/td&gt;
  &lt;td&gt;Per-class results:&lt;br/&gt;                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML      FAF     TP      FP      FN      IDS     FRAG    TID    LGD&lt;br/&gt;bicycle         0.000   1.908   0.621   0.000   58      0.000   0.172   3       1       80.8    7       59      22      29      4       0.14   0.93&lt;br/&gt;bus             0.000   2.000   0.000   0.000   86      0.000   2.000   0       5       500.0   0       nan     86      nan     nan     20.00  20.00&lt;br/&gt;car             0.000   2.000   0.000   0.000   2729    0.000   2.000   0       154     500.0   0       nan     2729    nan     nan     20.00  20.00&lt;br/&gt;motorcy         0.000   2.000   0.000   0.000   238     0.000   2.000   0       11      500.0   0       nan     238     nan     nan     20.00  20.00&lt;br/&gt;pedestr         0.000   2.000   0.000   0.000   1470    0.000   2.000   0       85      500.0   0       nan     1470    nan     nan     20.00  20.00&lt;br/&gt;trailer         0.000   2.000   0.000   0.000   41      0.000   2.000   0       1       500.0   0       nan     41      nan     nan     20.00  20.00&lt;br/&gt;truck           0.000   2.000   0.000   0.000   177     0.000   2.000   0       9       500.0   0       nan     177     nan     nan     20.00  20.00&lt;br/&gt;&lt;br/&gt;Aggregated results:&lt;br/&gt;AMOTA   0.000&lt;br/&gt;AMOTP   1.987&lt;br/&gt;RECALL  0.089&lt;br/&gt;MOTAR   0.000&lt;br/&gt;GT      685&lt;br/&gt;MOTA    0.000&lt;br/&gt;MOTP    1.739&lt;br/&gt;MT      3&lt;br/&gt;ML      266&lt;br/&gt;FAF     440.1&lt;br/&gt;TP      7&lt;br/&gt;FP      59&lt;br/&gt;FN      4763&lt;br/&gt;IDS     29&lt;br/&gt;FRAG    4&lt;br/&gt;TID     17.16&lt;br/&gt;LGD     17.28&lt;br/&gt;Eval time: 9.8s&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;8&lt;/td&gt;
  &lt;td&gt;Per-class results:&lt;br/&gt;                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML      FAF     TP      FP      FN      IDS     FRAG    TID    LGD&lt;br/&gt;bicycle         0.000   1.908   0.621   0.000   58      0.000   0.172   3       1       80.8    7       59      22      29      4       0.14   0.93&lt;br/&gt;bus             0.000   2.000   0.000   0.000   86      0.000   2.000   0       5       500.0   0       nan     86      nan     nan     20.00  20.00&lt;br/&gt;car             0.000   2.000   0.000   0.000   2729    0.000   2.000   0       154     500.0   0       nan     2729    nan     nan     20.00  20.00&lt;br/&gt;motorcy         0.000   2.000   0.000   0.000   238     0.000   2.000   0       11      500.0   0       nan     238     nan     nan     20.00  20.00&lt;br/&gt;pedestr         0.000   2.000   0.000   0.000   1470    0.000   2.000   0       85      500.0   0       nan     1470    nan     nan     20.00  20.00&lt;br/&gt;trailer         0.000   2.000   0.000   0.000   41      0.000   2.000   0       1       500.0   0       nan     41      nan     nan     20.00  20.00&lt;br/&gt;truck           0.000   2.000   0.000   0.000   177     0.000   2.000   0       9       500.0   0       nan     177     nan     nan     20.00  20.00&lt;br/&gt;&lt;br/&gt;Aggregated results:&lt;br/&gt;AMOTA   0.000&lt;br/&gt;AMOTP   1.987&lt;br/&gt;RECALL  0.089&lt;br/&gt;MOTAR   0.000&lt;br/&gt;GT      685&lt;br/&gt;MOTA    0.000&lt;br/&gt;MOTP    1.739&lt;br/&gt;MT      3&lt;br/&gt;ML      266&lt;br/&gt;FAF     440.1&lt;br/&gt;TP      7&lt;br/&gt;FP      59&lt;br/&gt;FN      4763&lt;br/&gt;IDS     29&lt;br/&gt;FRAG    4&lt;br/&gt;TID     17.16&lt;br/&gt;LGD     17.28&lt;br/&gt;Eval time: 9.8s&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;12&lt;/td&gt;
  &lt;td&gt;Per-class results:&lt;br/&gt;                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML      FAF     TP      FP      FN      IDS     FRAG    TID    LGD&lt;br/&gt;bicycle         0.000   1.908   0.621   0.000   58      0.000   0.172   3       1       80.8    7       59      22      29      4       0.14   0.93&lt;br/&gt;bus             0.000   2.000   0.000   0.000   86      0.000   2.000   0       5       500.0   0       nan     86      nan     nan     20.00  20.00&lt;br/&gt;car             0.000   2.000   0.000   0.000   2729    0.000   2.000   0       154     500.0   0       nan     2729    nan     nan     20.00  20.00&lt;br/&gt;motorcy         0.000   2.000   0.000   0.000   238     0.000   2.000   0       11      500.0   0       nan     238     nan     nan     20.00  20.00&lt;br/&gt;pedestr         0.000   2.000   0.000   0.000   1470    0.000   2.000   0       85      500.0   0       nan     1470    nan     nan     20.00  20.00&lt;br/&gt;trailer         0.000   2.000   0.000   0.000   41      0.000   2.000   0       1       500.0   0       nan     41      nan     nan     20.00  20.00&lt;br/&gt;truck           0.000   2.000   0.000   0.000   177     0.000   2.000   0       9       500.0   0       nan     177     nan     nan     20.00  20.00&lt;br/&gt;&lt;br/&gt;Aggregated results:&lt;br/&gt;AMOTA   0.000&lt;br/&gt;AMOTP   1.987&lt;br/&gt;RECALL  0.089&lt;br/&gt;MOTAR   0.000&lt;br/&gt;GT      685&lt;br/&gt;MOTA    0.000&lt;br/&gt;MOTP    1.739&lt;br/&gt;MT      3&lt;br/&gt;ML      266&lt;br/&gt;FAF     440.1&lt;br/&gt;TP      7&lt;br/&gt;FP      59&lt;br/&gt;FN      4763&lt;br/&gt;IDS     29&lt;br/&gt;FRAG    4&lt;br/&gt;TID     17.16&lt;br/&gt;LGD     17.28&lt;br/&gt;Eval time: 10.0s&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;16&lt;/td&gt;
  &lt;td&gt;Per-class results:&lt;br/&gt;                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML      FAF     TP      FP      FN      IDS     FRAG    TID    LGD&lt;br/&gt;bicycle         0.435   0.671   0.552   0.688   58      0.379   0.192   2       4       25.0    32      10      26      0       0       0.20   1.60&lt;br/&gt;bus             0.787   0.568   0.814   0.900   86      0.733   0.294   3       0       10.3    70      7       16      0       3       0.90   1.10&lt;br/&gt;car             0.793   0.435   0.837   0.847   2729    0.702   0.266   104     33      213.0   2262    345     446     21      16      0.48   0.73&lt;br/&gt;motorcy         0.744   0.473   0.739   0.926   238     0.681   0.317   5       2       19.7    175     13      62      1       1       0.67   1.61&lt;br/&gt;pedestr         0.782   0.445   0.796   0.912   1470    0.693   0.331   47      22      75.4    1117    98      300     53      14      0.28   0.95&lt;br/&gt;trailer         1.000   0.210   1.000   1.000   41      1.000   0.210   1       0       0.0     41      0       0       0       0       0.00   0.00&lt;br/&gt;truck           0.462   0.494   0.672   0.580   177     0.390   0.286   4       5       42.4    119     50      58      0       1       0.00   0.12&lt;br/&gt;&lt;br/&gt;Aggregated results:&lt;br/&gt;AMOTA   0.715&lt;br/&gt;AMOTP   0.471&lt;br/&gt;RECALL  0.773&lt;br/&gt;MOTAR   0.836&lt;br/&gt;GT      685&lt;br/&gt;MOTA    0.654&lt;br/&gt;MOTP    0.271&lt;br/&gt;MT      166&lt;br/&gt;ML      66&lt;br/&gt;FAF     55.1&lt;br/&gt;TP      3816&lt;br/&gt;FP      523&lt;br/&gt;FN      908&lt;br/&gt;IDS     75&lt;br/&gt;FRAG    35&lt;br/&gt;TID     0.36&lt;br/&gt;LGD     0.87&lt;br/&gt;Eval time: 106.0s&lt;/td&gt;
  &lt;td&gt;Per-class results:&lt;br/&gt;                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML      FAF     TP      FP      FN      IDS     FRAG    TID    LGD&lt;br/&gt;bicycle         0.435   0.671   0.552   0.688   58      0.379   0.192   2       4       25.0    32      10      26      0       0       0.20   1.60&lt;br/&gt;bus             0.787   0.568   0.814   0.900   86      0.733   0.294   3       0       10.3    70      7       16      0       3       0.90   1.10&lt;br/&gt;car             0.793   0.435   0.837   0.847   2729    0.702   0.266   104     33      213.0   2262    345     446     21      16      0.48   0.73&lt;br/&gt;motorcy         0.744   0.473   0.739   0.926   238     0.681   0.317   5       2       19.7    175     13      62      1       1       0.67   1.61&lt;br/&gt;pedestr         0.782   0.445   0.796   0.912   1470    0.693   0.331   47      22      75.4    1117    98      300     53      14      0.28   0.95&lt;br/&gt;trailer         1.000   0.210   1.000   1.000   41      1.000   0.210   1       0       0.0     41      0       0       0       0       0.00   0.00&lt;br/&gt;truck           0.462   0.494   0.672   0.580   177     0.390   0.286   4       5       42.4    119     50      58      0       1       0.00   0.12&lt;br/&gt;&lt;br/&gt;Aggregated results:&lt;br/&gt;AMOTA   0.715&lt;br/&gt;AMOTP   0.471&lt;br/&gt;RECALL  0.773&lt;br/&gt;MOTAR   0.836&lt;br/&gt;GT      685&lt;br/&gt;MOTA    0.654&lt;br/&gt;MOTP    0.271&lt;br/&gt;MT      166&lt;br/&gt;ML      66&lt;br/&gt;FAF     55.1&lt;br/&gt;TP      3816&lt;br/&gt;FP      523&lt;br/&gt;FN      908&lt;br/&gt;IDS     75&lt;br/&gt;FRAG    35&lt;br/&gt;TID     0.36&lt;br/&gt;LGD     0.87&lt;br/&gt;Eval time: 106.0s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;完整数据集&lt;/p&gt;&lt;h3&gt;Final results&lt;/h3&gt;
&lt;p&gt;Per-class results:
                AMOTA   AMOTP   RECALL  MOTAR   GT      MOTA    MOTP    MT      ML   FAF      TP      FP      FN      IDS     FRAG    TID     LGD
bicycle         0.230   0.819   0.387   0.626   1993    0.223   0.209   36      94   18.5     709     265     1222    62      28      1.29    2.15
bus             0.358   1.254   0.709   0.757   2112    0.313   0.390   57      23   13.6     875     213     615     622     60      1.06    1.96
car             0.554   0.790   0.744   0.799   58317   0.459   0.236   2100    944  117.0    33491   6742    14923   9903    1320    0.47    0.93
motorcy         0.346   0.948   0.526   0.744   1977    0.335   0.253   38      45   16.8     890     228     938     149     59      1.31    2.16
pedestr         0.064   1.596   0.551   0.654   25423   0.111   0.199   429     508  35.0     4331    1499    11404   9688    1756    0.95    1.92
trailer         0.321   1.093   0.462   0.628   2425    0.275   0.551   41      69   38.5     1061    395     1304    60      27      0.66    1.96
truck           0.450   0.887   0.617   0.647   9650    0.356   0.356   224     195  50.0     5310    1875    3698    642     222     0.69    1.56&lt;/p&gt;&lt;p&gt;Aggregated results:
AMOTA   0.332
AMOTP   1.055
RECALL  0.571
MOTAR   0.693
GT      14556
MOTA    0.296
MOTP    0.313
MT      2925
ML      1878
FAF     41.3
TP      46667
FP      11217
FN      34104
IDS     21126
FRAG    3472
TID     0.92
LGD     1.81
Eval time: 3569.3s&lt;/p&gt;</content><link href="/Blog/archives/3DtrackingOnNuScences/" rel="alternate"/><published>2021-10-17T00:00:00+08:06</published></entry><entry><id>/Blog/archives/blender_script/</id><title>blender script使用</title><updated>2021-11-19T13:06:49.825456+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;blender script&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;将blender中所有的button转换为代码接口，操纵物体&lt;/p&gt;&lt;p&gt;重要学习数据类型：bpy&lt;/p&gt;&lt;p&gt;bpy.data.object：打开的模型物体&lt;/p&gt;&lt;p&gt;Data is added and removed via methods on the collections in &lt;a href="https://docs.blender.org/api/current/bpy.data.html#module-bpy.data"&gt;&lt;code&gt;bpy.data&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;“poll” function which checks if the cursor is in a valid area or if the object is in the correct mode ：判断是否选择正确的操作方式&lt;/p&gt;&lt;p&gt;blender文件夹下scripts/startup/中有python的环境&lt;/p&gt;&lt;p&gt;When a script is imported as a module, its class instances will remain inside the module and can be accessed later on by importing that module again.&lt;/p&gt;&lt;p&gt;run the script：&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;blender --python /home/me/my_script.py&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;While &lt;code&gt;__init__()&lt;/code&gt; and &lt;code&gt;__del__()&lt;/code&gt; will be called if defined, the class instances lifetime only spans the execution.&lt;/p&gt;&lt;p&gt;数据保存为blender.data的格式，下次开启不会丢失&lt;/p&gt;&lt;p&gt;The register/unregister calls are used so it’s possible to toggle add-ons and reload scripts while Blender runs&lt;/p&gt;&lt;p&gt;每次重新跑，估计得重新加载选项&lt;/p&gt;&lt;p&gt;run script&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Loaded in the text editor and press &lt;em&gt;Run Script&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Typed or pasted into the interactive console.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Execute a Python file from the command line with Blender, e.g:&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;blender --python /home/me/my_script.py
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;建立子类，元素命名一般以bl_开头表示自己添加的&lt;/p&gt;&lt;p&gt;Notice these classes don’t define an &lt;code&gt;__init__(self)&lt;/code&gt; function. While &lt;code&gt;__init__()&lt;/code&gt; and &lt;code&gt;__del__()&lt;/code&gt; will be called if defined, the class instances lifetime only spans the execution&lt;/p&gt;&lt;p&gt;&lt;strong&gt;步骤&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;定义Panel面板&lt;/h2&gt;
&lt;p&gt;创建类&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TestPanel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;types&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Panel&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#创建Panel的实例&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;定义Panel类的属性&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TestPanel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;types&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Panel&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;bl_label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;LuoZhiXiang&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;bl_idname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;PT_Test Panel&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;bl_space_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;VIEW_3D&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;bl_region_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;UI&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;bl_category&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;BadGuy&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;#注意前面一定要带有bl_的前缀，否则是会报错的&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;创建Space Type （插件在哪种工作空间使用）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;注意全部要大写！它的作用就是定义这个插件是作用于哪个工作区域Workspace内。&lt;/p&gt;&lt;p&gt;可以切换测试，日志会输出相关type。&lt;/p&gt;&lt;figure style="flex: 127.63157894736842" &gt;&lt;img width="291" height="114" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/b4ecbc125d6216fc415bd62a91305102.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bl_space_type=&amp;quot;VIEW_3D&amp;quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;figure style="flex: 60.301507537688444" &gt;&lt;img width="720" height="597" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/f0a3975b5c50d3ceecb0d6e7f3ae1f78.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;设置使用区域，设置为UI即可&lt;/strong&gt;&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bl_region_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;UI&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其他种类：&lt;/p&gt;&lt;figure style="flex: 63.45609065155807" &gt;&lt;img width="448" height="353" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/5b20d1e58bc9c39cc00db43fd5941a14.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;设置&lt;strong&gt;归属类别&lt;/strong&gt;（将此Panel实例归到哪一类里面）&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bl_category&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;BadGuy&amp;quot;&lt;/span&gt; &lt;span class="c1"&gt;#SideBar Name&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;figure style="flex: 60.0" &gt;&lt;img width="720" height="600" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/3637e44f4b800e75bee53cac4372ac07.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;h1&gt;加载更新&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;register() 注册/登记/加载&lt;/li&gt;
&lt;li&gt;unregister() 不加载&lt;/li&gt;
&lt;li&gt;utils——utilities（实用工具）&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def register():
    bpy.utils.register_class(TestPanel)

def unregister():
    bpy.utils.unregister_class(TestPanel）

if __name__==&amp;quot;__main__&amp;quot;:
    register()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过直接执行脚本来扩展Blender意味着脚本完成执行后脚本定义的类在Blender中保持可用。与将脚本作为模块导入相比，以这种方式使用脚本使得将来访问其类（例如取消注册它们）变得更加困难。将脚本作为模块导入时，其类实例将保留在模块中，稍后可以通过再次导入该模块来访问。&lt;/p&gt;&lt;p&gt;bpy.data.objects返回值，第0个默认为camera，注意区别&lt;/p&gt;&lt;p&gt;输入：bpy.data.objects[0]&lt;/p&gt;&lt;p&gt;结果返回：bpy.data.objects['Camera']&lt;/p&gt;&lt;p&gt;输入：bpy.data.objects[1]&lt;/p&gt;&lt;p&gt;结果返回：bpy.data.objects['Cube']&lt;/p&gt;&lt;p&gt;blender中shapekey类似于material，是指向某个值，感觉跟指针一样，注意copy&lt;/p&gt;&lt;p&gt;所以copy obj的同时也应该copy shapekey&lt;/p&gt;&lt;p&gt;可以新建collection&lt;/p&gt;</content><link href="/Blog/archives/blender_script/" rel="alternate"/><published>2021-10-19T00:00:00+08:06</published></entry><entry><id>/Blog/archives/matlab%E8%AF%AD%E6%B3%95/</id><title>Matlab学习</title><updated>2021-11-19T13:06:49.825410+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;matlab学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;clc：清除命令窗口的内容，对工作环境中的全部变量无任何影响
close：关闭当前的Figure窗口
close all:关闭所有的Figure窗口
clear：清除工作空间的所有变量
clear all：清除工作空间的所有变量，函数，和MEX文件&lt;/p&gt;&lt;p&gt;grid on；写一次就可以打开网格&lt;/p&gt;&lt;p&gt;%.*对应元素相乘， *是矩阵相乘&lt;/p&gt;</content><link href="/Blog/archives/matlab%E8%AF%AD%E6%B3%95/" rel="alternate"/><published>2021-10-19T00:00:00+08:06</published></entry><entry><id>/Blog/archives/Teddy%20Bear/</id><title>泰迪熊</title><updated>2021-11-19T13:06:49.825364+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;Teddy Bear&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从小陪伴到大的朋友，却一起养成了坏习惯，这让自己一事无成，没有办法去承担自己应该承担的东西，最后还差一点无法守护自己的朋友。&lt;/p&gt;&lt;p&gt;面对爱情一味的去改变自己的生活，却不是自己真正的想要去改变，只是自己认为自己爱对方，所以就可以为了对方改变自己的一切行为。&lt;/p&gt;&lt;p&gt;我认为你应该有足够的能力去承担这个角色所应该有的责任，在困苦时，找到属于两个人共同的解决方法，不顾一切的去勇往直前（这是我想象的未来的相处方式）。&lt;/p&gt;&lt;p&gt;你可以同时是大人和小孩，有大人的成熟和小孩内心最坚强的陪伴。&lt;/p&gt;</content><link href="/Blog/archives/Teddy%20Bear/" rel="alternate"/><published>2021-10-26T00:00:00+08:06</published></entry><entry><id>/Blog/archives/base%20pytorch/</id><title>pytorch基础教程</title><updated>2021-11-19T13:06:49.825316+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;pytorch基础教程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;tensors是一种特殊的数据类型和arrays，matrices类似。用tensors编码代替input和output，还有模型参数。&lt;/p&gt;&lt;h1&gt;创建初始化方式&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;通过data生成torch.tensor(data)，这时类型自动推断，和data中类型一致&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;从numpy array&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;np_array&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x_np&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_numpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np_array&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="3"&gt;
&lt;li&gt;&lt;p&gt;从另一个tensor&lt;/p&gt;&lt;p&gt;隐式地保持类型一致&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x_ones&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones_like&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# retains the properties of x_data&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Ones Tensor: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x_ones&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;x_rand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand_like&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# overrides the datatype of x_data&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Random Tensor: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x_rand&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="4"&gt;
&lt;li&gt;调用函数&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;shape要是tensor维度的tuple&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,)&lt;/span&gt;
&lt;span class="n"&gt;rand_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ones_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;zeros_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Random Tensor: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;rand_tensor&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Ones Tensor: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;ones_tensor&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Zeros Tensor: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;zeros_tensor&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;tensor属性&lt;/h1&gt;
&lt;p&gt;tensor.shape,tensor.dtype（datatype的缩写）,torch.device&lt;/p&gt;&lt;h1&gt;tensor数学运算&lt;/h1&gt;
&lt;p&gt;transposing, indexing, slicing, mathematical operations, linear algebra, random sampling, and more are comprehensively described &lt;a href="https://pytorch.org/docs/stable/torch.html"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;tensor.to(‘cuda’)还可以显式在定义时指定device=torch.device(“cuda”)&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;和numpy一样的切片操作&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;用torch.cat拼接tensor（torch.stack用的较少），torch.cat可以指定维度&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;乘法，对应位置相乘&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# This computes the element-wise product&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;tensor.mul(tensor) &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Alternative syntax:&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;tensor * tensor &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="4"&gt;
&lt;li&gt;矩阵乘法&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;tensor.matmul(tensor.T) &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Alternative syntax:&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;tensor @ tensor.T &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="4"&gt;
&lt;li&gt;替代修改操作&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Operations that have a &lt;code&gt;_&lt;/code&gt; suffix are in-place. For example: &lt;code&gt;x.copy_(y)&lt;/code&gt;, &lt;code&gt;x.t_()&lt;/code&gt;, will change &lt;code&gt;x&lt;/code&gt;.&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;5.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;5.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;5.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;5.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;in_place操作会节省内存，但是求导时会报错，故不鼓励使用&lt;/p&gt;&lt;h2&gt;Bridge with NumPy&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;t: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;n: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;t: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;n: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="err"&gt;：&lt;/span&gt;
&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;两者会同时修改，潜在的空间一样&lt;/p&gt;&lt;h1&gt;&lt;code&gt;TORCH.AUTOGRAD&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Forward Propagation&lt;/strong&gt;: 产生最佳最正确的输出&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Backward Propagation&lt;/strong&gt;: 调整它的参数根据生成的error&lt;/p&gt;&lt;p&gt;i.e.:&lt;strong&gt;abbr.&lt;/strong&gt;亦即（源自拉丁文 id est）&lt;/p&gt;&lt;p&gt;w.r.t. :with respect to，相对某一方面而言&lt;/p&gt;&lt;p&gt;backward后会把loss值free，如果loss不是标量，需要指定gradient&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;3.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;requires_grad&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;6.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;4.&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;requires_grad&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;Q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="n"&gt;external_grad&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;Q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;external_grad&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;directed acyclic graph (DAG)有向无环图，leaves are the input tensors, roots are the output tensors.倒过来的树，从root跟踪到leaves自动计算梯度&lt;/p&gt;&lt;p&gt;&lt;strong&gt;frozen parameters&lt;/strong&gt;：用来微调模型参数&lt;/p&gt;&lt;h1&gt;NEURAL NETWORKS&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Define the neural network that has some learnable parameters (or weights)&lt;/li&gt;
&lt;li&gt;Iterate over a dataset of inputs&lt;/li&gt;
&lt;li&gt;Process input through the network&lt;/li&gt;
&lt;li&gt;Compute the loss (how far is the output from being correct)&lt;/li&gt;
&lt;li&gt;Propagate gradients back into the network’s parameters&lt;/li&gt;
&lt;li&gt;Update the weights of the network, typically using a simple update rule: &lt;code&gt;weight = weight - learning_rate * gradient&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;torch.Tensor&lt;/code&gt; - A &lt;em&gt;multi-dimensional array&lt;/em&gt; with support for autograd operations like &lt;code&gt;backward()&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;code&gt;nn.Module&lt;/code&gt;-封装好的类，方便move到GPU上&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grad_fn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# MSELoss&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grad_fn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_functions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# Linear&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grad_fn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_functions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_functions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# ReLU&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这样可以观察计算图&lt;/p&gt;&lt;p&gt;每次backward前，把计算图梯度清零，否则每次会积累&lt;/p&gt;&lt;h1&gt;数据处理&lt;/h1&gt;
&lt;p&gt;首先导入为ndarray，然后转换为torch.*Tensor&lt;/p&gt;</content><link href="/Blog/archives/base%20pytorch/" rel="alternate"/><published>2021-10-26T00:00:00+08:06</published></entry><entry><id>/Blog/archives/%E5%BD%92%E4%B8%80%E5%8C%96/</id><title>归一化</title><updated>2021-11-19T13:06:49.825264+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;归一化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;sigmoid和softmax函数区别&lt;/p&gt;&lt;h2&gt;分类问题&lt;/h2&gt;
&lt;h3&gt;&lt;strong&gt;1 Sigmoid函数&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Sigmoid =&lt;strong&gt;多标签分类问题&lt;/strong&gt;=多个正确答案=非独占输出（例如胸部X光检查、住院）。构建分类器，解决有多个正确答案的问题时，用Sigmoid函数分别处理各个原始输出值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Sigmoid函数&lt;/strong&gt;是一种logistic函数，它将任意的值转换到$[0,1]$之间，如图1所示，函数表达式为：$Sigmoid = \frac{1}{1 + e^{-x}}$ 。&lt;/p&gt;&lt;p&gt;它的导函数为： $Sigmoid'(x) = Sigmoid(x)*(1-Sigmoid(x))$。&lt;/p&gt;&lt;figure style="flex: 74.94145199063232" &gt;&lt;img width="640" height="427" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/b3c2cbcc5704847d6d9042143cb7401f.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;​																									图1：Sigmoid函数&lt;/p&gt;&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：1. Sigmoid函数的输出在(0,1)之间，输出范围有限，优化稳定，可以用作输出层。2. 连续函数，便于求导。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;：1. 最明显的就是饱和性，从上图也不难看出其两侧导数逐渐趋近于0，容易造成梯度消失。2.==激活函数的偏移现象==。Sigmoid函数的输出值均大于0，使得输出==不是0的均值==，这会导致后一层的神经元将得到上一层非0均值的信号作为输入，这会对梯度产生影响。 3. 计算复杂度高，因为Sigmoid函数是指数形式。&lt;/p&gt;&lt;h3&gt;2 Softmax函数&lt;/h3&gt;
&lt;p&gt;Softmax =&lt;strong&gt;多类别分类问题&lt;/strong&gt;=只有一个正确答案=互斥输出（例如手写数字，鸢尾花）。构建分类器，解决只有唯一正确答案的问题时，用Softmax函数处理各个原始输出值。Softmax函数的分母综合了原始输出值的所有因素，这意味着，Softmax函数得到的不同概率之间相互关联。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Softmax函数&lt;/strong&gt;，又称归一化指数函数，函数表达式为：$Softmax = \frac{e^{x_i}}{\sum_{j=1}^{n}e^{x_j}}$。&lt;/p&gt;&lt;figure style="flex: 89.33002481389578" &gt;&lt;img width="720" height="403" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/dc924cfae91bbe8d50b7de43d9d5dfed.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;​																				图2：Softmax函数计算过程&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Softmax函数是二分类函数Sigmoid在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。&lt;/strong&gt;如图2所示，Softmax直白来说就是将原来输出是3,1,-3通过Softmax函数一作用，就映射成为(0,1)的值，而这些值的累和为1（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标。&lt;/p&gt;&lt;p&gt;由于Softmax函数先拉大了输入向量元素之间的差异（通过指数函数），然后才归一化为一个概率分布，在应用到分类问题时，它使得各个类别的概率差异比较显著，最大值产生的概率更接近1，这样输出分布的形式更接近真实分布。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Softmax可以由三个不同的角度来解释。从不同角度来看softmax函数，可以对其应用场景有更深刻的理解：&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;softmax可以当作arg max的一种平滑近似，与arg max操作中暴力地选出一个最大值（产生一个one-hot向量）不同，softmax将这种输出作了一定的平滑，即将one-hot输出中最大值对应的1按输入元素值的大小分配给其他位置。&lt;/li&gt;
&lt;li&gt;softmax将输入向量归一化映射到一个类别概率分布，即 个类别上的概率分布（前文也有提到）。这也是为什么在深度学习中常常将softmax作为MLP的最后一层，并配合以交叉熵损失函数（对分布间差异的一种度量)。&lt;/li&gt;
&lt;li&gt;从概率图模型的角度来看，softmax的这种形式可以理解为一个概率无向图上的联合概率。因此你会发现，条件最大熵模型与softmax回归模型实际上是一致的，诸如这样的例子还有很多。由于概率图模型很大程度上借用了一些热力学系统的理论，因此也可以从物理系统的角度赋予softmax一定的内涵。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;3 总结&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;如果模型输出为非互斥类别，且可以同时选择多个类别，则采用Sigmoid函数计算该网络的原始输出值。&lt;/li&gt;
&lt;li&gt;如果模型输出为互斥类别，且只能选择一个类别，则采用Softmax函数计算该网络的原始输出值。&lt;/li&gt;
&lt;li&gt;Sigmoid函数可以用来解决多标签问题，Softmax函数用来解决单标签问题。&lt;a href="https://zhuanlan.zhihu.com/p/356976844#ref_1"&gt;[1]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;对于某个分类场景，当Softmax函数能用时，Sigmoid函数一定可以用。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;4. 二分类任务&lt;/h3&gt;
&lt;p&gt;对于二分类问题来说，&lt;strong&gt;理论上，两者是没有任何区别的。&lt;/strong&gt;由于我们现在用的Pytorch、TensorFlow等框架计算矩阵方式的问题，导致两者在反向传播的过程中还是有区别的。实验结果表明，两者还是存在差异的，对于不同的分类模型，可能Sigmoid函数效果好，也可能是Softmax函数效果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;首先我们先理论上证明一下二者没有本质上的区别&lt;/strong&gt;，对于二分类而言（以输入$x_1$为例)：&lt;/p&gt;&lt;p&gt;Sigmoid函数： $output(x_1)=\frac{1}{1+e^{-x_1}} (1)$&lt;/p&gt;&lt;p&gt;Softmax函数： $output(x_2)=\frac{e^{-x_1}}{e^{-x_1}+e^{-x_2}} (2)$&lt;/p&gt;&lt;p&gt;由公式（2）我们可知， $x_1-x_2$可以用$z_1$代替，即Softmax函数可以写成：  $output(z_1)=\frac{1}{1+e^{-z_1}} $，和公式（1)完全相同，所以理论上来说两者是没有任何区别的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;然后我们再分析为什么两者之间还存着差异（以Pytorch为例）：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先我们要明白，当你用Sigmoid函数的时候，你的最后一层全连接层的神经元个数为1，而当你用Softmax函数的时候，你的最后一层全连接层的神经元个数是2。这个很好理解，因为Sigmoid函数只有是目标和不是目标之分，实际上只存在一类目标类，另外一个是背景类。而Softmax函数将目标分类为了二类，所以有两个神经元。这也是导致两者存在差异的主要原因。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Sigmoid函数&lt;/strong&gt;针对两点分布提出。神经网络的输出经过它的转换，可以将数值压缩到(0,1)之间，得到的结果可以理解成&lt;strong&gt;分类成目标类别的概率P，而不分类到该类别的概率是(1 - P)&lt;/strong&gt;，这也是典型的两点分布的形式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Softmax函数&lt;/strong&gt;本身针对多项分布提出，当类别数是2时，它退化为二项分布。而它和Sigmoid函数真正的区别就在——二项分布包含两个分类类别（姑且分别称为A和B），而两点分布其实是针对一个类别的概率分布，其对应的那个类别的分布直接由1-P得出。&lt;/p&gt;&lt;p&gt;简单点理解就是，&lt;strong&gt;Sigmoid函数，我们可以当作成它是对一个类别的“建模”&lt;/strong&gt;，将该类别建模完成，另一个相对的类别就直接通过1减去得到。&lt;strong&gt;而softmax函数，是对两个类别建模&lt;/strong&gt;，同样的，得到两个类别的概率之和是1。&lt;/p&gt;&lt;p&gt;神经网络在做二分类时，使用Softmax还是Sigmoid，做法其实有明显差别。由于Softmax是对两个类别（正反两类，通常定义为0/1的label）建模，所以对于NLP模型而言（比如泛BERT模型），Bert输出层需要通过一个nn.Linear()全连接层压缩至2维，然后接Softmax（Pytorch的做法，就是直接接上torch.nn.CrossEntropyLoss）；而Sigmoid只对一个类别建模（通常就是正确的那个类别），所以Bert输出层需要通过一个nn.Linear()全连接层压缩至1维，然后接Sigmoid（torch就是接torch.nn.BCEWithLogitsLoss）。&lt;/p&gt;&lt;p&gt;总而言之，Sotfmax和Sigmoid确实在二分类的情况下可以化为相同的数学表达形式，但并不意味着二者有一样的含义，而且二者的输入输出都是不同的。Sigmoid得到的结果是“分到正确类别的概率和未分到正确类别的概率”，Softmax得到的是“分到正确类别的概率和分到错误类别的概率”。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一种常见的错法（NLP中）：&lt;/strong&gt;即错误地将Softmax和Sigmoid混为一谈，再把BERT输出层压缩至2维的情况下，却用Sigmoid对结果进行计算。这样我们得到的结果其意义是什么呢？&lt;/p&gt;&lt;p&gt;假设我们现在BERT输出层经nn.Linear()压缩后，得到一个二维的向量：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[-0.9419267177581787, 1.944047451019287]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;对应类别分别是(0,1)。我们经过Sigmoid运算得到：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tensor([0.2805, 0.8748])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;前者0.2805指的是分类类别为0的概率，0.8748指的是分类类别为1的概率。二者相互独立，可看作两次独立的实验（显然在这里不适用，因为0-1类别之间显然不是相互独立的两次伯努利事件）。所以显而易见的，二者加和并不等于1。&lt;/p&gt;&lt;p&gt;若用softmax进行计算，可得：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tensor([0.0529, 0.9471])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里两者加和是1，才是正确的选择。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;经验：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对于NLP而言&lt;/strong&gt;，这两者之间确实有差别，Softmax的处理方式有时候会比Sigmoid的处理方式好一点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对于CV而言&lt;/strong&gt;，这两者之间也是有差别的，Sigmoid的处理方式有时候会比Softmax的处理方式好一点。&lt;/p&gt;&lt;p&gt;两者正好相反，这只是笔者的实验经验，建议大家两者都试试。&lt;/p&gt;</content><link href="/Blog/archives/%E5%BD%92%E4%B8%80%E5%8C%96/" rel="alternate"/><published>2021-10-31T00:00:00+08:06</published></entry><entry><id>/Blog/archives/model.train/</id><title>dataloader</title><updated>2021-11-19T13:06:49.825214+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;dataloader&lt;/strong&gt;&lt;/p&gt;&lt;h1&gt;参数含义&lt;/h1&gt;
&lt;p&gt;1、dataset：（数据类型 dataset）&lt;/p&gt;&lt;p&gt;输入的数据类型。看名字感觉就像是数据库，C#里面也有dataset类，理论上应该还有下一级的datatable。这应当是原始数据的输入。PyTorch内也有这种数据结构。这里先不管，估计和C#的类似，这里只需要知道是输入数据类型是dataset就可以了。&lt;/p&gt;&lt;p&gt;dataset分为两类：&lt;/p&gt;&lt;h3&gt;Map-style datasets&lt;/h3&gt;
&lt;p&gt;需要完成__getitem__()&lt;code&gt;and&lt;/code&gt;__len__()函数，可以通过dataset[idx]调用数据&lt;/p&gt;&lt;h3&gt;Iterable-style datasets&lt;/h3&gt;
&lt;p&gt;完成__iter__()，这适用于无法shuffle，只可以通过依次调用，确定data的batch_size，可以通过iter(dataset)返回一个数据序列&lt;/p&gt;&lt;p&gt;2、batch_size：（数据类型 int）&lt;/p&gt;&lt;p&gt;每次输入数据的行数，默认为1。PyTorch训练模型时调用数据不是一行一行进行的（这样太没效率），而是一捆一捆来的。这里就是定义每次喂给神经网络多少行数据，如果设置成1，那就是一行一行进行（个人偏好，PyTorch默认设置是1）。&lt;/p&gt;&lt;p&gt;3、shuffle：（数据类型 bool）&lt;/p&gt;&lt;p&gt;洗牌。默认设置为False。在每次迭代训练时是否将数据洗牌，默认设置是False。将输入数据的顺序打乱，是为了使数据更有独立性，但如果数据是有序列特征的，就不要设置成True了。&lt;/p&gt;&lt;p&gt;4、collate_fn：（数据类型 callable，没见过的类型）&lt;/p&gt;&lt;p&gt;将一小段数据合并成数据列表，默认设置是False。如果设置成True，系统会在返回前会将张量数据（Tensors）复制到CUDA内存中。自己定义一个函数提前处理数据，做相应处理&lt;/p&gt;&lt;p&gt;&lt;code&gt;collate_fn&lt;/code&gt; can be used to customize collation, e.g., padding sequential data to max length of a batch. See &lt;a href="https://pytorch.org/docs/1.9.1/data.html?highlight=dataloader#dataloader-collate-fn"&gt;this section&lt;/a&gt; on more about &lt;code&gt;collate_fn&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;5、batch_sampler：（数据类型 Sampler）&lt;/p&gt;&lt;p&gt;批量采样，默认设置为None。但每次返回的是一批数据的索引（注意：不是数据）。其和batch_size、shuffle 、sampler and drop_last参数是不兼容的。我想，应该是每次输入网络的数据是随机采样模式，这样能使数据更具有独立性质。所以，它和一捆一捆按顺序输入，数据洗牌，数据采样，等模式是不兼容的。&lt;/p&gt;&lt;p&gt;6、sampler：（数据类型 Sampler）&lt;/p&gt;&lt;p&gt;采样，默认设置为None。根据定义的策略从数据集中采样输入。如果定义采样规则，则洗牌（shuffle）设置必须为False。&lt;/p&gt;&lt;p&gt;定义采样规则，specify the sequence of indices/keys used in data loading，对于Iterable-style datasets则必须自己定义所有的采样顺序&lt;/p&gt;&lt;p&gt;7、num_workers：（数据类型 Int）&lt;/p&gt;&lt;p&gt;工作者数量，默认是0。使用多少个子进程来导入数据。设置为0，就是使用主进程来导入数据。注意：这个数字必须是大于等于0的，负数估计会出错。&lt;/p&gt;&lt;p&gt;8、pin_memory：（数据类型 bool）&lt;/p&gt;&lt;p&gt;内存寄存，默认为False。在数据返回前，是否将数据复制到CUDA内存中。&lt;/p&gt;&lt;p&gt;9、drop_last：（数据类型 bool）&lt;/p&gt;&lt;p&gt;丢弃最后数据，默认为False。设置了 batch_size 的数目后，最后一批数据未必是设置的数目，有可能会小些。这时你是否需要丢弃这批数据。&lt;/p&gt;&lt;p&gt;10、timeout：（数据类型 numeric）&lt;/p&gt;&lt;p&gt;超时，默认为0。是用来设置数据读取的超时时间的，但超过这个时间还没读取到数据的话就会报错。 所以，数值必须大于等于0。&lt;/p&gt;&lt;p&gt;11、worker_init_fn（数据类型 callable，没见过的类型）&lt;/p&gt;&lt;p&gt;子进程导入模式，默认为Noun。在数据导入前和步长结束后，根据工作子进程的ID逐个按顺序导入数据。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;When automatic batching is disabled&lt;/strong&gt;, the default &lt;code&gt;collate_fn&lt;/code&gt; simply converts NumPy arrays into PyTorch Tensors, and keeps everything else untouched.&lt;/p&gt;&lt;p&gt;When both &lt;code&gt;batch_size&lt;/code&gt; and &lt;code&gt;batch_sampler&lt;/code&gt; are &lt;code&gt;None&lt;/code&gt; (default value for &lt;code&gt;batch_sampler&lt;/code&gt; is already &lt;code&gt;None&lt;/code&gt;), automatic batching is disabled. Each sample obtained from the &lt;code&gt;dataset&lt;/code&gt; is processed with the function passed as the &lt;code&gt;collate_fn&lt;/code&gt; argument.&lt;/p&gt;&lt;p&gt;重点是collate_fn参数&lt;/p&gt;</content><link href="/Blog/archives/model.train/" rel="alternate"/><published>2021-11-14T00:00:00+08:06</published></entry><entry><id>/Blog/archives/numpy%E8%AF%AD%E6%B3%95/</id><title>numpy学习</title><updated>2021-11-19T13:06:49.825110+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;numpy学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;numpy.where()&lt;/strong&gt; 有两种用法：&lt;/p&gt;&lt;h3&gt;1. np.where(condition, x, y)&lt;/h3&gt;
&lt;p&gt;满足条件(condition)，输出x，不满足输出y。&lt;/p&gt;&lt;p&gt;如果是一维数组，相当于&lt;code&gt;[xv if c else yv for (c,xv,yv) in zip(condition,x,y)]&lt;/code&gt;&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;    &lt;span class="c1"&gt;# 官网上的例子&lt;/span&gt;
    		 &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
             &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面这个例子的条件为&lt;code&gt;[[True,False], [True,False]]&lt;/code&gt;，分别对应最后输出结果的四个值。第一个值从&lt;code&gt;[1,9]&lt;/code&gt;中选，因为条件为True，所以是选1。==第二个值从[2,8]中选==，因为条件为False，所以选8，后面以此类推。类似的问题可以再看个例子：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
             &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;not chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;not chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
             &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;not chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;not chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chosen&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;chosen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;chosen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;chosen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;chosen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;lt;U10&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;2. np.where(condition)&lt;/h3&gt;
&lt;p&gt;只有条件 (condition)，没有x和y，则输出满足条件 (即非0) 元素的坐标 (等价于&lt;a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.nonzero.html#numpy.nonzero"&gt;numpy.nonzero&lt;/a&gt;)。这里的坐标以tuple的形式给出，通常原数组有多少维，输出的tuple中就包含几个数组，分别对应符合条件元素的各维坐标。&lt;/p&gt;&lt;p&gt;下面看个复杂点的例子：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;27&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[[&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;

       &lt;span class="p"&gt;[[&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;

       &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;]]])&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;


&lt;span class="c1"&gt;# 符合条件的元素为&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;

      &lt;span class="p"&gt;[[&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;

      &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
       &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;]]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;所以np.where会输出每个元素的对应的坐标，因为原数组有三维，所以tuple中有三个数组。&lt;/p&gt;</content><link href="/Blog/archives/numpy%E8%AF%AD%E6%B3%95/" rel="alternate"/><published>2021-11-14T00:00:00+08:06</published></entry></feed>