<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-CN"><id>/Blog/</id><title>我的个人博客</title><updated>2021-08-01T07:47:40.036252+08:06</updated><author><name>LSQ</name><email>1959376918@qq.com</email></author><link href="/Blog/" rel="alternate"/><generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator><logo>https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/f-logo.png</logo><subtitle>记录生活美好</subtitle><entry><id>/Blog/archives/lr%E2%80%94%E2%80%94optimization/</id><title>pytorch学习率调整</title><updated>2021-08-01T07:47:40.036570+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;一、pytorch中学习率调整方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. lr_scheduler.StepLR&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;class torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;功能：&lt;/strong&gt; 等间隔调整学习率，&lt;strong&gt;调整倍数为gamma倍，调整间隔为step_size&lt;/strong&gt;。间隔单位是step。需要注意的是，step通常是指epoch，不要弄成iteration了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参数：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;step_size(int)- 学习率下降间隔数，若为30，则会在30、60、90......个step时，将*&lt;em&gt;学习率调整为lr&lt;/em&gt;gamma**。&lt;/p&gt;&lt;p&gt;gamma(float)- 学习率调整倍数，&lt;strong&gt;默认为0.1倍，即下降10倍&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;last_epoch(int)- &lt;strong&gt;上一个epoch数&lt;/strong&gt;，这个变量用来指示学习率是否需要调整。当last_epoch符合设定的间隔时，就会对学习率进行调整。&lt;strong&gt;当为-1时，学习率设置为初始值&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.lr_scheduler.MultiStepLR&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;class torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;功能：&lt;/strong&gt; 按设定的间隔调整学习率。这个方法适合后期调试使用，==观察loss曲线==，为每个实验定制学习率调整时机。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参数：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;milestones(list)- 一个list，==每一个元素代表何时调整学习率==，list元素必须是递增的。如 milestones=[30,80,120]&lt;/p&gt;&lt;p&gt;gamma(float)- 学习率调整倍数，默认为0.1倍，即下降10倍。&lt;/p&gt;&lt;p&gt;last_epoch(int)- 上一个epoch数，这个变量用来指示学习率是否需要调整。当last_epoch符合设定的间隔时，就会对学习率进行调整。当为-1时，学习率设置为初始值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.lr_scheduler.ExponentialLR&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;class torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch=-1)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;功能：&lt;/strong&gt; 按指数衰减调整学习率，调整公式: lr = lr * gamma** &lt;strong&gt;epoch&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;参数：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;gamma- 学习率调整倍数的底，指数为epoch，即 gamma*&lt;/strong&gt;*epoch&lt;/p&gt;&lt;p&gt;last_epoch(int)- 上一个epoch数，这个变量用来指示学习率是否需要调整。当last_epoch符合设定的间隔时，就会对学习率进行调整。当为-1时，学习率设置为初始值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.lr_scheduler.CosineAnnealingLR&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;class torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;功能：&lt;/strong&gt; 以余弦函数为周期，并在每个周期最大值时重新设置学习率。具体如下图所示&lt;/p&gt;&lt;figure style="flex: 77.92207792207792" &gt;&lt;img width="720" height="462" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/766ae875366d7fedfd1e5d0ccba04d34.jpg" /&gt;&lt;/figure&gt;&lt;p&gt;详细请阅读论文《 SGDR: Stochastic Gradient Descent with Warm Restarts》(ICLR-2017)：&lt;a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1608.03983"&gt;&lt;a href="https://arxiv.org/abs/1608.03983"&gt;https://arxiv.org/abs/1608.03983&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参数：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;T_max(int)- 一次学习率周期的迭代次数，即T_max个epoch之后重新设置学习率。 eta_min(float)- 最小学习率，即在一个周期中，学习率最小会下降到eta_min，默认值为0。&lt;/p&gt;&lt;p&gt;学习率调整公式为：&lt;/p&gt;&lt;figure style="flex: 278.46153846153845" &gt;&lt;img width="362" height="65" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/708c59d860cae21f9926274afe951a8d.jpg" /&gt;&lt;/figure&gt;&lt;p&gt;可以看出是以初始学习率为最大学习率，以2*Tmax为周期，在一个周期内先下降，后上升。&lt;/p&gt;&lt;p&gt;实例： T_max = 200, 初始学习率 = 0.001, eta_min = 0&lt;/p&gt;&lt;figure style="flex: 76.57342657342657" &gt;&lt;img width="219" height="143" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/df4aea5436368aa7d5e63c326bab902c.jpg" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;5.lr_scheduler.ReduceLROnPlateau&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;class torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;功能：&lt;/strong&gt; 当某指标不再变化（下降或升高），调整学习率，这是非常实用的学习率调整策略。例如，当验证集的loss不再下降时，进行学习率调整；或者监测验证集的accuracy，当accuracy不再上升时，则调整学习率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参数：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;mode(str)- 模式选择，有 min和max两种模式，min表示当指标不再降低(如监测loss)，max表示当指标不再升高(如监测accuracy)。&lt;/p&gt;&lt;p&gt;factor(float)- 学习率调整倍数(等同于其它方法的gamma)，即学习率更新为 lr = lr * factor patience(int)- 直译——&amp;quot;耐心&amp;quot;，即忍受该指标多少个step不变化，当忍无可忍时，调整学习率。注，可以不是连续5次。&lt;/p&gt;&lt;p&gt;verbose(bool)- 是否打印学习率信息， print('Epoch {:5d}: reducing learning rate' ' of group {} to {:.4e}.'.format(epoch, i, new_lr))&lt;/p&gt;&lt;p&gt;threshold(float)- Threshold for measuring the new optimum，配合threshold_mode使用，默认值1e-4。作用是用来控制当前指标与best指标的差异。&lt;/p&gt;&lt;p&gt;threshold_mode(str)- 选择判断指标是否达最优的模式，有两种模式，rel和abs。 当threshold_mode = rel，并且mode = max时，dynamic_threshold = best * ( 1 + threshold )； 当threshold_mode = rel，并且mode = min时，dynamic_threshold = best * ( 1 - threshold )； 当threshold_mode = abs，并且mode = max时，dynamic_threshold = best + threshold ； 当threshold_mode = rel，并且mode = max时，dynamic_threshold = best - threshold&lt;/p&gt;&lt;p&gt;cooldown(int)- “冷却时间“，当调整学习率之后，让学习率调整策略冷静一下，让模型再训练一段时间，再重启监测模式。&lt;/p&gt;&lt;p&gt;min_lr(float or list)- 学习率下限，可为float，或者list，当有多个参数组时，可用list进行设置。&lt;/p&gt;&lt;p&gt;eps(float)- 学习率衰减的最小值，当学习率变化小于eps时，则不调整学习率。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6.lr_scheduler.LambdaLR&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;class torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;功能：&lt;/strong&gt; 为不同参数组设定不同学习率调整策略。调整规则为，lr = base_lr * lmbda(self.last_epoch) 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参数：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;lr_lambda(function or list)- 一个计算&lt;strong&gt;学习率调整倍数的函数&lt;/strong&gt;，输入通常为step，当有多个参数组时，设为list。&lt;/p&gt;&lt;p&gt;last_epoch(int)- 上一个epoch数，这个变量用来指示学习率是否需要调整。当last_epoch符合设定的间隔时，就会对学习率进行调整。当为-1时，学习率设置为初始值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;例如：&lt;/strong&gt;&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ignored_params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fc3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;span class="n"&gt;base_params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="err"&gt;§&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ignored_params&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;optim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SGD&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;base_params&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fc3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;}],&lt;/span&gt; 
    &lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weight_decay&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;lambda1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="n"&gt;lambda2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.95&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt;

&lt;span class="n"&gt;scheduler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;optim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lr_scheduler&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LambdaLR&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lr_lambda&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;lambda1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lambda2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;scheduler&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;epoch: &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;lr: &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scheduler&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_lr&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;输出：&lt;/strong&gt;&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.095&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.09025&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.0857375&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.081450625&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.07737809374999999&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.002&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.07350918906249998&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.002&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.06983372960937498&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.002&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.06634204312890622&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.003&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.0630249409724609&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;第一个参数组的学习率为0：这是因为学习率计算方式。 第一个参数组的初始学习率设置为0.001, lambda1 = lambda epoch: epoch // 3, 第1个epoch时，由lr = base_lr * lmbda(self.last_epoch)，可知道 lr = 0.001 * (0//3) ，又因为1//3等于0，所以导致学习率为0。&lt;/p&gt;&lt;p&gt;第二个参数组的学习率变化，初始为0.1，lr = 0.1 * 0.95^epoch ，当epoch为0时，lr=0.1 ，epoch为1时，lr=0.1*0.95。&lt;/p&gt;&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;二、 学习率调整小结及step源码阅读&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.1 学习率调整小结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Pytorch提供了六种学习率调整方法，可分为三大类，分别是&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;有序调整；&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自适应调整；&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自定义调整。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第一类，依一定规律有序进行调整，这一类是最常用的，分别是等间隔下降(Step)，按需设定下降间隔(MultiStep)，指数下降(Exponential)和CosineAnnealing。这四种方法的调整时机都是人为可控的，也是&lt;strong&gt;训练时常用到的&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;第二类，依训练状况伺机调整，这就是ReduceLROnPlateau方法。该法通过监测某一指标的变化情况，当该指标不再怎么变化的时候，就是调整学习率的时机，因而属于自适应的调整。&lt;/p&gt;&lt;p&gt;第三类，自定义调整，Lambda。Lambda方法提供的调整策略十分灵活，我们可以为不同的层设定不同的学习率调整方法，这在fine-tune中十分有用，我们不仅可为不同的层设定不同的学习率，还可以为其设定不同的学习率调整策略，简直不能更棒！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.2 step源码阅读&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在pytorch中，学习率的更新是通过scheduler.step()，而我们知道影响学习率的一个重要参数就是epoch，而epoch与scheduler.step()是如何关联的呢？这就需要看源码了。 源码在torch/optim/lr_scheduler.py，step()方法在_LRScheduler类当中，该类作为所有学习率调整的基类，其中定义了一些基本方法，如现在要介绍的step()，以及最常用的get_lr()，不过get_lr()是一个虚函数，均需要在派生类中重新定义函数。&lt;/p&gt;&lt;p&gt;看看step()&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;last_epoch&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;last_epoch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;param_group&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;param_groups&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_lr&lt;/span&gt;&lt;span class="p"&gt;()):&lt;/span&gt;
    	&lt;span class="n"&gt;param_group&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;函数接收变量epoch，默认为None，当为None时，epoch = self.last_epoch + 1。从这里知道，last_epoch是用以记录epoch的。上面有提到last_epoch的初始值是-1，因此，第一个epoch的值为 -1+1 =0。接着最重要的一步就是获取学习率，并更新。 由于pytorch是基于参数组的管理方式，这里需要采用for循环对每一个参数组的学习率进行获取及更新。这里需要注意的是get_lr()，get_lr()的功能就是获取当前epoch，该参数组的学习率。&lt;/p&gt;&lt;p&gt;这里以StepLR()为例，介绍get_lr()，请看代码：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_lr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;base_lr&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gamma&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;last_epoch&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;base_lr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;base_lrs&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;由于pytorch是基于参数组的管理方式，可能会有多个参数组，因此用for循环，返回的是一个list。list元素的计算方式为 base_lr * self.gamma ** (self.last_epoch // self.step_size)。&lt;/p&gt;&lt;p&gt;看完代码，可以知道，在执行一次scheduler.step()之后，epoch会加1，因此scheduler.step()要放在epoch的for循环当中执行。&lt;/p&gt;&lt;hr /&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#优化函数，model.parameters()为该实例中可优化的参数，lr为参数优化的选项（学习率等）&lt;/span&gt;
&lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;optim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Adam&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;param&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;named_parameters&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt; &lt;span class="c1"&gt;#查看可优化的参数有哪些&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;param&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;requires_grad&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
</content><link href="/Blog/archives/lr%E2%80%94%E2%80%94optimization/" rel="alternate"/><published>2021-07-19T00:00:00+08:06</published></entry><entry><id>/Blog/archives/strange%20idea/</id><title>20号奇怪想法</title><updated>2021-08-01T07:47:40.036543+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;七月二十日&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;KD蒸馏的新奇地方&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;response-base knowledge：用最后的logits，最简单直接&lt;/li&gt;
&lt;li&gt;feature-base knowledge：loss方法，hint layer的选取没有明确的指示，让中间层的特征，attention map一致&lt;/li&gt;
&lt;li&gt;relation-base knowledge：同时使用logits和中间层的feature&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;训练方法，offline，online，self-distillation&lt;/p&gt;&lt;p&gt;stu-network设计暂时不设计&lt;/p&gt;&lt;p&gt;训练算法：使用gan，生成数据，增强数据集&lt;/p&gt;&lt;p&gt;多种模型压缩算法使用增强网络功能&lt;/p&gt;&lt;p&gt;小的教师网络增强大的学生网络的学习&lt;/p&gt;&lt;p&gt;feature-base knowledge distillation开源文章及代码：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Cross-Layer Distillation with Semantic Calibration&lt;/strong&gt;（&lt;a href="https://github.com/DefangChen/SemCKD"&gt;GitHub - DefangChen/SemCKD: This is the official implementation for the AAAI-2021 paper (Cross-Layer Distillation with Semantic Calibration).&lt;/a&gt;  AAAI被引用次数1&lt;/p&gt;&lt;p&gt;2014-2021KD论文整理：&lt;a href="https://github.com/FLHonker/Awesome-Knowledge-Distillation"&gt;FLHonker/Awesome-Knowledge-Distillation: Awesome Knowledge-Distillation. 分类整理的知识蒸馏paper(2014-2021)&lt;/a&gt;&lt;/p&gt;&lt;p&gt;attetionmap use neuron selectivity transfer&lt;/p&gt;</content><link href="/Blog/archives/strange%20idea/" rel="alternate"/><published>2021-07-20T00:00:00+08:06</published></entry><entry><id>/Blog/archives/key_point/</id><title>论文阅读</title><updated>2021-08-01T07:47:40.036519+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;论文阅读&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;总共四篇论文，关于action recognition蒸馏方向&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Spatiotemporal distilled dense-Connectivity network for video action recognition&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;解决空间和时间层面信息共享的问题，而不是单独训练。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新知识&lt;/strong&gt;：乘法门&lt;/p&gt;&lt;figure style="flex: 93.26424870466322" &gt;&lt;img width="720" height="386" src="https://pic3.zhimg.com/80/v2-a4142c9523b06fd73b9190d6f36625e2_720w.jpg" /&gt;&lt;/figure&gt;&lt;p&gt;乘法门是一组信息对另一组数据的控制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;写作手法&lt;/strong&gt;：首先便与21文章比对区别之处，说明网络想法来源，通过DenseNet（将所有浅层输出的feature map作为输入），方便信息重复利用，减缓梯度消失问题，等等。公式花里胡哨的，将公式分多块书写，每个loss大量笔墨&lt;/p&gt;&lt;p&gt;新设计的网络跨模态融合，让RGB（appearance）和FLOW（motion）信息交流，设计了一个新的网络结构SDDN和新的蒸馏方式，两个学生（RGB，FLOW）和一个teacher（fusion）&lt;/p&gt;&lt;figure style="flex: 103.07308970099668" &gt;&lt;img width="1241" height="602" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/e6fc8b44286ff20c27bf6bf31bb6ac6b.png" /&gt;&lt;figcaption&gt;image-20210722105903240&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;基础网络结构&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如果使用乘法将两个信息相乘进行控制？使用dense connection？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;用所有层的信息有提升准确率&lt;/p&gt;&lt;figure style="flex: 232.5" &gt;&lt;img width="372" height="80" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/3cc938b889631727b1c59843a1d2b9ca.png" /&gt;&lt;figcaption&gt;image-20210722115733057&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;将各个层的flow feature concatenate在一起&lt;/p&gt;&lt;p&gt;消融实验做得很好：&lt;/p&gt;&lt;p&gt;提升的做法有：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;STDDCN模型本身更好&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;α，β，temperature选取最佳值&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Distillation，教师和两个学生的模式更佳&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;利用前置所有的信息更佳&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;motion信息指导appearance更佳&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Modality distillation with multiple stream networks for action recognition&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;hallucination network:初步理解为模拟的信息输入，自我产生，例如在RGB中模拟输入depth信息 &lt;strong&gt;是否可以模拟帧数多的情景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;将depth数据学得的信息输入hallucination network中学习，网络原本的输入是RGB，所以最后可以在同一种RGB数据下训练和测试&lt;/p&gt;&lt;p&gt;跨模态方法是通过残差&lt;/p&gt;&lt;figure style="flex: 347.43589743589746" &gt;&lt;img width="542" height="78" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/976d481f370ea18695f14d48ca09d38a.png" /&gt;&lt;figcaption&gt;image-20210722195112871&lt;/figcaption&gt;&lt;/figure&gt;&lt;ol start="3"&gt;
&lt;li&gt;&lt;strong&gt;Cross-Modal Knowledge Distillation for Action Recognition&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;使用交叉熵，获得比KL-loss更高的准确度，原因是temperature不好确定&lt;/p&gt;&lt;p&gt;mutual learning 使用多个学生网络&lt;/p&gt;&lt;figure style="flex: 91.98250728862973" &gt;&lt;img width="631" height="343" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/d467e9d6ba401d7fcb9e8fc3e7a0bc2c.png" /&gt;&lt;figcaption&gt;image-20210723101729283&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;解决的问题，将没有标注的skeleton data用于学生网络的训练，增强了数据集的可用性，（可不可以直接用teacher 网络的输出作为ground truth，这样的准确率等于0.86*0.86=0.7396）mutual learning 74.2差不多&lt;/p&gt;&lt;p&gt;利用了缺失标签的信息才是它的长处&lt;/p&gt;&lt;ol start="4"&gt;
&lt;li&gt;&lt;strong&gt;Graph distillation for action detection with privileged modalities&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;解决问题：source domain大部分信息没有利用到&lt;/p&gt;&lt;p&gt;human parsing:人体部分的颜色标注&lt;/p&gt;&lt;p&gt;前面层低级语义信息可以共享&lt;/p&gt;&lt;p&gt;1*1卷积：局部卷积，信息充分融合&lt;/p&gt;&lt;p&gt;训练方式，数据集&lt;/p&gt;&lt;p&gt;会议更新的比较快&lt;/p&gt;&lt;p&gt;bilstm：帧顺着输一次，倒着输一次，可以得到后面的信息&lt;/p&gt;&lt;p&gt;LSTM学习到后面的隐变量&lt;/p&gt;&lt;p&gt;HDM51 dataloader&lt;/p&gt;</content><link href="/Blog/archives/key_point/" rel="alternate"/><published>2021-07-22T00:00:00+08:06</published></entry><entry><id>/Blog/archives/resnet/</id><title>resnet网络</title><updated>2021-08-01T07:47:40.036496+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;restnet&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;简化了学习过程，增强了梯度传播&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;相比于学习原始的信号，残差网络学习的是信号的差值，这在许多的研究中被验证是更加有效的，它简化了学习的过程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;根据我们前面的内容可知，在一定程度上，网络越深表达能力越强，性能越好。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;然而随着网络深度的增加，带来了许多优化相关的问题，比如梯度消散，梯度爆炸。&lt;/p&gt;&lt;p&gt;残差网络从根本上解决了梯度问题&lt;/p&gt;&lt;figure style="flex: 121.0762331838565" &gt;&lt;img width="1080" height="446" src="https://res-static.hc-cdn.cn/fms/img/fb9d7c7db3bb265f7f997160aa48bc641603780769781" /&gt;&lt;/figure&gt;&lt;ol start="2"&gt;
&lt;li&gt;&lt;strong&gt;打破了网络的不对称性&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;虽然残差网络可以通过跳层连接，增强了梯度的流动，从而使得上千层网络的训练成为可能，&lt;strong&gt;不过相关的研究表面残差网络的有效性，更加体现在减轻了神经网络的退化。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如果在网络中每个层只有少量的隐藏单元对不同的输入改变它们的激活值，而大部分隐藏单元对不同的输入都是相同的反应，此时整个权重矩阵的秩不高。并且随着网络层数的增加，连乘后使得整个秩变的更低，这就是我们常说的网络退化问题。&lt;/strong&gt;&lt;/p&gt;&lt;ol start="3"&gt;
&lt;li&gt;&lt;strong&gt;增强了网络的泛化能力&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一个残差块可以用表示为：&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7Bl%2B1%7D%3D+x_l%2B%5Cmathcal%7BF%7D%28x_l%2C+%7BW_l%7D%29%5Ctag%7B1%7D" /&gt;&lt;/figure&gt;&lt;p&gt;残差块分成两部分直接映射部分和残差部分。 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=h%28x_l%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是直接映射，反应在图1中是左边的曲线； &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BF%7D%28x_l%2C+%7BW_l%7D%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是残差部分，一般由两个或者三个卷积操作构成，即下图中右侧包含卷积的部分。&lt;/p&gt;&lt;figure style="flex: 23.668639053254438" &gt;&lt;img width="160" height="338" src="https://pic2.zhimg.com/80/v2-bd76d0f10f84d74f90505eababd3d4a1_720w.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图中的Weight在卷积网络中是指卷积操作，addition是指单位加操作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;残差网络的背后原理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;残差块一个更通用的表示方式是&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=y_l%3D+h%28x_l%29%2B%5Cmathcal%7BF%7D%28x_l%2C+%7BW_l%7D%29%5Ctag%7B3%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7Bl%2B1%7D+%3D+f%28y_l%29%5Ctag%7B4%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;现在我们先不考虑升维或者降维的情况，那么在[1]中， &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=h%28%5Ccdot%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是直接映射， &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=f%28%5Ccdot%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是激活函数，一般使用ReLU。我们首先给出两个假设：&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;假设1： &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=h%28%5Ccdot%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是直接映射；&lt;/li&gt;
&lt;li&gt;假设2： &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=f%28%5Ccdot%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是直接映射。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么这时候残差块可以表示为：&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7Bl%2B1%7D+%3D+x_l+%2B+%5Cmathcal%7BF%7D%28x_l%2C+%7BW_l%7D%29%5Ctag%7B5%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对于一个更深的层 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=L" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ，其与 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=l" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 层的关系可以表示为&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_L+%3D+x_l+%2B+%5Csum_%7Bi%3Dl%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29%5Ctag%7B6%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个公式反应了残差网络的两个属性：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=L" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 层可以表示为==任意一个比它浅的l层和他们之间的残差部分之和；==&lt;/li&gt;
&lt;li&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_L%3D+x_0+%2B+%5Csum_%7Bi%3D0%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ， &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=L" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 是各个残差块特征的单位累和，而MLP是特征矩阵的累积。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;根据BP（back propagation）中使用的导数的链式法则，损失函数 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cvarepsilon" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 关于 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_l" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 的梯度可以表示为&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_l%7D+%3D+%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D%5Cfrac%7B%5Cpartial+x_L%7D%7B%5Cpartial+x_l%7D+%3D+%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D%281%2B%5Cfrac%7B%5Cpartial+%7D%7B%5Cpartial+x_l%7D%5Csum_%7Bi%3Dl%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29%29+%3D+%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D%2B%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D+%5Cfrac%7B%5Cpartial+%7D%7B%5Cpartial+x_l%7D%5Csum_%7Bi%3Dl%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29+%5Ctag%7B7%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上面公式反映了残差网络的两个属性：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;在整个训练过程中， &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%7D%7B%5Cpartial+x_l%7D%5Csum_%7Bi%3Dl%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29+" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 不可能一直为 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=-1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ，也就是说在残差网络中==不会出现梯度消失的问题==。&lt;/li&gt;
&lt;li&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 表示 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=L" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 层的梯度可以直接传递到任何一个比它浅的 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=l" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 层。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过分析残差网络的正向和反向两个过程，我们发现，当残差块满足上面两个假设时，信息可以非常畅通的在高层和低层之间相互传导，说明这两个假设是让残差网络可以训练深度模型的充分条件。那么这两个假设是必要条件吗？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;直接映射是最好的选择&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于假设1，我们采用反证法，假设 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=h%28x_l%29+%3D+%5Clambda_l+x_l" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ，那么这时候，残差块（图3.b）表示为&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7Bl%2B1%7D+%3D+%5Clambda_lx_l+%2B+%5Cmathcal%7BF%7D%28x_l%2C+%7BW_l%7D%29%5Ctag%7B8%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对于更深的L层&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7BL%7D+%3D+%28%5Cprod_%7Bi%3Dl%7D%5E%7BL-1%7D%5Clambda_i%29x_l+%2B+%5Csum_%7Bi%3Dl%7D%5E%7BL-1%7D%5Cmathcal%7BF%7D%28x_i%2C+%7BW_i%7D%29%5Ctag%7B9%7D" /&gt;&lt;/figure&gt;&lt;p&gt;为了简化问题，我们只考虑公式的左半部分 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_%7BL%7D+%3D+%28%5Cprod_%7Bi%3Dl%7D%5E%7BL-1%7D%5Clambda_l%29x_l" /&gt;&lt;/figure&gt; ，损失函数 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cvarepsilon" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 对 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=x_l" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 求偏微分得&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%5Cvarepsilon%7D%7B%5Cpartial+x_l%7D+%3D+%5Cfrac%7B%5Cpartial%5Cvarepsilon%7D%7B%5Cpartial+x_L%7D+%5Cleft%28+%28%5Cprod_%7Bi%3Dl%7D%5E%7BL-1%7D%5Clambda_i%29+%2B+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_l%7D+%5Chat%7B%5Cmathcal%7BF%7D%7D%28x_i%2C+%5Cmathcal%7BW%7D_i%29%5Cright%29%5Ctag%7B10%7D+" /&gt;&lt;/figure&gt;&lt;p&gt;上面公式反映了两个属性：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;当 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Clambda%3E1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，很有可能发生梯度爆炸；&lt;/li&gt;
&lt;li&gt;当 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Clambda%3C1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，梯度变成0，会阻碍残差网络信息的反向传递，从而影响残差网络的训练。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=%5Clambda" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ==必须等1==。同理，其他常见的激活函数都会产生和上面的例子类似的阻碍信息反向传播的问题。&lt;/p&gt;&lt;p&gt;对于其它不影响梯度的 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=h%28%5Ccdot%29" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ，例如LSTM中的门机制（图3.c，图3.d）或者Dropout（图3.f）以及[1]中用于降维的 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=1%5Ctimes1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 卷积（图3.e）也许会有效果，作者采用了实验的方法进行验证，实验结果见图4&lt;/p&gt;&lt;figure style="flex: 52.63157894736842" &gt;&lt;img width="720" height="684" src="https://pic2.zhimg.com/80/v2-843326b572e2e4c5c8956e289bd3f58d_720w.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图3：直接映射的变异模型&lt;/p&gt;&lt;figure style="flex: 109.7560975609756" &gt;&lt;img width="720" height="328" src="https://pic4.zhimg.com/80/v2-5d8fd2868a4ba30e61ce477ab00d7f0f_720w.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;图4：变异模型（均为110层）在Cifar10数据集上的表现&lt;p&gt;从图4的实验结果中我们可以看出，在所有的变异模型中，依旧是==直接映射的效果最好==。下面我们对图3中的各种变异模型的分析&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;Exclusive Gating：在LSTM的门机制中，绝大多数门的值为0或者1，几乎很难落到0.5附近。当 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=g%28x%29%5Crightarrow0" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，残差块变成只有直接映射组成，阻碍卷积部分特征的传播；当 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=g%28x%29%5Crightarrow1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，直接映射失效，退化为普通的卷积网络；&lt;/li&gt;
&lt;li&gt;Short-cut only gating： &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=g%28x%29%5Crightarrow0" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，此时网络便是[1]提出的直接映射的残差网络； &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=g%28x%29%5Crightarrow1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 时，退化为普通卷积网络；&lt;/li&gt;
&lt;li&gt;Dropout：类似于将直接映射乘以 &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=1-p" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; ，所以会影响梯度的反向传播；&lt;/li&gt;
&lt;li&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=1%5Ctimes1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; conv： &lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=1%5Ctimes1" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt; 卷积比直接映射拥有更强的表示能力，但是实验效果却不如直接映射，说明该问题更可能是优化问题而非模型容量问题。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以我们可以得出结论：假设1成立，即&lt;/p&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=y_l+%3D+x_l+%2B+%5Cmathcal%7BF%7D%28x_l%2C+w_l%29+%5Ctag%7B11%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure  size-undefined&gt;&lt;img width="-1" height="-1" src="https://www.zhihu.com/equation?tex=y_%7Bl%2B1%7D+%3D+x_%7Bl%2B1%7D+%2B+%5Cmathcal%7BF%7D%28x_%7Bl%2B1%7D%2C+w_%7Bl%2B1%7D%29+%3D+f%28y_l%29+%2B+%5Cmathcal%7BF%7D%28f%28y_l%29%2C+w_%7Bl%2B1%7D%29+%5Ctag%7B12%7D" /&gt;&lt;figcaption&gt;[公式]&lt;/figcaption&gt;&lt;/figure&gt;</content><link href="/Blog/archives/resnet/" rel="alternate"/><published>2021-07-22T00:00:00+08:06</published></entry><entry><id>/Blog/archives/schedule/</id><title>论文后续安排</title><updated>2021-08-01T07:47:40.036472+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;工作安排&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先为了让模型适用于UCF101和HDM51两个数据集上，搭建baseline并测试精度&lt;/p&gt;&lt;p&gt;之后尝试经典蒸馏方法并运用到上面查看突破口，想出创新点并应用在该领域&lt;/p&gt;&lt;p&gt;创新点：连接加上权重，将所有前面feature输入并加上权重&lt;/p&gt;</content><link href="/Blog/archives/schedule/" rel="alternate"/><published>2021-07-23T00:00:00+08:06</published></entry><entry><id>/Blog/archives/github%20HMDB51%E6%80%BB%E7%BB%93/</id><title>github阅读</title><updated>2021-08-01T07:47:40.036443+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;h2&gt;3D-CNN Method&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
  &lt;th&gt;&lt;/th&gt;
  &lt;th&gt;&lt;/th&gt;
  &lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
  &lt;td&gt;iDT&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;LRCN&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;CVPR 2015&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;LSTM composite model&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;C3D&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;2015&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;TSN&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;ECCV 2016&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;R3DCNN&lt;/td&gt;
  &lt;td&gt;NVIDIA&lt;/td&gt;
  &lt;td&gt;2016&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;P3D&lt;/td&gt;
  &lt;td&gt;MSRA&lt;/td&gt;
  &lt;td&gt;ICCV 2017&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;R3D/2.5D&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;2017&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;T3D&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;2017&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;R2+1D&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;2018&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!-- more --&gt;
&lt;p&gt;--&lt;/p&gt;&lt;hr /&gt;
&lt;p&gt;General LIb:&lt;/p&gt;&lt;p&gt;[ video model zoo (caffe2) ] &lt;a href="https://github.com/facebookresearch/VMZ"&gt;https://github.com/facebookresearch/VMZ&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Currently, this codebase supports the following models:&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;R(2+1)D, MCx models &lt;a href="https://research.fb.com/wp-content/uploads/2018/04/a-closer-look-at-spatiotemporal-convolutions-for-action-recognition.pdf"&gt;[1]&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;CSN models &lt;a href="https://arxiv.org/pdf/1904.02811.pdf"&gt;[2]&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;R(2+1)D and CSN models pre-trained on large-scale (65 million!) weakly-supervised public Instagram videos (&lt;strong&gt;IG-65M&lt;/strong&gt;) &lt;a href="https://research.fb.com/wp-content/uploads/2019/05/Large-scale-weakly-supervised-pre-training-for-video-action-recognition.pdf"&gt;[3]&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;C3D&lt;/h3&gt;
&lt;p&gt;[github caffe ]&lt;a href="https://github.com/facebook/C3D"&gt;https://github.com/facebook/C3D&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[ github tensorflow ]&lt;a href="https://github.com/hx173149/C3D-tensorflow"&gt;https://github.com/hx173149/C3D-tensorflow&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[github pytorch] &lt;a href="https://github.com/jfzhang95/pytorch-video-recognition"&gt;https://github.com/jfzhang95/pytorch-video-recognition&lt;/a&gt;&lt;/p&gt;&lt;p&gt;3x3x3  Kernel&lt;/p&gt;&lt;figure style="flex: 262.77372262773724" &gt;&lt;img width="720" height="137" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/71853e0cfa11f4c2df712fc43d7ee2f4.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure style="flex: 42.767857142857146" &gt;&lt;img width="479" height="560" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/b43d027f12bba9f3525b3e699fd0ac8f.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;P3D&lt;/h3&gt;
&lt;p&gt;[ caffe ] &lt;a href="https://github.com/ZhaofanQiu/pseudo-3d-residual-networks"&gt;https://github.com/ZhaofanQiu/pseudo-3d-residual-networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[ pytorch ] &lt;a href="https://github.com/jfzhang95/pytorch-video-recognition"&gt;https://github.com/jfzhang95/pytorch-video-recognition&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Learning spatio-temporal representation with pseudo-3d residual networks. In ICCV, 2017.&lt;/p&gt;&lt;figure style="flex: 79.02208201892745" &gt;&lt;img width="501" height="317" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/424604edeaa910b2e7f9068987cbd376.png" /&gt;&lt;figcaption&gt;1567834917557&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure style="flex: 121.82857142857142" &gt;&lt;img width="2132" height="875" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/2843da38780038aff460bbcd558bab05.png" /&gt;&lt;figcaption&gt;1567834970578&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;T3D*&lt;/h3&gt;
&lt;p&gt;Architecture: DenseNet + 3D&lt;/p&gt;&lt;p&gt;[ github pytorch] &lt;a href="https://github.com/MohsenFayyaz89/T3D"&gt;https://github.com/MohsenFayyaz89/T3D&lt;/a&gt;&lt;/p&gt;&lt;figure style="flex: 97.0059880239521" &gt;&lt;img width="648" height="334" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/8498c4f96d09598e772ad76adb771aa4.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure style="flex: 44.662921348314605" &gt;&lt;img width="477" height="534" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/c03698d9b35355fcf748ec0b723ba4bd.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Res3D/R3D&lt;/h3&gt;
&lt;p&gt;architecture:	ResNet + 3DConv&lt;/p&gt;&lt;p&gt;[github pytorch] &lt;a href="https://github.com/jfzhang95/pytorch-video-recognition"&gt;https://github.com/jfzhang95/pytorch-video-recognition&lt;/a&gt;&lt;/p&gt;&lt;figure style="flex: 59.01856763925729" &gt;&lt;img width="445" height="377" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/8150945c2e765ba0c3418c83799ad304.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure style="flex: 51.63170163170163" &gt;&lt;img width="443" height="429" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/023a150c62aa2f2fabe6010dca6c74b5.jpg" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;R2.5D&lt;/h4&gt;
&lt;figure style="flex: 59.58083832335329" &gt;&lt;img width="398" height="334" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/aa929bfe9c21b425a5c3ba07516d40c3.png" /&gt;&lt;figcaption&gt;1567836996218&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;R2+1D&lt;/h3&gt;
&lt;p&gt;[ offical video model zoo (caffe2) ] &lt;a href="https://github.com/facebookresearch/VMZ"&gt;https://github.com/facebookresearch/VMZ&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[ github PyTorch] &lt;a href="https://github.com/leftthomas/R2Plus1D-C3D"&gt;https://github.com/leftthomas/R2Plus1D-C3D&lt;/a&gt;&lt;/p&gt;&lt;figure style="flex: 49.527186761229316" &gt;&lt;img width="419" height="423" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/d9b208e0c8fd89040655af70eee8f95c.png" /&gt;&lt;figcaption&gt;Figure 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;R3DCNN&lt;/h3&gt;
&lt;p&gt;[NVIDIA]&lt;a href="https://research.nvidia.com/sites/default/files/publications/NVIDIA_R3DCNN_cvpr2016.pdf"&gt;https://research.nvidia.com/sites/default/files/publications/NVIDIA_R3DCNN_cvpr2016.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[tensorflow ]&lt;a href="https://github.com/breadbread1984/R3DCNN"&gt;https://github.com/breadbread1984/R3DCNN&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[tensorflow ] &lt;a href="https://github.com/kilsenp/R3DCNN-tensorflow"&gt;https://github.com/kilsenp/R3DCNN-tensorflow&lt;/a&gt;&lt;/p&gt;&lt;p&gt;architecture: C3D + RNN&lt;/p&gt;&lt;h3&gt;TSN&lt;/h3&gt;
&lt;p&gt;[github caffe ] &lt;a href="https://github.com/yjxiong/temporal-segment-networks"&gt;https://github.com/yjxiong/temporal-segment-networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[ caffe opensource ] &lt;a href="https://github.com/yjxiong/caffe"&gt;https://github.com/yjxiong/caffe&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[Paper] &lt;a href="https://arxiv.org/pdf/1608.00859.pdf"&gt;https://arxiv.org/pdf/1608.00859.pdf&lt;/a&gt;&lt;/p&gt;&lt;figure style="flex: 87.5" &gt;&lt;img width="1393" height="796" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/03c5b5d0c76ff8ac3419831b8c213d31.png" /&gt;&lt;figcaption&gt;1568038064174&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;I3D&lt;/h3&gt;
&lt;p&gt;Architecture: Inception base&lt;/p&gt;&lt;p&gt;[git keras ] &lt;a href="https://github.com/OanaIgnat/i3d_keras"&gt;https://github.com/OanaIgnat/i3d_keras&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[Paper ] &lt;a href="https://arxiv.org/pdf/1705.07750.pdf"&gt;https://arxiv.org/pdf/1705.07750.pdf&lt;/a&gt;&lt;/p&gt;&lt;figure style="flex: 118.86792452830188" &gt;&lt;img width="2016" height="848" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/69f472dba62bd4c9c900fd5fad1f8aeb.png" /&gt;&lt;figcaption&gt;1568037268584&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure style="flex: 97.72946859903382" &gt;&lt;img width="2023" height="1035" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/45c870c31d512a5092a0aff42829b21c.png" /&gt;&lt;figcaption&gt;1568037351528&lt;/figcaption&gt;&lt;/figure&gt;</content><link href="/Blog/archives/github%20HMDB51%E6%80%BB%E7%BB%93/" rel="alternate"/><published>2021-07-27T00:00:00+08:06</published></entry><entry><id>/Blog/archives/HMDB51%E5%A4%84%E7%90%86/</id><title>HMDB数据集</title><updated>2021-08-01T07:47:40.036416+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;HMDB51数据集&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;orgin HMDB51-About 2GB for a total of 7,000 clips distributed in 51 action classes。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_sta.rar"&gt;Stabilized HMDB51&lt;/a&gt; – the number of clips and classes are the same as HMDB51, but there is a mask in [video_name].form associated with each clip. The mask file is readable in matlab.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了动作标签，还有meta-label（元标签）表征片段的属性&lt;/p&gt;&lt;p&gt;各个方向的，前面，后面，左右方向的视频&lt;/p&gt;&lt;p&gt;There should be 70 videos with id 1 , 30 videos with id 2 in each txt file.&lt;/p&gt;&lt;p&gt;mask:ice_cream:：只有为1的才表征人&lt;/p&gt;&lt;p&gt;stabilized：还有matrxi表征数据集对原始图像的转换&lt;/p&gt;&lt;p&gt;accimage: accelerate image对PIL库的部分功能实现&lt;/p&gt;&lt;p&gt;hog，hof特征为处理后的光流信息特征&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.cnblogs.com/ocean1100/p/9494640.html"&gt;PyTorch载入图片后ToTensor解读（含PIL和OpenCV读取图片对比） - 木易修 - 博客园 (cnblogs.com)&lt;/a&gt;&lt;/p&gt;&lt;p&gt;totensor对于Opencv（不会除以255）和PIL.image的处理不一样&lt;/p&gt;&lt;p&gt;尝试&lt;a href="https://github.com/sebastiantiesmeyer/deeplabchop3d"&gt;GitHub - sebastiantiesmeyer/deeplabchop3d: inflated labchop kinetic net&lt;/a&gt;&lt;/p&gt;&lt;p&gt;直接复现最高精度的结果&lt;/p&gt;</content><link href="/Blog/archives/HMDB51%E5%A4%84%E7%90%86/" rel="alternate"/><published>2021-07-28T00:00:00+08:06</published></entry><entry><id>/Blog/archives/pytorch%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E6%80%BB%E7%BB%93/</id><title>pytorch常见错误总结</title><updated>2021-08-01T07:47:40.036385+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;PyTorch常见报错汇总&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;报错： ValueError: num_samples should be a positive integer value, but got num_samples=0&lt;/p&gt;&lt;p&gt;可能的原因：传入的Dataset中的len(self.data_info)==0，即传入该dataloader的dataset里没有数据&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;检查dataset中的路径，路径不对，读取不到数据。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;检查Dataset的&lt;strong&gt;len&lt;/strong&gt;()函数为何&lt;strong&gt;输出为零&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2&lt;/p&gt;&lt;p&gt;报错：TypeError: pic should be PIL Image or ndarray. Got &amp;lt;class 'torch.Tensor'&amp;gt;&lt;/p&gt;&lt;p&gt;可能的原因：当前操作需要PIL Image或ndarray数据类型，但传入了Tensor&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;检查transform中是否存在&lt;strong&gt;两次ToTensor()方法&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;检查transform中每一个操作的数据类型变化&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;3&lt;/p&gt;&lt;p&gt;报错：RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 93 and 89 in dimension 1 at /Users/soumith/code/builder/wheel/pytorch-src/aten/src/TH/generic/THTensorMath.cpp:3616&lt;/p&gt;&lt;p&gt;可能的原因：dataloader的__getitem__函数中，返回的图片形状不一致，导致无法stack&lt;/p&gt;&lt;p&gt;解决方法：检查__getitem__函数中的操作&lt;/p&gt;&lt;p&gt;4&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;p&gt;conv: RuntimeError: Given groups=1, weight of size 6 1 5 5, expected input[16, 3, 32, 32] to have 1 channels, but got 3 channels instead&lt;/p&gt;&lt;p&gt;linear: RuntimeError: size mismatch, m1: [16 x 576], m2: [400 x 120] at ../aten/src/TH/generic/THTensorMath.cpp:752&lt;/p&gt;&lt;p&gt;可能的原因：网络层输入数据与网络的参数不匹配&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;检查对应网络层前后定义是否有误&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;检查输入数据shape&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;5&lt;/p&gt;&lt;p&gt;报错：AttributeError: 'DataParallel' object has no attribute 'linear'&lt;/p&gt;&lt;p&gt;可能的原因：并行运算时，模型被dataparallel包装，所有module都增加一个属性 module. 因此需要通过 net.module.linear调用&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;网络层前加入module.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;6&lt;/p&gt;&lt;p&gt;报错:&lt;/p&gt;&lt;p&gt;RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.&lt;/p&gt;&lt;p&gt;可能的原因：gpu训练的模型保存后，在无gpu设备上无法直接加载，或者内存不够了&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;需要设置map_location=&amp;quot;cpu&amp;quot;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;7&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;p&gt;AttributeError: Can't get attribute 'FooNet2' on &amp;lt;module '&lt;strong&gt;main&lt;/strong&gt;' from '&lt;/p&gt;&lt;p&gt;可能的原因：保存的网络模型在当前python脚本中没有定义&lt;/p&gt;&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;提前定义该类&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;8&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;p&gt;RuntimeError: Assertion `cur_target &amp;gt;= 0 &amp;amp;&amp;amp; cur_target &amp;lt; n_classes' failed. at ../aten/src/THNN/generic/ClassNLLCriterion.c:94&lt;/p&gt;&lt;p&gt;可能的原因：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;标签数大于等于类别数量，即不满足 cur_target &amp;lt; n_classes，通常是因为&lt;strong&gt;标签从1开始而不是从0开始&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;解决方法：&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;修改label，从0开始，例如：10分类的标签取值应该是0-9&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;9&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;p&gt;RuntimeError: expected device cuda:0 and dtype Long but got device cpu and dtype Long&lt;/p&gt;&lt;p&gt;Expected object of backend CPU but got backend CUDA for argument #2 'weight'&lt;/p&gt;&lt;p&gt;可能的原因：需计算的两个数据不在同一个设备上&lt;/p&gt;&lt;p&gt;解决方法：采用to函数将数据迁移到同一个设备上&lt;/p&gt;&lt;p&gt;10&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;p&gt;RuntimeError: DataLoader worker (pid 27) is killed by signal: Killed. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.&lt;/p&gt;&lt;p&gt;可能原因：内存不够（不是gpu显存，是内存）&lt;/p&gt;&lt;p&gt;解决方法：申请更大内存&lt;/p&gt;&lt;p&gt;11&lt;/p&gt;&lt;p&gt;报错：&lt;/p&gt;&lt;figure style="flex: 514.2857142857143" &gt;&lt;img width="720" height="70" src="https://pic2.zhimg.com/80/v2-92824691477c695c9e7c5a6e6e6263fd_720w.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;RuntimeError: reduce failed to synchronize: device-side assert triggered&lt;/p&gt;&lt;p&gt;可能的原因：采用&lt;strong&gt;BCE损失函数的时候，input必须是0-1之间&lt;/strong&gt;，由于模型最后没有加sigmoid激活函数，导致的。&lt;/p&gt;&lt;p&gt;解决方法：让模型输出的值域在[0, 1]&lt;/p&gt;&lt;p&gt;12&lt;/p&gt;&lt;p&gt;报错：RuntimeError: unexpected EOF. The file might be corrupted.&lt;/p&gt;&lt;p&gt;torch.load加载模型过程报错，因为模型传输过程中有问题，重新传一遍模型即可&lt;/p&gt;&lt;p&gt;13&lt;/p&gt;&lt;p&gt;报错：UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 1: invalid start byte&lt;/p&gt;&lt;p&gt;可能的原因：&lt;strong&gt;python2保存，python3加载，会报错&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;解决方法：把&lt;strong&gt;encoding改为encoding='iso-8859-1'&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;check_p = torch.load(path, map_location=&amp;quot;cpu&amp;quot;, encoding='iso-8859-1')&lt;/p&gt;&lt;p&gt;14&lt;/p&gt;&lt;p&gt;报错：RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same&lt;/p&gt;&lt;p&gt;问题原因：数据张量已经转换到GPU上，但模型参数还在cpu上，造成计算不匹配问题。&lt;/p&gt;&lt;p&gt;解决方法：通过添加model.cuda()将模型转移到GPU上以解决这个问题。或者通过添加model.to(cuda)解决问题&lt;/p&gt;&lt;ol start="15"&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;报错：ValueError: num_samples should be a positive integer value, but got num_samples=0&lt;/p&gt;&lt;p&gt;问题原因：高版本pytorch对于tensor.data[0]会报错，统一修改成tensor.item()&lt;/p&gt;&lt;p&gt;实验代码demo&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch&lt;/span&gt; 
&lt;span class="n"&gt;a&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;print(a.item()) 运行该行代码会报错&lt;/strong&gt;&lt;/p&gt;&lt;figure style="flex: 120.91503267973856" &gt;&lt;img width="370" height="153" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/2b1c7d53e81bc775f36bc651cb2d3632.png" /&gt;&lt;figcaption&gt;在这里插入图片描述&lt;/figcaption&gt;&lt;/figure&gt;</content><link href="/Blog/archives/pytorch%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E6%80%BB%E7%BB%93/" rel="alternate"/><published>2021-07-29T00:00:00+08:06</published></entry><entry><id>/Blog/archives/docker%E4%BD%BF%E7%94%A8/</id><title>docker使用</title><updated>2021-08-01T07:47:40.036352+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;docker使用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;命令：&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker run -it ubuntu /bin/bash
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;参数说明：&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;-i&lt;/strong&gt;: 交互式操作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-t&lt;/strong&gt;: 终端。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ubuntu&lt;/strong&gt;: ubuntu 镜像。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;/bin/bash&lt;/strong&gt;：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要退出终端，直接输入 &lt;strong&gt;exit&lt;/strong&gt;:&lt;/p&gt;&lt;h3&gt;启动已停止运行的容器&lt;/h3&gt;
&lt;p&gt;查看所有的容器命令如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker ps -a
&lt;/code&gt;&lt;/pre&gt;
&lt;figure style="flex: 1217.1052631578948" &gt;&lt;img width="1850" height="76" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/36bdc4d66eebe31fcf823d3af0a3bbd5.png" /&gt;&lt;/figure&gt;使用 docker start 启动一个已停止的容器：
&lt;pre&gt;&lt;code&gt;$ docker start b750bbbcfd88 
&lt;/code&gt;&lt;/pre&gt;
&lt;figure style="flex: 848.3050847457627" &gt;&lt;img width="1001" height="59" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/da2e587fad6f121a93678c557f0a4ac4.png" /&gt;&lt;/figure&gt;&lt;h3&gt;后台运行&lt;/h3&gt;
&lt;p&gt;在大部分的场景下，我们希望 docker 的服务是在后台运行的，我们可以过 &lt;strong&gt;-d&lt;/strong&gt; 指定容器的运行模式。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker run -itd --name ubuntu-test ubuntu /bin/bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;点击图片查看大图：&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-run-d.png"&gt;&lt;figure style="flex: 1322.5" &gt;&lt;img width="1587" height="60" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/4735f78c70d26c666ab5c85a11a97379.png" /&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-run-d2.png"&gt;&lt;figure style="flex: 1151.9736842105262" &gt;&lt;img width="1751" height="76" src="https://cdn.jsdelivr.net/gh/LSQsjtu/Blog@gh-pages/archives/assets/2baa0f19820e31a07d4b9a8d0c8d5f54.png" /&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;注：&lt;/strong&gt;加了 &lt;strong&gt;-d&lt;/strong&gt; 参数默认不会进入容器，想要进入容器需要使用指令 &lt;strong&gt;docker exec&lt;/strong&gt;（下面会介绍到）。&lt;/p&gt;&lt;h3&gt;停止一个容器&lt;/h3&gt;
&lt;p&gt;停止容器的命令如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker stop &amp;lt;容器 ID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;figure style="flex: 910.0" &gt;&lt;img width="1001" height="55" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-stop-1.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;停止的容器可以通过 docker restart 重启：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker restart &amp;lt;容器 ID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;figure style="flex: 862.9310344827586" &gt;&lt;img width="1001" height="58" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-stop-2.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;进入容器&lt;/h3&gt;
&lt;p&gt;在使用 &lt;strong&gt;-d&lt;/strong&gt; 参数时，容器启动后会进入后台。此时想要进入容器，可以通过以下指令进入：&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;docker attach&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;docker exec&lt;/strong&gt;：推荐大家使用 docker exec 命令，因为此退出容器终端，不会导致容器的停止。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;attach 命令&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下面演示了使用 docker attach 命令。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker attach 1e560fca3906 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-attach.png"&gt;&lt;figure style="flex: 232.69230769230768" &gt;&lt;img width="1573" height="338" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-attach.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 如果从这个容器退出，会导致容器的停止。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;exec 命令&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;下面演示了使用 docker exec 命令。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker exec -it 243c32535da7 /bin/bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-exec.png"&gt;&lt;figure style="flex: 247.64150943396226" &gt;&lt;img width="1575" height="318" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-exec.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 如果从这个容器退出，容器不会停止，这就是为什么推荐大家使用 &lt;strong&gt;docker exec&lt;/strong&gt; 的原因。&lt;/p&gt;&lt;p&gt;更多参数说明请使用 &lt;strong&gt;docker exec --help&lt;/strong&gt; 命令查看。&lt;/p&gt;&lt;h3&gt;导出和导入容器&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;导出容器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果要导出本地某个容器，可以使用 &lt;strong&gt;docker export&lt;/strong&gt; 命令。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker export 1e560fca3906 &amp;gt; ubuntu.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;导出容器 1e560fca3906 快照到本地文件 ubuntu.tar。&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-export.png"&gt;&lt;figure style="flex: 280.7142857142857" &gt;&lt;img width="1572" height="280" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-export.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这样将导出容器快照到本地文件。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;导入容器快照&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;可以使用 docker import 从容器快照文件中再导入为镜像，以下实例将快照文件 ubuntu.tar 导入到镜像 test/ubuntu:v1:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat docker/ubuntu.tar | docker import - test/ubuntu:v1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-import.png"&gt;&lt;figure style="flex: 232.36607142857142" &gt;&lt;img width="1041" height="224" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-import.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;此外，也可以通过指定 URL 或者某个目录来导入，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker import http://example.com/exampleimage.tgz example/imagerepo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;删除容器&lt;/h3&gt;
&lt;p&gt;删除容器使用 &lt;strong&gt;docker rm&lt;/strong&gt; 命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker rm -f 1e560fca3906
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="https://www.runoob.com/wp-content/uploads/2016/05/docker-container-rmi.png"&gt;&lt;figure style="flex: 247.16981132075472" &gt;&lt;img width="1572" height="318" src="https://www.runoob.com/wp-content/uploads/2016/05/docker-container-rmi.png" /&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;下面的命令可以清理掉所有处于终止状态的容器。&lt;/p&gt;&lt;p&gt;$ docker container prune&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;nvidia-docker run -it --name&lt;span class="o"&gt;=&lt;/span&gt;容器名 -v 宿主机目录:/容器内目录 -p 自定义端口号（此处假定为23333）:22 ufoym/deepo bash
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;镜像ufoym/deepo&lt;/p&gt;&lt;p&gt;-v是实现目录挂载，关于目录挂载，-p是端口映射，映射成功后可以直接通过映射后的端口访问docker。&lt;/p&gt;&lt;p&gt;举例：&lt;/p&gt;&lt;p&gt;假设服务器IP地址为** . ** . *. ***，端口映射为 -p 23333:22  -p 23334:6006  -p 23335:8888，其中8888是jupyter的默认端口，6006是tensorboard的默认端口。则可&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;通过IP地址的23333端口可以直接访问docker，无需通过22端口进入服务器，再在服务器中进入docker&lt;/li&gt;
&lt;li&gt;同一网段内的任意浏览器都可以通过 IP地址:6006来访问tensorboard（前提：已开启tensorboard服务）&lt;/li&gt;
&lt;li&gt;同一网段内的任意浏览器都可以通过 IP地址:8888来访问jupyter（前提：已开启jupyter服务）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果要在主机（计算机或VM）与使用Deepo的容器之间共享数据和配置，请使用-v选项，例如&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;nvidia-docker run -it -v /host/data:/data -v /host/config:/config ufoym/deepo bash
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;某些框架（例如PyTorch）使用共享内存在进程之间共享数据，因此如果使用多处理，容器运行的默认共享内存段大小是不够的，您应该使用&lt;code&gt;--ipc=host&lt;/code&gt;或&lt;code&gt;--shm-size&lt;/code&gt;命令行选项增加共享内存大小到&lt;code&gt;nvidia-docker run&lt;/code&gt;。&lt;/p&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;nvidia-docker run -it --ipc&lt;span class="o"&gt;=&lt;/span&gt;host ufoym/deepo bash
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;共享内存参数&lt;/h4&gt;
&lt;p&gt;shmmax:共享内存段最大尺寸(字节)
shmmni:共享内存段最大数目
shmall:系统共享内存最大尺寸(页), 对32位系统，一页(page)等于4KB
shmmin:共享内存段最小尺寸(字节)
shmseg:每进程最大共享内存段数量&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--ipc=&amp;quot;MODE&amp;quot; : Set the IPC mode for the container

&amp;quot;shareable&amp;quot;: Own private IPC namespace, with a possibility to share it with other containers.

&amp;quot;host&amp;quot;: Use the host system’s IPC namespace.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用host将IPC名称空间公开给控制了主机的攻击者。使用shareable，只能在容器内部访问IPC名称空间，其中可能包含任何攻击。 host模式的存在是为了允许容器与其主机之间进行协作。&lt;/p&gt;&lt;p&gt;--shm-size命令：设置共享内存，shared memory&lt;/p&gt;</content><link href="/Blog/archives/docker%E4%BD%BF%E7%94%A8/" rel="alternate"/><published>2021-07-30T00:00:00+08:06</published></entry><entry><id>/Blog/archives/%E8%BF%BD%E8%B8%AA%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</id><title>追踪基本知识</title><updated>2021-08-01T07:47:40.036297+00:00</updated><author><name>刘胜琪</name><email>1959376918@qq.com</email><uri>https://lsqsjtu.github.io/Blog/</uri></author><content>&lt;p&gt;&lt;strong&gt;object detection&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Region Proposal Network，直接翻译是“&lt;strong&gt;区域生成网络&lt;/strong&gt;”，通俗讲是“筛选出可能会有目标的框”。其本质是基于滑窗的无类别object检测器，输入是任意尺度的图像，输出是一系列矩形候选区域。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;BEV(Bird's Eye View) Map&lt;/strong&gt;：bev视角，鸟瞰视角&lt;/p&gt;</content><link href="/Blog/archives/%E8%BF%BD%E8%B8%AA%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/" rel="alternate"/><published>2021-08-01T00:00:00+08:06</published></entry></feed>